{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "364a9ebc-3e3c-4645-9049-a34bd084c8a8",
   "metadata": {},
   "source": [
    "# Method Benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c55227-147e-417f-b0dd-bb0b7f322930",
   "metadata": {},
   "source": [
    "- **Creator**: Sebastian Birk (<sebastian.birk@helmholtz-munich.de>).\n",
    "- **Affiliation:** Helmholtz Munich, Institute of Computational Biology (ICB), Talavera-LÃ³pez Lab\n",
    "- **Date of Creation:** 06.01.2023\n",
    "- **Date of Last Modification:** 16.01.2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7529cde5-be12-403b-a94c-07561774b86c",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faad87bd-fef5-4429-a175-d714c491ae76",
   "metadata": {},
   "source": [
    "### 1.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e0bf12-90ee-403e-8970-0d1ac2f47540",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../autotalker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f93960-c759-424f-8cb2-1d8698acae2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import scanpy as sc\n",
    "import scib\n",
    "import seaborn as sns\n",
    "\n",
    "from autotalker.benchmarking import compute_benchmarking_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b5efa5-2052-4986-8ae5-89cfab018515",
   "metadata": {},
   "source": [
    "### 1.2 Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c8b48a-ed5e-48b5-8c5c-c1de11493aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"seqfish_mouse_organogenesis_embryo2\"\n",
    "cell_type_key = \"celltype_mapped_refined\"\n",
    "spatial_key = \"spatial\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28adc110-0f41-4a71-9838-dc7f0687809a",
   "metadata": {},
   "source": [
    "### 1.3 Run Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334b87ca-3387-4ba9-8567-84bc4754ff0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.set_figure_params(figsize=(6, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab6b302-1c0b-4937-8624-40629ada2e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get time of notebook execution for timestamping saved artifacts\n",
    "now = datetime.now()\n",
    "current_timestamp = now.strftime(\"%d%m%Y_%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85538952-006b-4b0b-a50c-fe7445ce22e2",
   "metadata": {},
   "source": [
    "### 1.4 Configure Paths and Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddcc49c-ba22-4155-acd5-05b5b810e091",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder_path = \"../datasets/srt_data/gold/\"\n",
    "figure_folder_path = f\"../figures/method_benchmarking/{dataset}/\"\n",
    "artifact_folder_path = f\"../artifacts/method_benchmarking/{dataset}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb93ae1a-e35b-45ce-a488-6d592774c902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create required directories\n",
    "os.makedirs(artifact_folder_path, exist_ok=True)\n",
    "os.makedirs(figure_folder_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0172369b-361a-42de-bd56-82fef8accfac",
   "metadata": {},
   "source": [
    "### 1.5 Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749b4036-ffb8-4ed5-81b1-a8e5ffcba8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_combined_benchmarking_metrics(model_adata,\n",
    "                                          model_name,\n",
    "                                          spatial_model,\n",
    "                                          run_number_list=list(np.arange(1, 11)),\n",
    "                                          n_neighbors_list=[4, 4, 8, 8, 12, 12, 16, 16, 20, 20],\n",
    "                                          cell_type_key=\"celltype_mapped_refined\"):\n",
    "    benchmarking_dict_list = []\n",
    "    for run_number, n_neighbors in zip(run_number_list, n_neighbors_list):\n",
    "        \n",
    "        # Compute Autotalker metrics\n",
    "        benchmarking_dict = compute_benchmarking_metrics(adata=model_adata,\n",
    "                                                         spatial_model=spatial_model,\n",
    "                                                         latent_key=f\"{model_name}_latent_run{run_number}\",\n",
    "                                                         active_gp_names_key=f\"{model_name}_active_gp_names_run{run_number}\",\n",
    "                                                         cell_type_key=cell_type_key,\n",
    "                                                         spatial_key=spatial_key,\n",
    "                                                         spatial_knng_key = f\"{model_name}_spatial_{n_neighbors}nng\",\n",
    "                                                         latent_knng_key = f\"{model_name}_latent_{n_neighbors}nng\",\n",
    "                                                         n_neighbors=n_neighbors)\n",
    "\n",
    "        # Compute scib metrics\n",
    "        sc.pp.neighbors(adata=model_adata,\n",
    "                        use_rep=f\"{model_name}_latent_run{run_number}\",\n",
    "                        n_neighbors=n_neighbors)\n",
    "        scib.me.cluster_optimal_resolution(adata=model_adata,\n",
    "                                           cluster_key=\"cluster\",\n",
    "                                           label_key=cell_type_key)\n",
    "        benchmarking_dict[\"ari\"] = scib.me.ari(model_adata,\n",
    "                                               cluster_key=\"cluster\",\n",
    "                                               label_key=cell_type_key)\n",
    "        benchmarking_dict[\"clisi\"] = scib.me.clisi_graph(adata=model_adata,\n",
    "                                                         label_key=cell_type_key,\n",
    "                                                         type_=\"embed\",\n",
    "                                                         use_rep=f\"{model_name}_latent_run{run_number}\")\n",
    "        benchmarking_dict[\"nmi\"] = scib.me.nmi(adata=model_adata,\n",
    "                                               cluster_key=\"cluster\",\n",
    "                                               label_key=cell_type_key)\n",
    "        benchmarking_dict[\"asw\"] = scib.me.silhouette(adata=model_adata,\n",
    "                                                      label_key=cell_type_key,\n",
    "                                                      embed=f\"{model_name}_latent_run{run_number}\")\n",
    "        benchmarking_dict[\"ilasw\"] = scib.me.isolated_labels_asw(adata=model_adata,\n",
    "                                                                 batch_key=\"sample\",\n",
    "                                                                 label_key=cell_type_key,\n",
    "                                                                 embed=f\"{model_name}_latent_run{run_number}\")\n",
    "        \n",
    "        benchmarking_dict[\"model_name\"] = model_name\n",
    "        benchmarking_dict[\"run\"] = run_number\n",
    "        benchmarking_dict_list.append(benchmarking_dict)\n",
    "    return benchmarking_dict_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f3bcb4-901b-48dd-b684-a398c836160b",
   "metadata": {},
   "source": [
    "## 2. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e2d83f-e66a-4c9c-a151-bdfb491e08be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data after running all notebooks in the 'method_benchmarking' folder\n",
    "adata_pca = sc.read_h5ad(data_folder_path + f\"{dataset}_pca.h5ad\")\n",
    "adata_scvi = sc.read_h5ad(data_folder_path + f\"{dataset}_scvi.h5ad\")\n",
    "adata_expimap = sc.read_h5ad(data_folder_path + f\"{dataset}_expimap.h5ad\")\n",
    "adata_sagenet = sc.read_h5ad(data_folder_path + f\"{dataset}_sagenet.h5ad\")\n",
    "adata_deeplinc = sc.read_h5ad(data_folder_path + f\"{dataset}_deeplinc.h5ad\")\n",
    "adata_graphst = sc.read_h5ad(data_folder_path + f\"{dataset}_graphst.h5ad\")\n",
    "adata_autotalker = sc.read_h5ad(data_folder_path + f\"{dataset}_autotalker.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1f3798-2b4a-49ed-892c-a85d167d8ff1",
   "metadata": {},
   "source": [
    "## 3. Method Benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed96ebf-922e-42c2-a8aa-778e59737bc0",
   "metadata": {},
   "source": [
    "- Run all notebooks in the ```method_benchmarking``` directory before continuing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8884ac28-0cdf-4b37-9281-4a86dd194ef5",
   "metadata": {},
   "source": [
    "### 3.1 Latent Space Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57be0e75-d2d6-4244-82db-d225457bdb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = 12\n",
    "\n",
    "# Baseline\n",
    "sc.pp.neighbors(adata_pca, use_rep=f\"pca_latent_run1\", n_neighbors=n_neighbors)\n",
    "sc.tl.umap(adata_pca, min_dist=0.3)\n",
    "\n",
    "# Methods\n",
    "run_number = 5\n",
    "adata_sagenet.obsm[\"X_umap\"] = adata_sagenet.obsm[f\"sagenet_latent_run{run_number}\"] # latent representation of SageNet are already UMAP features\n",
    "for adata, method in zip([adata_scvi, adata_expimap, adata_deeplinc, adata_graphst, adata_autotalker],\n",
    "                         [\"scvi\", \"expimap\", \"deeplinc\", \"graphst\", \"autotalker\"]):\n",
    "    sc.pp.neighbors(adata, use_rep=f\"{method}_latent_run{run_number}\", n_neighbors=n_neighbors)\n",
    "    sc.tl.umap(adata, min_dist=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253a316b-1452-431f-80ad-9687828d3927",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=4, figsize=(20, 10))\n",
    "plt.suptitle(\"Latent Space Comparison\", fontsize=25, x=0.575)\n",
    "plt.subplots_adjust(hspace=0.25, wspace=0.25, top=0.9)\n",
    "axs=axs.flatten()\n",
    "\n",
    "sc.pl.spatial(adata=adata,\n",
    "              color=[cell_type_key],\n",
    "              spot_size=0.03,\n",
    "              ax=axs[0],\n",
    "              show=False)\n",
    "axs[0].set_title(\"Physical Space\", fontsize=17)\n",
    "handles, labels = axs[0].get_legend_handles_labels()\n",
    "lgd = fig.legend(handles, labels, loc=\"upper center\", bbox_to_anchor=(1.07, 0.845))\n",
    "axs[0].get_legend().remove()\n",
    "                         \n",
    "for i, (adata, title) in enumerate(zip([adata_autotalker, adata_deeplinc, adata_graphst, adata_sagenet, adata_pca, adata_scvi, adata_expimap],\n",
    "                                       [\"Autotalker\", \"DeepLinc\", \"GraphST\", \"SageNet\", \"Log Normalized Counts PCA\", \"scVI\", \"expiMap\"])):        \n",
    "    sc.pl.umap(adata,\n",
    "               color=[cell_type_key],\n",
    "               ax=axs[i + 1],\n",
    "               show=False,\n",
    "               legend_loc=None)\n",
    "    axs[i + 1].set_title(title, fontsize=17)\n",
    "\n",
    "fig.savefig(f\"{figure_folder_path}/latent_comparison_{current_timestamp}.png\",\n",
    "            bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781e4275-de08-4bf4-adbf-9519615d6ff4",
   "metadata": {},
   "source": [
    "### 3.2 Benchmarking Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000f2614-4aa5-400b-adb0-6b45d7fc38ce",
   "metadata": {},
   "source": [
    "#### 3.2.1 PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be5c8f3-1f57-4ea3-aba9-89947d6fe022",
   "metadata": {},
   "source": [
    "- Evaluate PCA of log normalized gene expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f742181-0e99-4e8e-a2b1-6c6599316fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarking_dict_list_pca = compute_combined_benchmarking_metrics(model_adata=adata_pca,\n",
    "                                                                   model_name=\"pca\",\n",
    "                                                                   spatial_model=False,\n",
    "                                                                   run_number_list=[1],\n",
    "                                                                   n_neighbors_list=[12],\n",
    "                                                                   cell_type_key=\"celltype_mapped_refined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccfd4e7-be35-4ccc-a5c2-6982b1576ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarking_dict_list = benchmarking_dict_list_pca\n",
    "\n",
    "# Store to disk\n",
    "with open(f\"{artifact_folder_path}/benchmarking_dict_list.pickle\", \"wb\") as f:\n",
    "    pickle.dump(benchmarking_dict_list, f)\n",
    "\n",
    "# Clean from memory\n",
    "del(adata_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6d14f8-f174-499e-bf03-43567d4b2663",
   "metadata": {},
   "source": [
    "#### 3.2.2 scVI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f8c8db-9986-4f3b-bcc3-f3be97dfdee0",
   "metadata": {},
   "source": [
    "- Evaluate scVI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d56a3fb-9c61-446c-87bd-b4a941eeec6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarking_dict_list_scvi = compute_combined_benchmarking_metrics(model_adata=adata_scvi,\n",
    "                                                                    model_name=\"scvi\",\n",
    "                                                                    spatial_model=False,\n",
    "                                                                    run_number_list=list(np.arange(1, 11)),\n",
    "                                                                    n_neighbors_list=[4, 4, 8, 8, 12, 12, 16, 16, 20, 20],\n",
    "                                                                    cell_type_key=\"celltype_mapped_refined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375c371b-5ec3-4ff0-8f57-29a7d649e74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarking_dict_list += benchmarking_dict_list_scvi\n",
    "\n",
    "# Store to disk\n",
    "with open(f\"{artifact_folder_path}/benchmarking_dict_list.pickle\", \"wb\") as f:\n",
    "    pickle.dump(benchmarking_dict_list, f)\n",
    "\n",
    "# Clean from memory\n",
    "del(adata_scvi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57f9dd0-6aa7-4090-98e4-765e646c9751",
   "metadata": {},
   "source": [
    "#### 3.2.3 expiMap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74225552-bd7a-4933-8252-cb95f89945e3",
   "metadata": {},
   "source": [
    "- Evaluate expiMap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0c96b2-7707-4bd9-ad36-56df712bf56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarking_dict_list_expimap = compute_combined_benchmarking_metrics(model_adata=adata_expimap,\n",
    "                                                                       model_name=\"expimap\",\n",
    "                                                                       spatial_model=False,\n",
    "                                                                       run_number_list=list(np.arange(1, 11)),\n",
    "                                                                       n_neighbors_list=[4, 4, 8, 8, 12, 12, 16, 16, 20, 20],\n",
    "                                                                       cell_type_key=\"celltype_mapped_refined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f694d1-b559-46ae-8d7b-1eee8aaac401",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarking_dict_list += benchmarking_dict_list_expimap\n",
    "\n",
    "# Store to disk\n",
    "with open(f\"{artifact_folder_path}/benchmarking_dict_list.pickle\", \"wb\") as f:\n",
    "    pickle.dump(benchmarking_dict_list, f)\n",
    "\n",
    "del(adata_expimap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f91d7cf-efb4-49fa-80a5-f98d37f9600b",
   "metadata": {},
   "source": [
    "#### 3.2.4 SageNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7e570e-87ba-4d39-8f18-d323292434ce",
   "metadata": {},
   "source": [
    "- Evaluate SageNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d38efcc-bb74-43ae-aadf-cd52780b3ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarking_dict_list_sagenet = compute_combined_benchmarking_metrics(model_adata=adata_sagenet,\n",
    "                                                                       model_name=\"sagenet\",\n",
    "                                                                       spatial_model=True,\n",
    "                                                                       run_number_list=list(np.arange(1, 11)),\n",
    "                                                                       n_neighbors_list=[4, 4, 8, 8, 12, 12, 16, 16, 20, 20],\n",
    "                                                                       cell_type_key=\"celltype_mapped_refined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2ff85a-3fe3-4f0f-a49c-3e4402df2cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarking_dict_list += benchmarking_dict_list_sagenet\n",
    "\n",
    "# Store to disk\n",
    "with open(f\"{artifact_folder_path}/benchmarking_dict_list.pickle\", \"wb\") as f:\n",
    "    pickle.dump(benchmarking_dict_list, f)\n",
    "    \n",
    "del(adata_sagenet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e819e7ff-4901-4688-8095-c72ede7f905b",
   "metadata": {},
   "source": [
    "#### 3.2.5 DeepLinc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc28dd65-eaba-4dbb-b2f6-cdba1bcdf017",
   "metadata": {},
   "source": [
    "- Evaluate DeepLinc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb28048f-d071-4fe1-87b9-7dd24fc13cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarking_dict_list_deeplinc = compute_combined_benchmarking_metrics(model_adata=adata_deeplinc,\n",
    "                                                                        model_name=\"deeplinc\",\n",
    "                                                                        spatial_model=True,\n",
    "                                                                        run_number_list=list(np.arange(1, 11)),\n",
    "                                                                        n_neighbors_list=[4, 4, 8, 8, 12, 12, 16, 16, 20, 20],\n",
    "                                                                        cell_type_key=\"celltype_mapped_refined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e01d17-e5c5-4f6e-8d84-332cfce70bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarking_dict_list += benchmarking_dict_list_deeplinc\n",
    "\n",
    "# Store to disk\n",
    "with open(f\"{artifact_folder_path}/benchmarking_dict_list.pickle\", \"wb\") as f:\n",
    "    pickle.dump(benchmarking_dict_list, f)\n",
    "\n",
    "del(adata_deeplinc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b185161d-e2ce-4eaa-b461-54efadb18263",
   "metadata": {},
   "source": [
    "#### 3.2.6 GraphST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e256ae-891c-4b36-acdb-eb6627ad333c",
   "metadata": {},
   "source": [
    "- Evaluate GraphST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3642faa2-80d6-452c-8fda-35f397c30fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarking_dict_list_graphst = compute_combined_benchmarking_metrics(model_adata=adata_graphst,\n",
    "                                                                       model_name=\"graphst\",\n",
    "                                                                       spatial_model=True,\n",
    "                                                                       run_number_list=list(np.arange(1, 11)),\n",
    "                                                                       n_neighbors_list=[4, 4, 8, 8, 12, 12, 16, 16, 20, 20],\n",
    "                                                                       cell_type_key=\"celltype_mapped_refined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853804b6-0861-48d1-9bdc-4818a63bdd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarking_dict_list += benchmarking_dict_list_graphst\n",
    "\n",
    "# Store to disk\n",
    "with open(f\"{artifact_folder_path}/benchmarking_dict_list.pickle\", \"wb\") as f:\n",
    "    pickle.dump(benchmarking_dict_list, f)\n",
    "\n",
    "del(adata_graphst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fe621a-6621-400e-a563-847a005475ee",
   "metadata": {},
   "source": [
    "#### 3.2.7 Autotalker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c59ed8-b06b-4fe0-ba25-88d500085268",
   "metadata": {},
   "source": [
    "- Evaluate Autotalker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577a6a10-a6eb-4c54-ba4a-fbaedbe9092c",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarking_dict_list_autotalker = compute_combined_benchmarking_metrics(model_adata=adata_autotalker,\n",
    "                                                                          model_name=\"autotalker\",\n",
    "                                                                          spatial_model=True,\n",
    "                                                                          run_number_list=list(np.arange(1, 11)),\n",
    "                                                                          n_neighbors_list=[4, 4, 8, 8, 12, 12, 16, 16, 20, 20],\n",
    "                                                                          cell_type_key=\"celltype_mapped_refined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5258d749-5a6c-4616-ae6e-b6f3f206c424",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarking_dict_list += benchmarking_dict_list_autotalker\n",
    "\n",
    "# Store to disk\n",
    "with open(f\"{artifact_folder_path}/benchmarking_dict_list.pickle\", \"wb\") as f:\n",
    "    pickle.dump(benchmarking_dict_list, f)\n",
    "\n",
    "del(adata_autotalker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d224f8-b044-4133-8242-e55c7bec4e9f",
   "metadata": {},
   "source": [
    "#### 3.2.8 Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06c1040-6026-425b-9f93-086de58b56d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read complete benchmarking data from disk\n",
    "with open(f\"{artifact_folder_path}/benchmarking_dict_list.pickle\", \"rb\") as f:\n",
    "    benchmarking_dict_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869cd40e-6788-4d5d-8213-ed68cccd667a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(benchmarking_dict_list)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4daed2-0f50-4772-895a-1ac9e25bfbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metric means over all runs\n",
    "mean_df = df.groupby(\"model_name\").mean()\n",
    "\n",
    "columns = [\"gcd\",\n",
    "           \"mlnmi\",\n",
    "           \"cad\",\n",
    "           \"arclisi\",\n",
    "           \"germse\",\n",
    "           \"cca\",\n",
    "           \"ari\",\n",
    "           \"clisi\",\n",
    "           \"nmi\",\n",
    "           \"asw\",\n",
    "           \"ilasw\"]\n",
    "\n",
    "rows = [\"autotalker\",\n",
    "        \"deeplinc\",\n",
    "        \"graphst\",\n",
    "        \"sagenet\",\n",
    "        \"pca\",\n",
    "        \"scvi\",\n",
    "        \"expimap\"]\n",
    "\n",
    "mean_df = mean_df[columns]\n",
    "mean_df = mean_df.reindex(rows)\n",
    "\n",
    "mean_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d21d727-72dd-4ab1-81bb-9b60191b746a",
   "metadata": {},
   "source": [
    "##### 3.2.8.1 Metrics Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f4fd45-3d4c-40aa-b5ec-2f24d0031443",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=int(np.ceil(len(columns)/2)), figsize=(3*len(columns), 8))\n",
    "axs=axs.flatten()\n",
    "\n",
    "for i, col in enumerate(columns):\n",
    "    sns.barplot(data=mean_df, x=mean_df.index, y=col, ax=axs[i])\n",
    "    axs[i].set_xlabel('')\n",
    "    xlabels = axs[i].get_xticks()\n",
    "    axs[i].set_xticklabels(mean_df.index, rotation=45)\n",
    "plt.suptitle(\"Method Benchmarking Metrics\", fontsize=25)\n",
    "plt.subplots_adjust(hspace=0.5, wspace=0.5, top=0.9)\n",
    "\n",
    "if len(columns) % 2 != 0:\n",
    "    fig.delaxes(axs[-1])\n",
    "\n",
    "fig.savefig(f\"{figure_folder_path}/metrics_{current_timestamp}.png\",\n",
    "            bbox_inches=\"tight\")    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89418b7-7d74-4dfb-be72-1f1c0aef93f1",
   "metadata": {},
   "source": [
    "##### 3.2.8.1 Metrics Ranking Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895e0bff-e8b0-4bc2-afa1-50b38cd19f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_df_min_best = mean_df[[\"gcd\", \"cad\", \"arclisi\", \"germse\"]] # lower values are better\n",
    "mean_df_max_best = mean_df[[\"mlnmi\", \"cca\", \"ari\", \"clisi\", \"nmi\", \"asw\", \"ilasw\", ]] # higher values are better\n",
    "rank_df_min = mean_df_min_best.rank(method=\"max\", ascending=True)\n",
    "rank_df_max = mean_df_max_best.rank(method=\"max\", ascending=False)\n",
    "rank_df = pd.concat([rank_df_min, rank_df_max], axis=1)\n",
    "rank_df = rank_df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfb4629-bd72-4918-bcf0-5176937a28b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap = sns.heatmap(rank_df, annot=True, cmap=\"YlGnBu\")\n",
    "fig = heatmap.get_figure()\n",
    "plt.title(\"Method Benchmarking Metrics Ranking\", fontsize=20, pad=25)\n",
    "plt.xticks(rotation=45)\n",
    "fig.savefig(f\"{figure_folder_path}/metrics_ranking_{current_timestamp}.png\",\n",
    "            bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40bd054-dc77-45c5-9c12-7ea78f6829a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
