{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "364a9ebc-3e3c-4645-9049-a34bd084c8a8",
   "metadata": {},
   "source": [
    "# Method Benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c55227-147e-417f-b0dd-bb0b7f322930",
   "metadata": {},
   "source": [
    "- **Creator**: Sebastian Birk (<sebastian.birk@helmholtz-munich.de>).\n",
    "- **Affiliation:** Helmholtz Munich, Institute of Computational Biology (ICB), Talavera-LÃ³pez Lab\n",
    "- **Date of Creation:** 06.01.2023\n",
    "- **Date of Last Modification:** 22.02.2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7529cde5-be12-403b-a94c-07561774b86c",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faad87bd-fef5-4429-a175-d714c491ae76",
   "metadata": {},
   "source": [
    "### 1.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9533f18-f082-4dcc-8e93-117b9759133e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1e0bf12-90ee-403e-8970-0d1ac2f47540",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../autotalker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7f93960-c759-424f-8cb2-1d8698acae2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sbirk/miniconda3/envs/autotalker/lib/python3.9/site-packages/omnipath/_core/query/_query_validator.py:165: ResourceWarning: unclosed <ssl.SSLSocket fd=58, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.209.62.242', 60420), raddr=('178.62.7.222', 443)>\n",
      "  res = Downloader(opt).maybe_download(\n",
      "/home/sbirk/miniconda3/envs/autotalker/lib/python3.9/site-packages/omnipath/_core/query/_query_validator.py:165: ResourceWarning: unclosed <ssl.SSLSocket fd=58, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.209.62.242', 60430), raddr=('178.62.7.222', 443)>\n",
      "  res = Downloader(opt).maybe_download(\n",
      "/home/sbirk/miniconda3/envs/autotalker/lib/python3.9/site-packages/omnipath/_core/query/_query_validator.py:165: ResourceWarning: unclosed <ssl.SSLSocket fd=58, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.209.62.242', 60432), raddr=('178.62.7.222', 443)>\n",
      "  res = Downloader(opt).maybe_download(\n",
      "/home/sbirk/miniconda3/envs/autotalker/lib/python3.9/site-packages/omnipath/_core/query/_query_validator.py:165: ResourceWarning: unclosed <ssl.SSLSocket fd=59, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.209.62.242', 60444), raddr=('178.62.7.222', 443)>\n",
      "  res = Downloader(opt).maybe_download(\n",
      "/home/sbirk/miniconda3/envs/autotalker/lib/python3.9/site-packages/omnipath/_core/query/_query_validator.py:165: ResourceWarning: unclosed <ssl.SSLSocket fd=59, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.209.62.242', 60458), raddr=('178.62.7.222', 443)>\n",
      "  res = Downloader(opt).maybe_download(\n",
      "/home/sbirk/miniconda3/envs/autotalker/lib/python3.9/site-packages/omnipath/_core/downloader/_downloader.py:218: ResourceWarning: unclosed <ssl.SSLSocket fd=59, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.209.62.242', 60464), raddr=('178.62.7.222', 443)>\n",
      "  return UNKNOWN_SERVER_VERSION\n",
      "/home/sbirk/miniconda3/envs/autotalker/lib/python3.9/site-packages/umap/__init__.py:9: ImportWarning: Tensorflow not installed; ParametricUMAP will be unavailable\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import scanpy as sc\n",
    "import scib\n",
    "import seaborn as sns\n",
    "\n",
    "from autotalker.benchmarking import compute_benchmarking_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b5efa5-2052-4986-8ae5-89cfab018515",
   "metadata": {},
   "source": [
    "### 1.2 Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5c8b48a-ed5e-48b5-8c5c-c1de11493aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"seqfish_mouse_organogenesis_embryo2\"\n",
    "cell_type_key = \"celltype_mapped_refined\"\n",
    "spatial_key = \"spatial\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28adc110-0f41-4a71-9838-dc7f0687809a",
   "metadata": {},
   "source": [
    "### 1.3 Run Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "334b87ca-3387-4ba9-8567-84bc4754ff0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sbirk/miniconda3/envs/autotalker/lib/python3.9/site-packages/scanpy/_settings.py:447: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  IPython.display.set_matplotlib_formats(*ipython_format)\n"
     ]
    }
   ],
   "source": [
    "sc.set_figure_params(figsize=(6, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ab6b302-1c0b-4937-8624-40629ada2e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get time of notebook execution for timestamping saved artifacts\n",
    "now = datetime.now()\n",
    "current_timestamp = now.strftime(\"%d%m%Y_%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85538952-006b-4b0b-a50c-fe7445ce22e2",
   "metadata": {},
   "source": [
    "### 1.4 Configure Paths and Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ddcc49c-ba22-4155-acd5-05b5b810e091",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder_path = \"../datasets/srt_data/gold/\"\n",
    "figure_folder_path = f\"../figures/{dataset}/method_benchmarking/\"\n",
    "artifact_folder_path = f\"../artifacts/{dataset}/method_benchmarking/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb93ae1a-e35b-45ce-a488-6d592774c902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create required directories\n",
    "os.makedirs(artifact_folder_path, exist_ok=True)\n",
    "os.makedirs(figure_folder_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0172369b-361a-42de-bd56-82fef8accfac",
   "metadata": {},
   "source": [
    "### 1.5 Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "749b4036-ffb8-4ed5-81b1-a8e5ffcba8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_combined_benchmarking_metrics(model_adata,\n",
    "                                          model_name,\n",
    "                                          cell_type_key,\n",
    "                                          run_number_list=list(np.arange(1, 11)),\n",
    "                                          n_neighbors_list=[4, 4, 8, 8, 12, 12, 16, 16, 20, 20]):\n",
    "    benchmarking_dict_list = []\n",
    "    for run_number, n_neighbors in zip(run_number_list, n_neighbors_list):\n",
    "        \n",
    "        # Compute Autotalker metrics\n",
    "        benchmarking_dict = compute_benchmarking_metrics(adata=model_adata,\n",
    "                                                         latent_key=f\"{model_name}_latent_run{run_number}\",\n",
    "                                                         active_gp_names_key=f\"{model_name}_active_gp_names_run{run_number}\",\n",
    "                                                         cell_type_key=cell_type_key,\n",
    "                                                         spatial_key=spatial_key,\n",
    "                                                         spatial_knng_key=\"spatial_knng\",\n",
    "                                                         latent_knng_key = f\"{model_name}_latent_knng_run{run_number}\")\n",
    "\n",
    "        # Compute scib metrics\n",
    "        sc.pp.neighbors(adata=model_adata,\n",
    "                        use_rep=f\"{model_name}_latent_run{run_number}\")\n",
    "        scib.me.cluster_optimal_resolution(adata=model_adata,\n",
    "                                           cluster_key=\"cluster\",\n",
    "                                           label_key=cell_type_key)\n",
    "        benchmarking_dict[\"ari\"] = scib.me.ari(model_adata,\n",
    "                                               cluster_key=\"cluster\",\n",
    "                                               label_key=cell_type_key)\n",
    "        benchmarking_dict[\"clisi\"] = scib.me.clisi_graph(adata=model_adata,\n",
    "                                                         label_key=cell_type_key,\n",
    "                                                         type_=\"embed\",\n",
    "                                                         use_rep=f\"{model_name}_latent_run{run_number}\")\n",
    "        benchmarking_dict[\"nmi\"] = scib.me.nmi(adata=model_adata,\n",
    "                                               cluster_key=\"cluster\",\n",
    "                                               label_key=cell_type_key)\n",
    "        benchmarking_dict[\"asw\"] = scib.me.silhouette(adata=model_adata,\n",
    "                                                      label_key=cell_type_key,\n",
    "                                                      embed=f\"{model_name}_latent_run{run_number}\")\n",
    "        benchmarking_dict[\"ilasw\"] = scib.me.isolated_labels_asw(adata=model_adata,\n",
    "                                                                 batch_key=\"sample\",\n",
    "                                                                 label_key=cell_type_key,\n",
    "                                                                 embed=f\"{model_name}_latent_run{run_number}\")\n",
    "        \n",
    "        benchmarking_dict[\"model_name\"] = model_name\n",
    "        benchmarking_dict[\"run\"] = run_number\n",
    "        benchmarking_dict_list.append(benchmarking_dict)\n",
    "    return benchmarking_dict_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f3bcb4-901b-48dd-b684-a398c836160b",
   "metadata": {},
   "source": [
    "## 2. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74e2d83f-e66a-4c9c-a151-bdfb491e08be",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = '../datasets/srt_data/gold/seqfish_mouse_organogenesis_embryo2_pca.h5ad', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load data after running all notebooks in the 'method_benchmarking' folder\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m adata_pca \u001b[38;5;241m=\u001b[39m \u001b[43msc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_h5ad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_folder_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdataset\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_pca.h5ad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m adata_scvi \u001b[38;5;241m=\u001b[39m sc\u001b[38;5;241m.\u001b[39mread_h5ad(data_folder_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_scvi.h5ad\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m adata_expimap \u001b[38;5;241m=\u001b[39m sc\u001b[38;5;241m.\u001b[39mread_h5ad(data_folder_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_expimap.h5ad\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/autotalker/lib/python3.9/site-packages/anndata/_io/h5ad.py:224\u001b[0m, in \u001b[0;36mread_h5ad\u001b[0;34m(filename, backed, as_sparse, as_sparse_fmt, chunk_size)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    217\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrently only `X` and `raw/X` can be read as sparse.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    218\u001b[0m         )\n\u001b[1;32m    220\u001b[0m rdasp \u001b[38;5;241m=\u001b[39m partial(\n\u001b[1;32m    221\u001b[0m     read_dense_as_sparse, sparse_format\u001b[38;5;241m=\u001b[39mas_sparse_fmt, axis_chunk\u001b[38;5;241m=\u001b[39mchunk_size\n\u001b[1;32m    222\u001b[0m )\n\u001b[0;32m--> 224\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    225\u001b[0m     d \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m f\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    227\u001b[0m         \u001b[38;5;66;03m# Backwards compat for old raw\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/autotalker/lib/python3.9/site-packages/h5py/_hl/files.py:567\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    558\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    559\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    560\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    561\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    562\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[1;32m    563\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    564\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    565\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    566\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 567\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m~/miniconda3/envs/autotalker/lib/python3.9/site-packages/h5py/_hl/files.py:231\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[1;32m    230\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 231\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    233\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:106\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = '../datasets/srt_data/gold/seqfish_mouse_organogenesis_embryo2_pca.h5ad', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "# Load data after running all notebooks in the 'method_benchmarking' folder\n",
    "adata_pca = sc.read_h5ad(data_folder_path + f\"{dataset}_pca.h5ad\")\n",
    "adata_scvi = sc.read_h5ad(data_folder_path + f\"{dataset}_scvi.h5ad\")\n",
    "adata_expimap = sc.read_h5ad(data_folder_path + f\"{dataset}_expimap.h5ad\")\n",
    "adata_sagenet = sc.read_h5ad(data_folder_path + f\"{dataset}_sagenet.h5ad\")\n",
    "adata_deeplinc = sc.read_h5ad(data_folder_path + f\"{dataset}_deeplinc.h5ad\")\n",
    "adata_graphst = sc.read_h5ad(data_folder_path + f\"{dataset}_graphst.h5ad\")\n",
    "adata_autotalker = sc.read_h5ad(data_folder_path + f\"{dataset}_autotalker.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1f3798-2b4a-49ed-892c-a85d167d8ff1",
   "metadata": {},
   "source": [
    "## 3. Method Benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed96ebf-922e-42c2-a8aa-778e59737bc0",
   "metadata": {},
   "source": [
    "- Run all notebooks in the ```method_benchmarking``` directory before continuing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8884ac28-0cdf-4b37-9281-4a86dd194ef5",
   "metadata": {},
   "source": [
    "### 3.1 Latent Space Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57be0e75-d2d6-4244-82db-d225457bdb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline\n",
    "sc.pp.neighbors(adata_pca, use_rep=f\"pca_latent_run1\")\n",
    "sc.tl.umap(adata_pca)\n",
    "\n",
    "# Methods\n",
    "run_number = 5\n",
    "adata_sagenet.obsm[\"X_umap\"] = adata_sagenet.obsm[f\"sagenet_latent_run{run_number}\"] # latent representation of SageNet are already UMAP features\n",
    "for adata, method in zip([adata_scvi, adata_expimap, adata_deeplinc, adata_graphst, adata_autotalker],\n",
    "                         [\"scvi\", \"expimap\", \"deeplinc\", \"graphst\", \"autotalker\"]):\n",
    "    sc.pp.neighbors(adata, use_rep=f\"{method}_latent_run{run_number}\")\n",
    "    sc.tl.umap(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253a316b-1452-431f-80ad-9687828d3927",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=4, figsize=(20, 10))\n",
    "plt.suptitle(\"Latent Space Comparison\", fontsize=25, x=0.575)\n",
    "plt.subplots_adjust(hspace=0.25, wspace=0.25, top=0.9)\n",
    "axs=axs.flatten()\n",
    "\n",
    "sc.pl.spatial(adata=adata,\n",
    "              color=[cell_type_key],\n",
    "              spot_size=0.03,\n",
    "              ax=axs[0],\n",
    "              show=False)\n",
    "axs[0].set_title(\"Physical Space\", fontsize=17)\n",
    "handles, labels = axs[0].get_legend_handles_labels()\n",
    "lgd = fig.legend(handles, labels, loc=\"upper center\", bbox_to_anchor=(1.07, 0.845))\n",
    "axs[0].get_legend().remove()\n",
    "                         \n",
    "for i, (adata, title) in enumerate(zip([adata_autotalker, adata_deeplinc, adata_graphst, adata_sagenet, adata_pca, adata_scvi, adata_expimap],\n",
    "                                       [\"Autotalker\", \"DeepLinc\", \"GraphST\", \"SageNet\", \"Log Normalized Counts PCA\", \"scVI\", \"expiMap\"])):        \n",
    "    sc.pl.umap(adata,\n",
    "               color=[cell_type_key],\n",
    "               ax=axs[i + 1],\n",
    "               show=False,\n",
    "               legend_loc=None)\n",
    "    axs[i + 1].set_title(title, fontsize=17)\n",
    "\n",
    "fig.savefig(f\"{figure_folder_path}/latent_comparison_{current_timestamp}.png\",\n",
    "            bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781e4275-de08-4bf4-adbf-9519615d6ff4",
   "metadata": {},
   "source": [
    "### 3.2 Benchmarking Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000f2614-4aa5-400b-adb0-6b45d7fc38ce",
   "metadata": {},
   "source": [
    "#### 3.2.1 PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be5c8f3-1f57-4ea3-aba9-89947d6fe022",
   "metadata": {},
   "source": [
    "- Evaluate PCA of log normalized gene expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f742181-0e99-4e8e-a2b1-6c6599316fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarking_dict_list_pca = compute_combined_benchmarking_metrics(model_adata=adata_pca,\n",
    "                                                                   model_name=\"pca\",\n",
    "                                                                   spatial_model=False,\n",
    "                                                                   run_number_list=[1],\n",
    "                                                                   n_neighbors_list=[12],\n",
    "                                                                   cell_type_key=\"celltype_mapped_refined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccfd4e7-be35-4ccc-a5c2-6982b1576ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarking_dict_list = benchmarking_dict_list_pca\n",
    "\n",
    "# Store to disk\n",
    "with open(f\"{artifact_folder_path}/benchmarking_dict_list.pickle\", \"wb\") as f:\n",
    "    pickle.dump(benchmarking_dict_list, f)\n",
    "\n",
    "# Clean from memory\n",
    "del(adata_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6d14f8-f174-499e-bf03-43567d4b2663",
   "metadata": {},
   "source": [
    "#### 3.2.2 scVI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f8c8db-9986-4f3b-bcc3-f3be97dfdee0",
   "metadata": {},
   "source": [
    "- Evaluate scVI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d56a3fb-9c61-446c-87bd-b4a941eeec6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarking_dict_list_scvi = compute_combined_benchmarking_metrics(model_adata=adata_scvi,\n",
    "                                                                    model_name=\"scvi\",\n",
    "                                                                    spatial_model=False,\n",
    "                                                                    run_number_list=list(np.arange(1, 11)),\n",
    "                                                                    n_neighbors_list=[4, 4, 8, 8, 12, 12, 16, 16, 20, 20],\n",
    "                                                                    cell_type_key=\"celltype_mapped_refined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375c371b-5ec3-4ff0-8f57-29a7d649e74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarking_dict_list += benchmarking_dict_list_scvi\n",
    "\n",
    "# Store to disk\n",
    "with open(f\"{artifact_folder_path}/benchmarking_dict_list.pickle\", \"wb\") as f:\n",
    "    pickle.dump(benchmarking_dict_list, f)\n",
    "\n",
    "# Clean from memory\n",
    "del(adata_scvi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57f9dd0-6aa7-4090-98e4-765e646c9751",
   "metadata": {},
   "source": [
    "#### 3.2.3 expiMap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74225552-bd7a-4933-8252-cb95f89945e3",
   "metadata": {},
   "source": [
    "- Evaluate expiMap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0c96b2-7707-4bd9-ad36-56df712bf56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarking_dict_list_expimap = compute_combined_benchmarking_metrics(model_adata=adata_expimap,\n",
    "                                                                       model_name=\"expimap\",\n",
    "                                                                       spatial_model=False,\n",
    "                                                                       run_number_list=list(np.arange(1, 11)),\n",
    "                                                                       n_neighbors_list=[4, 4, 8, 8, 12, 12, 16, 16, 20, 20],\n",
    "                                                                       cell_type_key=\"celltype_mapped_refined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f694d1-b559-46ae-8d7b-1eee8aaac401",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarking_dict_list += benchmarking_dict_list_expimap\n",
    "\n",
    "# Store to disk\n",
    "with open(f\"{artifact_folder_path}/benchmarking_dict_list.pickle\", \"wb\") as f:\n",
    "    pickle.dump(benchmarking_dict_list, f)\n",
    "\n",
    "del(adata_expimap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f91d7cf-efb4-49fa-80a5-f98d37f9600b",
   "metadata": {},
   "source": [
    "#### 3.2.4 SageNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7e570e-87ba-4d39-8f18-d323292434ce",
   "metadata": {},
   "source": [
    "- Evaluate SageNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d38efcc-bb74-43ae-aadf-cd52780b3ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarking_dict_list_sagenet = compute_combined_benchmarking_metrics(model_adata=adata_sagenet,\n",
    "                                                                       model_name=\"sagenet\",\n",
    "                                                                       spatial_model=True,\n",
    "                                                                       run_number_list=list(np.arange(1, 11)),\n",
    "                                                                       n_neighbors_list=[4, 4, 8, 8, 12, 12, 16, 16, 20, 20],\n",
    "                                                                       cell_type_key=\"celltype_mapped_refined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2ff85a-3fe3-4f0f-a49c-3e4402df2cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarking_dict_list += benchmarking_dict_list_sagenet\n",
    "\n",
    "# Store to disk\n",
    "with open(f\"{artifact_folder_path}/benchmarking_dict_list.pickle\", \"wb\") as f:\n",
    "    pickle.dump(benchmarking_dict_list, f)\n",
    "    \n",
    "del(adata_sagenet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e819e7ff-4901-4688-8095-c72ede7f905b",
   "metadata": {},
   "source": [
    "#### 3.2.5 DeepLinc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc28dd65-eaba-4dbb-b2f6-cdba1bcdf017",
   "metadata": {},
   "source": [
    "- Evaluate DeepLinc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb28048f-d071-4fe1-87b9-7dd24fc13cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarking_dict_list_deeplinc = compute_combined_benchmarking_metrics(model_adata=adata_deeplinc,\n",
    "                                                                        model_name=\"deeplinc\",\n",
    "                                                                        spatial_model=True,\n",
    "                                                                        run_number_list=list(np.arange(1, 11)),\n",
    "                                                                        n_neighbors_list=[4, 4, 8, 8, 12, 12, 16, 16, 20, 20],\n",
    "                                                                        cell_type_key=\"celltype_mapped_refined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e01d17-e5c5-4f6e-8d84-332cfce70bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarking_dict_list += benchmarking_dict_list_deeplinc\n",
    "\n",
    "# Store to disk\n",
    "with open(f\"{artifact_folder_path}/benchmarking_dict_list.pickle\", \"wb\") as f:\n",
    "    pickle.dump(benchmarking_dict_list, f)\n",
    "\n",
    "del(adata_deeplinc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b185161d-e2ce-4eaa-b461-54efadb18263",
   "metadata": {},
   "source": [
    "#### 3.2.6 GraphST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e256ae-891c-4b36-acdb-eb6627ad333c",
   "metadata": {},
   "source": [
    "- Evaluate GraphST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3642faa2-80d6-452c-8fda-35f397c30fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarking_dict_list_graphst = compute_combined_benchmarking_metrics(model_adata=adata_graphst,\n",
    "                                                                       model_name=\"graphst\",\n",
    "                                                                       spatial_model=True,\n",
    "                                                                       run_number_list=list(np.arange(1, 11)),\n",
    "                                                                       n_neighbors_list=[4, 4, 8, 8, 12, 12, 16, 16, 20, 20],\n",
    "                                                                       cell_type_key=\"celltype_mapped_refined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853804b6-0861-48d1-9bdc-4818a63bdd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarking_dict_list += benchmarking_dict_list_graphst\n",
    "\n",
    "# Store to disk\n",
    "with open(f\"{artifact_folder_path}/benchmarking_dict_list.pickle\", \"wb\") as f:\n",
    "    pickle.dump(benchmarking_dict_list, f)\n",
    "\n",
    "del(adata_graphst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fe621a-6621-400e-a563-847a005475ee",
   "metadata": {},
   "source": [
    "#### 3.2.7 Autotalker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c59ed8-b06b-4fe0-ba25-88d500085268",
   "metadata": {},
   "source": [
    "- Evaluate Autotalker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577a6a10-a6eb-4c54-ba4a-fbaedbe9092c",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarking_dict_list_autotalker = compute_combined_benchmarking_metrics(model_adata=adata_autotalker,\n",
    "                                                                          model_name=\"autotalker\",\n",
    "                                                                          spatial_model=True,\n",
    "                                                                          run_number_list=list(np.arange(1, 11)),\n",
    "                                                                          n_neighbors_list=[4, 4, 8, 8, 12, 12, 16, 16, 20, 20],\n",
    "                                                                          cell_type_key=\"celltype_mapped_refined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5258d749-5a6c-4616-ae6e-b6f3f206c424",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarking_dict_list += benchmarking_dict_list_autotalker\n",
    "\n",
    "# Store to disk\n",
    "with open(f\"{artifact_folder_path}/benchmarking_dict_list.pickle\", \"wb\") as f:\n",
    "    pickle.dump(benchmarking_dict_list, f)\n",
    "\n",
    "del(adata_autotalker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d224f8-b044-4133-8242-e55c7bec4e9f",
   "metadata": {},
   "source": [
    "#### 3.2.8 Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06c1040-6026-425b-9f93-086de58b56d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read complete benchmarking data from disk\n",
    "with open(f\"{artifact_folder_path}/benchmarking_dict_list.pickle\", \"rb\") as f:\n",
    "    benchmarking_dict_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869cd40e-6788-4d5d-8213-ed68cccd667a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(benchmarking_dict_list)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4daed2-0f50-4772-895a-1ac9e25bfbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metric means over all runs\n",
    "mean_df = df.groupby(\"model_name\").mean()\n",
    "\n",
    "columns = [\"gcd\",\n",
    "           \"mlnmi\",\n",
    "           \"cad\",\n",
    "           \"arclisi\",\n",
    "           \"germse\",\n",
    "           \"cca\",\n",
    "           \"ari\",\n",
    "           \"clisi\",\n",
    "           \"nmi\",\n",
    "           \"asw\",\n",
    "           \"ilasw\"]\n",
    "\n",
    "rows = [\"autotalker\",\n",
    "        \"deeplinc\",\n",
    "        \"graphst\",\n",
    "        \"sagenet\",\n",
    "        \"pca\",\n",
    "        \"scvi\",\n",
    "        \"expimap\"]\n",
    "\n",
    "mean_df = mean_df[columns]\n",
    "mean_df = mean_df.reindex(rows)\n",
    "\n",
    "mean_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d21d727-72dd-4ab1-81bb-9b60191b746a",
   "metadata": {},
   "source": [
    "##### 3.2.8.1 Metrics Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f4fd45-3d4c-40aa-b5ec-2f24d0031443",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=int(np.ceil(len(columns)/2)), figsize=(3*len(columns), 8))\n",
    "axs=axs.flatten()\n",
    "\n",
    "for i, col in enumerate(columns):\n",
    "    sns.barplot(data=mean_df, x=mean_df.index, y=col, ax=axs[i])\n",
    "    axs[i].set_xlabel('')\n",
    "    xlabels = axs[i].get_xticks()\n",
    "    axs[i].set_xticklabels(mean_df.index, rotation=45)\n",
    "plt.suptitle(\"Method Benchmarking Metrics\", fontsize=25)\n",
    "plt.subplots_adjust(hspace=0.5, wspace=0.5, top=0.9)\n",
    "\n",
    "if len(columns) % 2 != 0:\n",
    "    fig.delaxes(axs[-1])\n",
    "\n",
    "fig.savefig(f\"{figure_folder_path}/metrics_{current_timestamp}.png\",\n",
    "            bbox_inches=\"tight\")    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89418b7-7d74-4dfb-be72-1f1c0aef93f1",
   "metadata": {},
   "source": [
    "##### 3.2.8.1 Metrics Ranking Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895e0bff-e8b0-4bc2-afa1-50b38cd19f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_df_min_best = mean_df[[\"gcd\", \"cad\", \"arclisi\", \"germse\"]] # lower values are better\n",
    "mean_df_max_best = mean_df[[\"mlnmi\", \"cca\", \"ari\", \"clisi\", \"nmi\", \"asw\", \"ilasw\", ]] # higher values are better\n",
    "rank_df_min = mean_df_min_best.rank(method=\"max\", ascending=True)\n",
    "rank_df_max = mean_df_max_best.rank(method=\"max\", ascending=False)\n",
    "rank_df = pd.concat([rank_df_min, rank_df_max], axis=1)\n",
    "rank_df = rank_df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfb4629-bd72-4918-bcf0-5176937a28b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap = sns.heatmap(rank_df, annot=True, cmap=\"YlGnBu\")\n",
    "fig = heatmap.get_figure()\n",
    "plt.title(\"Method Benchmarking Metrics Ranking\", fontsize=20, pad=25)\n",
    "plt.xticks(rotation=45)\n",
    "fig.savefig(f\"{figure_folder_path}/metrics_ranking_{current_timestamp}.png\",\n",
    "            bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40bd054-dc77-45c5-9c12-7ea78f6829a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
