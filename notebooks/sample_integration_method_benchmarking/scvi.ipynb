{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "364a9ebc-3e3c-4645-9049-a34bd084c8a8",
   "metadata": {},
   "source": [
    "# scVI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c55227-147e-417f-b0dd-bb0b7f322930",
   "metadata": {},
   "source": [
    "- **Creator**: Sebastian Birk (<sebastian.birk@helmholtz-munich.de>).\n",
    "- **Affiliation:** Helmholtz Munich, Institute of Computational Biology (ICB), Talavera-López Lab\n",
    "- **Date of Creation:** 05.01.2023\n",
    "- **Date of Last Modification:** 24.04.2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f91758d-06e2-478a-a934-5f04ee9344eb",
   "metadata": {},
   "source": [
    "- The scVI source code is available at https://github.com/scverse/scvi-tools.\n",
    "- The corresponding publication is \"Lopez, R., Regier, J., Cole, M. B., Jordan, M. I. & Yosef, N. Deep generative modeling for single-cell transcriptomics. Nat. Methods 15, 1053–1058 (2018)\".\n",
    "- The workflow of this notebook follows the tutorial from https://docs.scvi-tools.org/en/stable/tutorials/notebooks/harmonization.html.\n",
    "- The authors use raw counts as input to scVI. Therefore, we also use raw counts (stored in adata.layers[\"counts\"])."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7529cde5-be12-403b-a94c-07561774b86c",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faad87bd-fef5-4429-a175-d714c491ae76",
   "metadata": {},
   "source": [
    "### 1.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7f93960-c759-424f-8cb2-1d8698acae2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import anndata as ad\n",
    "import scvi\n",
    "import scanpy as sc\n",
    "import scipy.sparse as sp\n",
    "import squidpy as sq\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b5efa5-2052-4986-8ae5-89cfab018515",
   "metadata": {},
   "source": [
    "### 1.2 Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5c8b48a-ed5e-48b5-8c5c-c1de11493aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"scvi\"\n",
    "latent_key = f\"{model_name}_latent\"\n",
    "mapping_entity_key = \"reference\"\n",
    "condition_key = \"batch\"\n",
    "counts_key = \"counts\"\n",
    "leiden_resolution = 0.5 # used for Leiden clustering of latent space\n",
    "random_seed = 0 # used for Leiden clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28adc110-0f41-4a71-9838-dc7f0687809a",
   "metadata": {},
   "source": [
    "### 1.3 Run Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "334b87ca-3387-4ba9-8567-84bc4754ff0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.set_figure_params(figsize=(6, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ab6b302-1c0b-4937-8624-40629ada2e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get time of notebook execution for timestamping saved artifacts\n",
    "now = datetime.now()\n",
    "current_timestamp = now.strftime(\"%d%m%Y_%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85538952-006b-4b0b-a50c-fe7445ce22e2",
   "metadata": {},
   "source": [
    "### 1.4 Configure Paths and Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ddcc49c-ba22-4155-acd5-05b5b810e091",
   "metadata": {},
   "outputs": [],
   "source": [
    "srt_data_gold_folder_path = \"../../datasets/srt_data/gold/\"\n",
    "srt_data_results_folder_path = \"../../datasets/srt_data/results/\" \n",
    "figure_folder_path = f\"../../figures\"\n",
    "\n",
    "# Create required directories\n",
    "os.makedirs(srt_data_gold_folder_path, exist_ok=True)\n",
    "os.makedirs(srt_data_results_folder_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d974cd00-eafa-4432-b172-fafc4058a619",
   "metadata": {},
   "source": [
    "## 2. scVI Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427dec10-5c8b-4eb2-a032-987b22beef9e",
   "metadata": {},
   "source": [
    "### 2.1 Define Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9981586-fc49-4654-a4a8-8224d09dd630",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_scvi_models(dataset,\n",
    "                      reference_batches,\n",
    "                      cell_type_key,\n",
    "                      adata_new=None,\n",
    "                      n_start_run=1,\n",
    "                      n_end_run=10,\n",
    "                      n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16, 20, 20],\n",
    "                      plot_latent_umaps=False):    \n",
    "    # Create new adata to store results from training runs in storage-efficient way\n",
    "    if adata_new is None:  \n",
    "        adata_batch_list = []\n",
    "        if reference_batches is not None:\n",
    "            for batch in reference_batches:\n",
    "                adata_batch = ad.read_h5ad(\n",
    "                    f\"{srt_data_gold_folder_path}/{dataset}_{batch}.h5ad\")\n",
    "                adata_batch.obs[mapping_entity_key] = \"reference\"\n",
    "                adata_batch_list.append(adata_batch)\n",
    "            adata_original = ad.concat(adata_batch_list, join=\"inner\")\n",
    "        else:\n",
    "            adata_original = ad.read_h5ad(f\"{srt_data_gold_folder_path}/{dataset}.h5ad\")\n",
    "\n",
    "        adata_new = sc.AnnData(sp.csr_matrix(\n",
    "            (adata_original.shape[0], adata_original.shape[1]),\n",
    "            dtype=np.float32))\n",
    "        adata_new.var_names = adata_original.var_names\n",
    "        adata_new.obs_names = adata_original.obs_names\n",
    "        adata_new.obs[\"cell_type\"] = adata_original.obs[cell_type_key].values\n",
    "        adata_new.obsm[\"spatial\"] = adata_original.obsm[\"spatial\"]\n",
    "        adata_new.obs[condition_key] = adata_original.obs[condition_key]\n",
    "        adata_new.obs[mapping_entity_key] = adata_original.obs[mapping_entity_key] \n",
    "        del(adata_original)\n",
    "        \n",
    "    model_seeds = list(range(10))\n",
    "    for run_number, n_neighbors in zip(np.arange(n_start_run, n_end_run+1), n_neighbor_list):\n",
    "        # n_neighbors is here only used for the latent neighbor graph construction used for\n",
    "        # UMAP generation and clustering as scVI is not a spatial method\n",
    "        \n",
    "        # Load data\n",
    "        adata_batch_list = []\n",
    "        if reference_batches is not None:\n",
    "            for batch in reference_batches:\n",
    "                print(f\"Processing batch {batch}...\")\n",
    "                print(\"Loading data...\")\n",
    "                adata_batch = ad.read_h5ad(\n",
    "                    f\"{srt_data_gold_folder_path}/{dataset}_{batch}.h5ad\")\n",
    "                adata_batch_list.append(adata_batch)\n",
    "            adata = ad.concat(adata_batch_list, join=\"inner\")\n",
    "        else:\n",
    "            adata = ad.read_h5ad(f\"{srt_data_gold_folder_path}/{dataset}.h5ad\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        scvi.settings.seed = model_seeds[run_number-1]\n",
    "\n",
    "        # Setup adata\n",
    "        scvi.model.SCVI.setup_anndata(adata,\n",
    "                                      layer=counts_key,\n",
    "                                      batch_key=condition_key)\n",
    "\n",
    "        # Initialize model\n",
    "        # Use hyperparams that provenly work well on integration tasks\n",
    "        model = scvi.model.SCVI(adata,\n",
    "                                n_layers=2,\n",
    "                                n_latent=30,\n",
    "                                gene_likelihood=\"nb\")\n",
    "\n",
    "        # Train model\n",
    "        model.train()\n",
    "\n",
    "        # Store latent representation\n",
    "        adata.obsm[latent_key] = model.get_latent_representation()\n",
    "        \n",
    "        # Measure time for model training\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        hours, rem = divmod(elapsed_time, 3600)\n",
    "        minutes, seconds = divmod(rem, 60)\n",
    "        print(f\"Duration of model training in run {run_number}: \"\n",
    "              f\"{int(hours)} hours, {int(minutes)} minutes and {int(seconds)} seconds.\")\n",
    "        adata_new.uns[f\"{model_name}_model_training_duration_run{run_number}\"] = (\n",
    "            elapsed_time)\n",
    "        \n",
    "        if plot_latent_umaps:\n",
    "            # Configure figure folder path\n",
    "            dataset_figure_folder_path = f\"{figure_folder_path}/{dataset}/sample_integration_method_benchmarking/\" \\\n",
    "                                         f\"{model_name}/{current_timestamp}\"\n",
    "            os.makedirs(dataset_figure_folder_path, exist_ok=True)\n",
    "    \n",
    "            # Use scVI latent space for UMAP generation\n",
    "            sc.pp.neighbors(adata,\n",
    "                            use_rep=latent_key,\n",
    "                            n_neighbors=n_neighbors)\n",
    "            sc.tl.umap(adata)\n",
    "            fig = sc.pl.umap(adata,\n",
    "                             color=[cell_type_key],\n",
    "                             title=\"Latent Space with Cell Types: scVI\",\n",
    "                             return_fig=True)\n",
    "            fig.savefig(f\"{dataset_figure_folder_path}/latent_{model_name}\"\n",
    "                        f\"_cell_types_run{run_number}.png\",\n",
    "                        bbox_inches=\"tight\")\n",
    "\n",
    "            # Compute latent Leiden clustering\n",
    "            sc.tl.leiden(adata=adata,\n",
    "                         resolution=leiden_resolution,\n",
    "                         random_state=random_seed,\n",
    "                         key_added=f\"latent_{model_name}_leiden_{str(leiden_resolution)}\")\n",
    "\n",
    "            # Create subplot of latent Leiden cluster annotations in physical and latent space\n",
    "            fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(6, 12))\n",
    "            title = fig.suptitle(t=\"Latent and Physical Space with Leiden Clusters: scVI\")\n",
    "            sc.pl.umap(adata=adata,\n",
    "                       color=[f\"latent_{model_name}_leiden_{str(leiden_resolution)}\"],\n",
    "                       title=f\"Latent Space with Leiden Clusters\",\n",
    "                       ax=axs[0],\n",
    "                       show=False)\n",
    "            sq.pl.spatial_scatter(adata=adata,\n",
    "                                  color=[f\"latent_{model_name}_leiden_{str(leiden_resolution)}\"],\n",
    "                                  title=f\"Physical Space with Leiden Clusters\",\n",
    "                                  shape=None,\n",
    "                                  ax=axs[1])\n",
    "\n",
    "            # Create and position shared legend\n",
    "            handles, labels = axs[0].get_legend_handles_labels()\n",
    "            lgd = fig.legend(handles, labels, bbox_to_anchor=(1.25, 0.9185))\n",
    "            axs[0].get_legend().remove()\n",
    "            axs[1].get_legend().remove()\n",
    "\n",
    "            # Adjust, save and display plot\n",
    "            plt.subplots_adjust(wspace=0, hspace=0.2)\n",
    "            fig.savefig(f\"{dataset_figure_folder_path}/latent_physical_comparison_\"\n",
    "                        f\"{model_name}_run{run_number}.png\",\n",
    "                        bbox_extra_artists=(lgd, title),\n",
    "                        bbox_inches=\"tight\")\n",
    "            plt.show()\n",
    "        \n",
    "        # Store latent representation\n",
    "        adata_new.obsm[latent_key + f\"_run{run_number}\"] = adata.obsm[latent_key]\n",
    "        \n",
    "        # Use latent representation for UMAP generation\n",
    "        sc.pp.neighbors(adata_new,\n",
    "                        use_rep=f\"{latent_key}_run{run_number}\",\n",
    "                        key_added=f\"{latent_key}_run{run_number}\")\n",
    "        sc.tl.umap(adata_new,\n",
    "                   neighbors_key=f\"{latent_key}_run{run_number}\")\n",
    "        adata_new.obsm[f\"{latent_key}_run{run_number}_X_umap\"] = adata_new.obsm[\"X_umap\"]\n",
    "        del(adata_new.obsm[\"X_umap\"])\n",
    "\n",
    "        # Store intermediate adata to disk\n",
    "        adata_new.write(f\"{srt_data_results_folder_path}/sample_integration_method_benchmarking/\"\n",
    "                        f\"{dataset}_{model_name}_sample_integration_method_benchmarking.h5ad\")  \n",
    "\n",
    "        # Free memory\n",
    "        del(adata)\n",
    "        del(model)\n",
    "        gc.collect()\n",
    "        \n",
    "    # Store final adata to disk\n",
    "    adata_new.write(f\"{srt_data_results_folder_path}/sample_integration_method_benchmarking/\"\n",
    "                    f\"{dataset}_{model_name}_sample_integration_method_benchmarking.h5ad\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e1609c-b40c-4bcc-addc-6065287ae21d",
   "metadata": {},
   "source": [
    "### 2.2 Train Models on Benchmarking Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a645699a-5fb8-4795-ae3d-071dd4e41f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scvi_models(dataset=\"seqfish_mouse_organogenesis\",\n",
    "                  reference_batches=[f\"batch{i}\" for i in range(1,7)],\n",
    "                  cell_type_key=\"celltype_mapped_refined\",\n",
    "                  adata_new=None,\n",
    "                  n_start_run=1,\n",
    "                  n_end_run=10,\n",
    "                  n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16, 20, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4181742c-41d1-46fe-8a7a-2e5f7c367984",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subsample_pct in [1, 5, 10, 25, 50]:\n",
    "    train_scvi_models(dataset=f\"seqfish_mouse_organogenesis_subsample_{subsample_pct}pct\",\n",
    "                      reference_batches=[f\"batch{i}\" for i in range(1,7)],\n",
    "                      cell_type_key=\"celltype_mapped_refined\",\n",
    "                      adata_new=None,\n",
    "                      n_start_run=1,\n",
    "                      n_end_run=10,\n",
    "                      n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16, 20, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3032c2f4-4721-458a-8870-41bc5fb1990f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scvi_models(dataset=\"starmap_plus_mouse_cns\",\n",
    "                  reference_batches=[f\"batch{i}\" for i in range(1,21)],\n",
    "                  cell_type_key=\"Main_molecular_cell_type\",\n",
    "                  adata_new=None,\n",
    "                  n_start_run=1,\n",
    "                  n_end_run=10,\n",
    "                  n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16, 20, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3324a416-4d74-40db-9a11-0921803a3a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Processing batch batch6...\n",
      "Loading data...\n",
      "Processing batch batch7...\n",
      "Loading data...\n",
      "Processing batch batch8...\n",
      "Loading data...\n",
      "Processing batch batch9...\n",
      "Loading data...\n",
      "Processing batch batch10...\n",
      "Loading data...\n",
      "Processing batch batch11...\n",
      "Loading data...\n",
      "Processing batch batch12...\n",
      "Loading data...\n",
      "Processing batch batch13...\n",
      "Loading data...\n",
      "Processing batch batch14...\n",
      "Loading data...\n",
      "Processing batch batch15...\n",
      "Loading data...\n",
      "Processing batch batch16...\n",
      "Loading data...\n",
      "Processing batch batch17...\n",
      "Loading data...\n",
      "Processing batch batch18...\n",
      "Loading data...\n",
      "Processing batch batch19...\n",
      "Loading data...\n",
      "Processing batch batch20...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [02:23<00:00,  2.80it/s, loss=284, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [02:23<00:00,  2.80it/s, loss=284, v_num=1]\n",
      "Duration of model training in run 1: 0 hours, 2 minutes and 23 seconds.\n",
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Processing batch batch6...\n",
      "Loading data...\n",
      "Processing batch batch7...\n",
      "Loading data...\n",
      "Processing batch batch8...\n",
      "Loading data...\n",
      "Processing batch batch9...\n",
      "Loading data...\n",
      "Processing batch batch10...\n",
      "Loading data...\n",
      "Processing batch batch11...\n",
      "Loading data...\n",
      "Processing batch batch12...\n",
      "Loading data...\n",
      "Processing batch batch13...\n",
      "Loading data...\n",
      "Processing batch batch14...\n",
      "Loading data...\n",
      "Processing batch batch15...\n",
      "Loading data...\n",
      "Processing batch batch16...\n",
      "Loading data...\n",
      "Processing batch batch17...\n",
      "Loading data...\n",
      "Processing batch batch18...\n",
      "Loading data...\n",
      "Processing batch batch19...\n",
      "Loading data...\n",
      "Processing batch batch20...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [02:26<00:00,  2.72it/s, loss=285, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [02:26<00:00,  2.73it/s, loss=285, v_num=1]\n",
      "Duration of model training in run 2: 0 hours, 2 minutes and 26 seconds.\n",
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Processing batch batch6...\n",
      "Loading data...\n",
      "Processing batch batch7...\n",
      "Loading data...\n",
      "Processing batch batch8...\n",
      "Loading data...\n",
      "Processing batch batch9...\n",
      "Loading data...\n",
      "Processing batch batch10...\n",
      "Loading data...\n",
      "Processing batch batch11...\n",
      "Loading data...\n",
      "Processing batch batch12...\n",
      "Loading data...\n",
      "Processing batch batch13...\n",
      "Loading data...\n",
      "Processing batch batch14...\n",
      "Loading data...\n",
      "Processing batch batch15...\n",
      "Loading data...\n",
      "Processing batch batch16...\n",
      "Loading data...\n",
      "Processing batch batch17...\n",
      "Loading data...\n",
      "Processing batch batch18...\n",
      "Loading data...\n",
      "Processing batch batch19...\n",
      "Loading data...\n",
      "Processing batch batch20...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 2\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [02:27<00:00,  2.71it/s, loss=283, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [02:27<00:00,  2.72it/s, loss=283, v_num=1]\n",
      "Duration of model training in run 3: 0 hours, 2 minutes and 27 seconds.\n",
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Processing batch batch6...\n",
      "Loading data...\n",
      "Processing batch batch7...\n",
      "Loading data...\n",
      "Processing batch batch8...\n",
      "Loading data...\n",
      "Processing batch batch9...\n",
      "Loading data...\n",
      "Processing batch batch10...\n",
      "Loading data...\n",
      "Processing batch batch11...\n",
      "Loading data...\n",
      "Processing batch batch12...\n",
      "Loading data...\n",
      "Processing batch batch13...\n",
      "Loading data...\n",
      "Processing batch batch14...\n",
      "Loading data...\n",
      "Processing batch batch15...\n",
      "Loading data...\n",
      "Processing batch batch16...\n",
      "Loading data...\n",
      "Processing batch batch17...\n",
      "Loading data...\n",
      "Processing batch batch18...\n",
      "Loading data...\n",
      "Processing batch batch19...\n",
      "Loading data...\n",
      "Processing batch batch20...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 3\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [02:26<00:00,  2.73it/s, loss=282, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [02:26<00:00,  2.73it/s, loss=282, v_num=1]\n",
      "Duration of model training in run 4: 0 hours, 2 minutes and 26 seconds.\n",
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Processing batch batch6...\n",
      "Loading data...\n",
      "Processing batch batch7...\n",
      "Loading data...\n",
      "Processing batch batch8...\n",
      "Loading data...\n",
      "Processing batch batch9...\n",
      "Loading data...\n",
      "Processing batch batch10...\n",
      "Loading data...\n",
      "Processing batch batch11...\n",
      "Loading data...\n",
      "Processing batch batch12...\n",
      "Loading data...\n",
      "Processing batch batch13...\n",
      "Loading data...\n",
      "Processing batch batch14...\n",
      "Loading data...\n",
      "Processing batch batch15...\n",
      "Loading data...\n",
      "Processing batch batch16...\n",
      "Loading data...\n",
      "Processing batch batch17...\n",
      "Loading data...\n",
      "Processing batch batch18...\n",
      "Loading data...\n",
      "Processing batch batch19...\n",
      "Loading data...\n",
      "Processing batch batch20...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 4\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [02:26<00:00,  2.72it/s, loss=288, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [02:26<00:00,  2.73it/s, loss=288, v_num=1]\n",
      "Duration of model training in run 5: 0 hours, 2 minutes and 26 seconds.\n",
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Processing batch batch6...\n",
      "Loading data...\n",
      "Processing batch batch7...\n",
      "Loading data...\n",
      "Processing batch batch8...\n",
      "Loading data...\n",
      "Processing batch batch9...\n",
      "Loading data...\n",
      "Processing batch batch10...\n",
      "Loading data...\n",
      "Processing batch batch11...\n",
      "Loading data...\n",
      "Processing batch batch12...\n",
      "Loading data...\n",
      "Processing batch batch13...\n",
      "Loading data...\n",
      "Processing batch batch14...\n",
      "Loading data...\n",
      "Processing batch batch15...\n",
      "Loading data...\n",
      "Processing batch batch16...\n",
      "Loading data...\n",
      "Processing batch batch17...\n",
      "Loading data...\n",
      "Processing batch batch18...\n",
      "Loading data...\n",
      "Processing batch batch19...\n",
      "Loading data...\n",
      "Processing batch batch20...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 5\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [02:27<00:00,  2.65it/s, loss=284, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [02:27<00:00,  2.71it/s, loss=284, v_num=1]\n",
      "Duration of model training in run 6: 0 hours, 2 minutes and 27 seconds.\n",
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Processing batch batch6...\n",
      "Loading data...\n",
      "Processing batch batch7...\n",
      "Loading data...\n",
      "Processing batch batch8...\n",
      "Loading data...\n",
      "Processing batch batch9...\n",
      "Loading data...\n",
      "Processing batch batch10...\n",
      "Loading data...\n",
      "Processing batch batch11...\n",
      "Loading data...\n",
      "Processing batch batch12...\n",
      "Loading data...\n",
      "Processing batch batch13...\n",
      "Loading data...\n",
      "Processing batch batch14...\n",
      "Loading data...\n",
      "Processing batch batch15...\n",
      "Loading data...\n",
      "Processing batch batch16...\n",
      "Loading data...\n",
      "Processing batch batch17...\n",
      "Loading data...\n",
      "Processing batch batch18...\n",
      "Loading data...\n",
      "Processing batch batch19...\n",
      "Loading data...\n",
      "Processing batch batch20...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 6\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [02:29<00:00,  2.67it/s, loss=286, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [02:29<00:00,  2.68it/s, loss=286, v_num=1]\n",
      "Duration of model training in run 7: 0 hours, 2 minutes and 29 seconds.\n",
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Processing batch batch6...\n",
      "Loading data...\n",
      "Processing batch batch7...\n",
      "Loading data...\n",
      "Processing batch batch8...\n",
      "Loading data...\n",
      "Processing batch batch9...\n",
      "Loading data...\n",
      "Processing batch batch10...\n",
      "Loading data...\n",
      "Processing batch batch11...\n",
      "Loading data...\n",
      "Processing batch batch12...\n",
      "Loading data...\n",
      "Processing batch batch13...\n",
      "Loading data...\n",
      "Processing batch batch14...\n",
      "Loading data...\n",
      "Processing batch batch15...\n",
      "Loading data...\n",
      "Processing batch batch16...\n",
      "Loading data...\n",
      "Processing batch batch17...\n",
      "Loading data...\n",
      "Processing batch batch18...\n",
      "Loading data...\n",
      "Processing batch batch19...\n",
      "Loading data...\n",
      "Processing batch batch20...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 7\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [02:27<00:00,  2.73it/s, loss=282, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [02:27<00:00,  2.71it/s, loss=282, v_num=1]\n",
      "Duration of model training in run 8: 0 hours, 2 minutes and 27 seconds.\n",
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Processing batch batch6...\n",
      "Loading data...\n",
      "Processing batch batch7...\n",
      "Loading data...\n",
      "Processing batch batch8...\n",
      "Loading data...\n",
      "Processing batch batch9...\n",
      "Loading data...\n",
      "Processing batch batch10...\n",
      "Loading data...\n",
      "Processing batch batch11...\n",
      "Loading data...\n",
      "Processing batch batch12...\n",
      "Loading data...\n",
      "Processing batch batch13...\n",
      "Loading data...\n",
      "Processing batch batch14...\n",
      "Loading data...\n",
      "Processing batch batch15...\n",
      "Loading data...\n",
      "Processing batch batch16...\n",
      "Loading data...\n",
      "Processing batch batch17...\n",
      "Loading data...\n",
      "Processing batch batch18...\n",
      "Loading data...\n",
      "Processing batch batch19...\n",
      "Loading data...\n",
      "Processing batch batch20...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 8\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [02:26<00:00,  2.73it/s, loss=282, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [02:26<00:00,  2.72it/s, loss=282, v_num=1]\n",
      "Duration of model training in run 9: 0 hours, 2 minutes and 27 seconds.\n",
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Processing batch batch6...\n",
      "Loading data...\n",
      "Processing batch batch7...\n",
      "Loading data...\n",
      "Processing batch batch8...\n",
      "Loading data...\n",
      "Processing batch batch9...\n",
      "Loading data...\n",
      "Processing batch batch10...\n",
      "Loading data...\n",
      "Processing batch batch11...\n",
      "Loading data...\n",
      "Processing batch batch12...\n",
      "Loading data...\n",
      "Processing batch batch13...\n",
      "Loading data...\n",
      "Processing batch batch14...\n",
      "Loading data...\n",
      "Processing batch batch15...\n",
      "Loading data...\n",
      "Processing batch batch16...\n",
      "Loading data...\n",
      "Processing batch batch17...\n",
      "Loading data...\n",
      "Processing batch batch18...\n",
      "Loading data...\n",
      "Processing batch batch19...\n",
      "Loading data...\n",
      "Processing batch batch20...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 9\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [02:27<00:00,  2.72it/s, loss=282, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [02:27<00:00,  2.72it/s, loss=282, v_num=1]\n",
      "Duration of model training in run 10: 0 hours, 2 minutes and 27 seconds.\n",
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Processing batch batch6...\n",
      "Loading data...\n",
      "Processing batch batch7...\n",
      "Loading data...\n",
      "Processing batch batch8...\n",
      "Loading data...\n",
      "Processing batch batch9...\n",
      "Loading data...\n",
      "Processing batch batch10...\n",
      "Loading data...\n",
      "Processing batch batch11...\n",
      "Loading data...\n",
      "Processing batch batch12...\n",
      "Loading data...\n",
      "Processing batch batch13...\n",
      "Loading data...\n",
      "Processing batch batch14...\n",
      "Loading data...\n",
      "Processing batch batch15...\n",
      "Loading data...\n",
      "Processing batch batch16...\n",
      "Loading data...\n",
      "Processing batch batch17...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch batch18...\n",
      "Loading data...\n",
      "Processing batch batch19...\n",
      "Loading data...\n",
      "Processing batch batch20...\n",
      "Loading data...\n",
      "Epoch 147/147: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 147/147 [04:30<00:00,  1.84s/it, loss=289, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=147` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/147: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 147/147 [04:30<00:00,  1.84s/it, loss=289, v_num=1]\n",
      "Duration of model training in run 1: 0 hours, 4 minutes and 30 seconds.\n",
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Processing batch batch6...\n",
      "Loading data...\n",
      "Processing batch batch7...\n",
      "Loading data...\n",
      "Processing batch batch8...\n",
      "Loading data...\n",
      "Processing batch batch9...\n",
      "Loading data...\n",
      "Processing batch batch10...\n",
      "Loading data...\n",
      "Processing batch batch11...\n",
      "Loading data...\n",
      "Processing batch batch12...\n",
      "Loading data...\n",
      "Processing batch batch13...\n",
      "Loading data...\n",
      "Processing batch batch14...\n",
      "Loading data...\n",
      "Processing batch batch15...\n",
      "Loading data...\n",
      "Processing batch batch16...\n",
      "Loading data...\n",
      "Processing batch batch17...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch batch18...\n",
      "Loading data...\n",
      "Processing batch batch19...\n",
      "Loading data...\n",
      "Processing batch batch20...\n",
      "Loading data...\n",
      "Epoch 147/147: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 147/147 [04:30<00:00,  1.83s/it, loss=288, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=147` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/147: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 147/147 [04:30<00:00,  1.84s/it, loss=288, v_num=1]\n",
      "Duration of model training in run 2: 0 hours, 4 minutes and 30 seconds.\n",
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Processing batch batch6...\n",
      "Loading data...\n",
      "Processing batch batch7...\n",
      "Loading data...\n",
      "Processing batch batch8...\n",
      "Loading data...\n",
      "Processing batch batch9...\n",
      "Loading data...\n",
      "Processing batch batch10...\n",
      "Loading data...\n",
      "Processing batch batch11...\n",
      "Loading data...\n",
      "Processing batch batch12...\n",
      "Loading data...\n",
      "Processing batch batch13...\n",
      "Loading data...\n",
      "Processing batch batch14...\n",
      "Loading data...\n",
      "Processing batch batch15...\n",
      "Loading data...\n",
      "Processing batch batch16...\n",
      "Loading data...\n",
      "Processing batch batch17...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 2\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch batch18...\n",
      "Loading data...\n",
      "Processing batch batch19...\n",
      "Loading data...\n",
      "Processing batch batch20...\n",
      "Loading data...\n",
      "Epoch 147/147: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 147/147 [04:29<00:00,  1.83s/it, loss=290, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=147` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/147: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 147/147 [04:29<00:00,  1.83s/it, loss=290, v_num=1]\n",
      "Duration of model training in run 3: 0 hours, 4 minutes and 29 seconds.\n",
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Processing batch batch6...\n",
      "Loading data...\n",
      "Processing batch batch7...\n",
      "Loading data...\n",
      "Processing batch batch8...\n",
      "Loading data...\n",
      "Processing batch batch9...\n",
      "Loading data...\n",
      "Processing batch batch10...\n",
      "Loading data...\n",
      "Processing batch batch11...\n",
      "Loading data...\n",
      "Processing batch batch12...\n",
      "Loading data...\n",
      "Processing batch batch13...\n",
      "Loading data...\n",
      "Processing batch batch14...\n",
      "Loading data...\n",
      "Processing batch batch15...\n",
      "Loading data...\n",
      "Processing batch batch16...\n",
      "Loading data...\n",
      "Processing batch batch17...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 3\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch batch18...\n",
      "Loading data...\n",
      "Processing batch batch19...\n",
      "Loading data...\n",
      "Processing batch batch20...\n",
      "Loading data...\n",
      "Epoch 147/147: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 147/147 [04:29<00:00,  1.83s/it, loss=286, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=147` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/147: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 147/147 [04:29<00:00,  1.83s/it, loss=286, v_num=1]\n",
      "Duration of model training in run 4: 0 hours, 4 minutes and 29 seconds.\n",
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Processing batch batch6...\n",
      "Loading data...\n",
      "Processing batch batch7...\n",
      "Loading data...\n",
      "Processing batch batch8...\n",
      "Loading data...\n",
      "Processing batch batch9...\n",
      "Loading data...\n",
      "Processing batch batch10...\n",
      "Loading data...\n",
      "Processing batch batch11...\n",
      "Loading data...\n",
      "Processing batch batch12...\n",
      "Loading data...\n",
      "Processing batch batch13...\n",
      "Loading data...\n",
      "Processing batch batch14...\n",
      "Loading data...\n",
      "Processing batch batch15...\n",
      "Loading data...\n",
      "Processing batch batch16...\n",
      "Loading data...\n",
      "Processing batch batch17...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 4\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch batch18...\n",
      "Loading data...\n",
      "Processing batch batch19...\n",
      "Loading data...\n",
      "Processing batch batch20...\n",
      "Loading data...\n",
      "Epoch 147/147: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 147/147 [04:29<00:00,  1.83s/it, loss=294, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=147` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/147: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 147/147 [04:29<00:00,  1.83s/it, loss=294, v_num=1]\n",
      "Duration of model training in run 5: 0 hours, 4 minutes and 29 seconds.\n",
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Processing batch batch6...\n",
      "Loading data...\n",
      "Processing batch batch7...\n",
      "Loading data...\n",
      "Processing batch batch8...\n",
      "Loading data...\n",
      "Processing batch batch9...\n",
      "Loading data...\n",
      "Processing batch batch10...\n",
      "Loading data...\n",
      "Processing batch batch11...\n",
      "Loading data...\n",
      "Processing batch batch12...\n",
      "Loading data...\n",
      "Processing batch batch13...\n",
      "Loading data...\n",
      "Processing batch batch14...\n",
      "Loading data...\n",
      "Processing batch batch15...\n",
      "Loading data...\n",
      "Processing batch batch16...\n",
      "Loading data...\n",
      "Processing batch batch17...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 5\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch batch18...\n",
      "Loading data...\n",
      "Processing batch batch19...\n",
      "Loading data...\n",
      "Processing batch batch20...\n",
      "Loading data...\n",
      "Epoch 147/147: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 147/147 [04:29<00:00,  1.83s/it, loss=287, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=147` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/147: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 147/147 [04:29<00:00,  1.83s/it, loss=287, v_num=1]\n",
      "Duration of model training in run 6: 0 hours, 4 minutes and 29 seconds.\n",
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Processing batch batch6...\n",
      "Loading data...\n",
      "Processing batch batch7...\n",
      "Loading data...\n",
      "Processing batch batch8...\n",
      "Loading data...\n",
      "Processing batch batch9...\n",
      "Loading data...\n",
      "Processing batch batch10...\n",
      "Loading data...\n",
      "Processing batch batch11...\n",
      "Loading data...\n",
      "Processing batch batch12...\n",
      "Loading data...\n",
      "Processing batch batch13...\n",
      "Loading data...\n",
      "Processing batch batch14...\n",
      "Loading data...\n",
      "Processing batch batch15...\n",
      "Loading data...\n",
      "Processing batch batch16...\n",
      "Loading data...\n",
      "Processing batch batch17...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 6\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch batch18...\n",
      "Loading data...\n",
      "Processing batch batch19...\n",
      "Loading data...\n",
      "Processing batch batch20...\n",
      "Loading data...\n",
      "Epoch 147/147: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 147/147 [04:29<00:00,  1.83s/it, loss=289, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=147` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/147: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 147/147 [04:29<00:00,  1.83s/it, loss=289, v_num=1]\n",
      "Duration of model training in run 7: 0 hours, 4 minutes and 29 seconds.\n",
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Processing batch batch6...\n",
      "Loading data...\n",
      "Processing batch batch7...\n",
      "Loading data...\n",
      "Processing batch batch8...\n",
      "Loading data...\n",
      "Processing batch batch9...\n",
      "Loading data...\n",
      "Processing batch batch10...\n",
      "Loading data...\n",
      "Processing batch batch11...\n",
      "Loading data...\n",
      "Processing batch batch12...\n",
      "Loading data...\n",
      "Processing batch batch13...\n",
      "Loading data...\n",
      "Processing batch batch14...\n",
      "Loading data...\n",
      "Processing batch batch15...\n",
      "Loading data...\n",
      "Processing batch batch16...\n",
      "Loading data...\n",
      "Processing batch batch17...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 7\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch batch18...\n",
      "Loading data...\n",
      "Processing batch batch19...\n",
      "Loading data...\n",
      "Processing batch batch20...\n",
      "Loading data...\n",
      "Epoch 147/147: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 147/147 [04:29<00:00,  1.83s/it, loss=298, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=147` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/147: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 147/147 [04:29<00:00,  1.83s/it, loss=298, v_num=1]\n",
      "Duration of model training in run 8: 0 hours, 4 minutes and 29 seconds.\n",
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Processing batch batch6...\n",
      "Loading data...\n",
      "Processing batch batch7...\n",
      "Loading data...\n",
      "Processing batch batch8...\n",
      "Loading data...\n",
      "Processing batch batch9...\n",
      "Loading data...\n",
      "Processing batch batch10...\n",
      "Loading data...\n",
      "Processing batch batch11...\n",
      "Loading data...\n",
      "Processing batch batch12...\n",
      "Loading data...\n",
      "Processing batch batch13...\n",
      "Loading data...\n",
      "Processing batch batch14...\n",
      "Loading data...\n",
      "Processing batch batch15...\n",
      "Loading data...\n",
      "Processing batch batch16...\n",
      "Loading data...\n",
      "Processing batch batch17...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 8\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch batch18...\n",
      "Loading data...\n",
      "Processing batch batch19...\n",
      "Loading data...\n",
      "Processing batch batch20...\n",
      "Loading data...\n",
      "Epoch 147/147: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 147/147 [04:29<00:00,  1.83s/it, loss=288, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=147` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/147: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 147/147 [04:29<00:00,  1.83s/it, loss=288, v_num=1]\n",
      "Duration of model training in run 9: 0 hours, 4 minutes and 29 seconds.\n",
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Processing batch batch6...\n",
      "Loading data...\n",
      "Processing batch batch7...\n",
      "Loading data...\n",
      "Processing batch batch8...\n",
      "Loading data...\n",
      "Processing batch batch9...\n",
      "Loading data...\n",
      "Processing batch batch10...\n",
      "Loading data...\n",
      "Processing batch batch11...\n",
      "Loading data...\n",
      "Processing batch batch12...\n",
      "Loading data...\n",
      "Processing batch batch13...\n",
      "Loading data...\n",
      "Processing batch batch14...\n",
      "Loading data...\n",
      "Processing batch batch15...\n",
      "Loading data...\n",
      "Processing batch batch16...\n",
      "Loading data...\n",
      "Processing batch batch17...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 9\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch batch18...\n",
      "Loading data...\n",
      "Processing batch batch19...\n",
      "Loading data...\n",
      "Processing batch batch20...\n",
      "Loading data...\n",
      "Epoch 147/147: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 147/147 [04:30<00:00,  1.84s/it, loss=292, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=147` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/147: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 147/147 [04:30<00:00,  1.84s/it, loss=292, v_num=1]\n",
      "Duration of model training in run 10: 0 hours, 4 minutes and 31 seconds.\n",
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Processing batch batch6...\n",
      "Loading data...\n",
      "Processing batch batch7...\n",
      "Loading data...\n",
      "Processing batch batch8...\n",
      "Loading data...\n",
      "Processing batch batch9...\n",
      "Loading data...\n",
      "Processing batch batch10...\n",
      "Loading data...\n",
      "Processing batch batch11...\n",
      "Loading data...\n",
      "Processing batch batch12...\n",
      "Loading data...\n",
      "Processing batch batch13...\n",
      "Loading data...\n",
      "Processing batch batch14...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch batch15...\n",
      "Loading data...\n",
      "Processing batch batch16...\n",
      "Loading data...\n",
      "Processing batch batch17...\n",
      "Loading data...\n",
      "Processing batch batch18...\n",
      "Loading data...\n",
      "Processing batch batch19...\n",
      "Loading data...\n",
      "Processing batch batch20...\n",
      "Loading data...\n",
      "Epoch 73/73: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 73/73 [04:26<00:00,  3.65s/it, loss=281, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=73` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/73: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 73/73 [04:26<00:00,  3.65s/it, loss=281, v_num=1]\n",
      "Duration of model training in run 1: 0 hours, 4 minutes and 26 seconds.\n",
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Processing batch batch6...\n",
      "Loading data...\n",
      "Processing batch batch7...\n",
      "Loading data...\n",
      "Processing batch batch8...\n",
      "Loading data...\n",
      "Processing batch batch9...\n",
      "Loading data...\n",
      "Processing batch batch10...\n",
      "Loading data...\n",
      "Processing batch batch11...\n",
      "Loading data...\n",
      "Processing batch batch12...\n",
      "Loading data...\n",
      "Processing batch batch13...\n",
      "Loading data...\n",
      "Processing batch batch14...\n",
      "Loading data...\n",
      "Processing batch batch15...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch batch16...\n",
      "Loading data...\n",
      "Processing batch batch17...\n",
      "Loading data...\n",
      "Processing batch batch18...\n",
      "Loading data...\n",
      "Processing batch batch19...\n",
      "Loading data...\n",
      "Processing batch batch20...\n",
      "Loading data...\n",
      "Epoch 73/73: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 73/73 [04:26<00:00,  3.64s/it, loss=294, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=73` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/73: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 73/73 [04:26<00:00,  3.65s/it, loss=294, v_num=1]\n",
      "Duration of model training in run 2: 0 hours, 4 minutes and 26 seconds.\n",
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Processing batch batch6...\n",
      "Loading data...\n",
      "Processing batch batch7...\n",
      "Loading data...\n",
      "Processing batch batch8...\n",
      "Loading data...\n",
      "Processing batch batch9...\n",
      "Loading data...\n",
      "Processing batch batch10...\n",
      "Loading data...\n",
      "Processing batch batch11...\n",
      "Loading data...\n",
      "Processing batch batch12...\n",
      "Loading data...\n",
      "Processing batch batch13...\n",
      "Loading data...\n",
      "Processing batch batch14...\n",
      "Loading data...\n",
      "Processing batch batch15...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 2\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch batch16...\n",
      "Loading data...\n",
      "Processing batch batch17...\n",
      "Loading data...\n",
      "Processing batch batch18...\n",
      "Loading data...\n",
      "Processing batch batch19...\n",
      "Loading data...\n",
      "Processing batch batch20...\n",
      "Loading data...\n",
      "Epoch 73/73: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 73/73 [04:25<00:00,  3.64s/it, loss=295, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=73` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/73: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 73/73 [04:25<00:00,  3.64s/it, loss=295, v_num=1]\n",
      "Duration of model training in run 3: 0 hours, 4 minutes and 26 seconds.\n",
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Processing batch batch6...\n",
      "Loading data...\n",
      "Processing batch batch7...\n",
      "Loading data...\n",
      "Processing batch batch8...\n",
      "Loading data...\n",
      "Processing batch batch9...\n",
      "Loading data...\n",
      "Processing batch batch10...\n",
      "Loading data...\n",
      "Processing batch batch11...\n",
      "Loading data...\n",
      "Processing batch batch12...\n",
      "Loading data...\n",
      "Processing batch batch13...\n",
      "Loading data...\n",
      "Processing batch batch14...\n",
      "Loading data...\n",
      "Processing batch batch15...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 3\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch batch16...\n",
      "Loading data...\n",
      "Processing batch batch17...\n",
      "Loading data...\n",
      "Processing batch batch18...\n",
      "Loading data...\n",
      "Processing batch batch19...\n",
      "Loading data...\n",
      "Processing batch batch20...\n",
      "Loading data...\n",
      "Epoch 73/73: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 73/73 [04:25<00:00,  3.64s/it, loss=290, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=73` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/73: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 73/73 [04:25<00:00,  3.63s/it, loss=290, v_num=1]\n",
      "Duration of model training in run 4: 0 hours, 4 minutes and 25 seconds.\n",
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Processing batch batch6...\n",
      "Loading data...\n",
      "Processing batch batch7...\n",
      "Loading data...\n",
      "Processing batch batch8...\n",
      "Loading data...\n",
      "Processing batch batch9...\n",
      "Loading data...\n",
      "Processing batch batch10...\n",
      "Loading data...\n",
      "Processing batch batch11...\n",
      "Loading data...\n",
      "Processing batch batch12...\n",
      "Loading data...\n",
      "Processing batch batch13...\n",
      "Loading data...\n",
      "Processing batch batch14...\n",
      "Loading data...\n",
      "Processing batch batch15...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 4\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch batch16...\n",
      "Loading data...\n",
      "Processing batch batch17...\n",
      "Loading data...\n",
      "Processing batch batch18...\n",
      "Loading data...\n",
      "Processing batch batch19...\n",
      "Loading data...\n",
      "Processing batch batch20...\n",
      "Loading data...\n",
      "Epoch 73/73: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 73/73 [04:25<00:00,  3.64s/it, loss=287, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=73` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/73: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 73/73 [04:25<00:00,  3.63s/it, loss=287, v_num=1]\n",
      "Duration of model training in run 5: 0 hours, 4 minutes and 25 seconds.\n",
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Processing batch batch6...\n",
      "Loading data...\n",
      "Processing batch batch7...\n",
      "Loading data...\n",
      "Processing batch batch8...\n",
      "Loading data...\n",
      "Processing batch batch9...\n",
      "Loading data...\n",
      "Processing batch batch10...\n",
      "Loading data...\n",
      "Processing batch batch11...\n",
      "Loading data...\n",
      "Processing batch batch12...\n",
      "Loading data...\n",
      "Processing batch batch13...\n",
      "Loading data...\n",
      "Processing batch batch14...\n",
      "Loading data...\n",
      "Processing batch batch15...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 5\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch batch16...\n",
      "Loading data...\n",
      "Processing batch batch17...\n",
      "Loading data...\n",
      "Processing batch batch18...\n",
      "Loading data...\n",
      "Processing batch batch19...\n",
      "Loading data...\n",
      "Processing batch batch20...\n",
      "Loading data...\n",
      "Epoch 73/73: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 73/73 [04:25<00:00,  3.63s/it, loss=292, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=73` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/73: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 73/73 [04:25<00:00,  3.63s/it, loss=292, v_num=1]\n",
      "Duration of model training in run 6: 0 hours, 4 minutes and 25 seconds.\n",
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Processing batch batch6...\n",
      "Loading data...\n",
      "Processing batch batch7...\n",
      "Loading data...\n",
      "Processing batch batch8...\n",
      "Loading data...\n",
      "Processing batch batch9...\n",
      "Loading data...\n",
      "Processing batch batch10...\n",
      "Loading data...\n",
      "Processing batch batch11...\n",
      "Loading data...\n",
      "Processing batch batch12...\n",
      "Loading data...\n",
      "Processing batch batch13...\n",
      "Loading data...\n",
      "Processing batch batch14...\n",
      "Loading data...\n",
      "Processing batch batch15...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 6\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch batch16...\n",
      "Loading data...\n",
      "Processing batch batch17...\n",
      "Loading data...\n",
      "Processing batch batch18...\n",
      "Loading data...\n",
      "Processing batch batch19...\n",
      "Loading data...\n",
      "Processing batch batch20...\n",
      "Loading data...\n",
      "Epoch 73/73: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 73/73 [04:25<00:00,  3.63s/it, loss=284, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=73` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/73: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 73/73 [04:25<00:00,  3.64s/it, loss=284, v_num=1]\n",
      "Duration of model training in run 7: 0 hours, 4 minutes and 26 seconds.\n",
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Processing batch batch6...\n",
      "Loading data...\n",
      "Processing batch batch7...\n",
      "Loading data...\n",
      "Processing batch batch8...\n",
      "Loading data...\n",
      "Processing batch batch9...\n",
      "Loading data...\n",
      "Processing batch batch10...\n",
      "Loading data...\n",
      "Processing batch batch11...\n",
      "Loading data...\n",
      "Processing batch batch12...\n",
      "Loading data...\n",
      "Processing batch batch13...\n",
      "Loading data...\n",
      "Processing batch batch14...\n",
      "Loading data...\n",
      "Processing batch batch15...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 7\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch batch16...\n",
      "Loading data...\n",
      "Processing batch batch17...\n",
      "Loading data...\n",
      "Processing batch batch18...\n",
      "Loading data...\n",
      "Processing batch batch19...\n",
      "Loading data...\n",
      "Processing batch batch20...\n",
      "Loading data...\n",
      "Epoch 73/73: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 73/73 [04:25<00:00,  3.64s/it, loss=294, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=73` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/73: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 73/73 [04:25<00:00,  3.63s/it, loss=294, v_num=1]\n",
      "Duration of model training in run 8: 0 hours, 4 minutes and 25 seconds.\n",
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Processing batch batch6...\n",
      "Loading data...\n",
      "Processing batch batch7...\n",
      "Loading data...\n",
      "Processing batch batch8...\n",
      "Loading data...\n",
      "Processing batch batch9...\n",
      "Loading data...\n",
      "Processing batch batch10...\n",
      "Loading data...\n",
      "Processing batch batch11...\n",
      "Loading data...\n",
      "Processing batch batch12...\n",
      "Loading data...\n",
      "Processing batch batch13...\n",
      "Loading data...\n",
      "Processing batch batch14...\n",
      "Loading data...\n",
      "Processing batch batch15...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 8\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch batch16...\n",
      "Loading data...\n",
      "Processing batch batch17...\n",
      "Loading data...\n",
      "Processing batch batch18...\n",
      "Loading data...\n",
      "Processing batch batch19...\n",
      "Loading data...\n",
      "Processing batch batch20...\n",
      "Loading data...\n",
      "Epoch 73/73: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 73/73 [04:27<00:00,  3.74s/it, loss=283, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=73` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/73: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 73/73 [04:27<00:00,  3.66s/it, loss=283, v_num=1]\n",
      "Duration of model training in run 9: 0 hours, 4 minutes and 27 seconds.\n",
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Processing batch batch6...\n",
      "Loading data...\n",
      "Processing batch batch7...\n",
      "Loading data...\n",
      "Processing batch batch8...\n",
      "Loading data...\n",
      "Processing batch batch9...\n",
      "Loading data...\n",
      "Processing batch batch10...\n",
      "Loading data...\n",
      "Processing batch batch11...\n",
      "Loading data...\n",
      "Processing batch batch12...\n",
      "Loading data...\n",
      "Processing batch batch13...\n",
      "Loading data...\n",
      "Processing batch batch14...\n",
      "Loading data...\n",
      "Processing batch batch15...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 9\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch batch16...\n",
      "Loading data...\n",
      "Processing batch batch17...\n",
      "Loading data...\n",
      "Processing batch batch18...\n",
      "Loading data...\n",
      "Processing batch batch19...\n",
      "Loading data...\n",
      "Processing batch batch20...\n",
      "Loading data...\n",
      "Epoch 73/73: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 73/73 [04:31<00:00,  3.62s/it, loss=288, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=73` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/73: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 73/73 [04:31<00:00,  3.72s/it, loss=288, v_num=1]\n",
      "Duration of model training in run 10: 0 hours, 4 minutes and 32 seconds.\n",
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Processing batch batch6...\n",
      "Loading data...\n",
      "Processing batch batch7...\n",
      "Loading data...\n",
      "Processing batch batch8...\n",
      "Loading data...\n",
      "Processing batch batch9...\n",
      "Loading data...\n",
      "Processing batch batch10...\n",
      "Loading data...\n",
      "Processing batch batch11...\n",
      "Loading data...\n",
      "Processing batch batch12...\n",
      "Loading data...\n",
      "Processing batch batch13...\n",
      "Loading data...\n",
      "Processing batch batch14...\n",
      "Loading data...\n",
      "Processing batch batch15...\n",
      "Loading data...\n",
      "Processing batch batch16...\n",
      "Loading data...\n",
      "Processing batch batch17...\n",
      "Loading data...\n",
      "Processing batch batch18...\n",
      "Loading data...\n",
      "Processing batch batch19...\n",
      "Loading data...\n",
      "Processing batch batch20...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/29: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [04:22<00:00,  9.07s/it, loss=283, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=29` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/29: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [04:22<00:00,  9.06s/it, loss=283, v_num=1]\n",
      "Duration of model training in run 1: 0 hours, 4 minutes and 24 seconds.\n",
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Processing batch batch6...\n",
      "Loading data...\n",
      "Processing batch batch7...\n",
      "Loading data...\n",
      "Processing batch batch8...\n",
      "Loading data...\n",
      "Processing batch batch9...\n",
      "Loading data...\n",
      "Processing batch batch10...\n",
      "Loading data...\n",
      "Processing batch batch11...\n",
      "Loading data...\n",
      "Processing batch batch12...\n",
      "Loading data...\n",
      "Processing batch batch13...\n",
      "Loading data...\n",
      "Processing batch batch14...\n",
      "Loading data...\n",
      "Processing batch batch15...\n",
      "Loading data...\n",
      "Processing batch batch16...\n",
      "Loading data...\n",
      "Processing batch batch17...\n",
      "Loading data...\n",
      "Processing batch batch18...\n",
      "Loading data...\n",
      "Processing batch batch19...\n",
      "Loading data...\n",
      "Processing batch batch20...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/29: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [04:24<00:00,  9.21s/it, loss=286, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=29` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/29: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [04:24<00:00,  9.12s/it, loss=286, v_num=1]\n",
      "Duration of model training in run 2: 0 hours, 4 minutes and 25 seconds.\n",
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Processing batch batch6...\n",
      "Loading data...\n",
      "Processing batch batch7...\n",
      "Loading data...\n",
      "Processing batch batch8...\n",
      "Loading data...\n",
      "Processing batch batch9...\n",
      "Loading data...\n",
      "Processing batch batch10...\n",
      "Loading data...\n",
      "Processing batch batch11...\n",
      "Loading data...\n",
      "Processing batch batch12...\n",
      "Loading data...\n",
      "Processing batch batch13...\n",
      "Loading data...\n",
      "Processing batch batch14...\n",
      "Loading data...\n",
      "Processing batch batch15...\n",
      "Loading data...\n",
      "Processing batch batch16...\n",
      "Loading data...\n",
      "Processing batch batch17...\n",
      "Loading data...\n",
      "Processing batch batch18...\n",
      "Loading data...\n",
      "Processing batch batch19...\n",
      "Loading data...\n",
      "Processing batch batch20...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 2\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/29: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [04:22<00:00,  9.08s/it, loss=287, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=29` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/29: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [04:22<00:00,  9.06s/it, loss=287, v_num=1]\n",
      "Duration of model training in run 3: 0 hours, 4 minutes and 24 seconds.\n",
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Processing batch batch6...\n",
      "Loading data...\n",
      "Processing batch batch7...\n",
      "Loading data...\n",
      "Processing batch batch8...\n",
      "Loading data...\n",
      "Processing batch batch9...\n",
      "Loading data...\n",
      "Processing batch batch10...\n",
      "Loading data...\n",
      "Processing batch batch11...\n",
      "Loading data...\n",
      "Processing batch batch12...\n",
      "Loading data...\n",
      "Processing batch batch13...\n",
      "Loading data...\n",
      "Processing batch batch14...\n",
      "Loading data...\n",
      "Processing batch batch15...\n",
      "Loading data...\n",
      "Processing batch batch16...\n",
      "Loading data...\n",
      "Processing batch batch17...\n",
      "Loading data...\n",
      "Processing batch batch18...\n",
      "Loading data...\n",
      "Processing batch batch19...\n",
      "Loading data...\n",
      "Processing batch batch20...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 3\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/29: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [04:21<00:00,  9.00s/it, loss=287, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=29` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/29: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [04:21<00:00,  9.02s/it, loss=287, v_num=1]\n",
      "Duration of model training in run 4: 0 hours, 4 minutes and 23 seconds.\n",
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Processing batch batch6...\n",
      "Loading data...\n",
      "Processing batch batch7...\n",
      "Loading data...\n",
      "Processing batch batch8...\n",
      "Loading data...\n",
      "Processing batch batch9...\n",
      "Loading data...\n",
      "Processing batch batch10...\n",
      "Loading data...\n",
      "Processing batch batch11...\n",
      "Loading data...\n",
      "Processing batch batch12...\n",
      "Loading data...\n",
      "Processing batch batch13...\n",
      "Loading data...\n",
      "Processing batch batch14...\n",
      "Loading data...\n",
      "Processing batch batch15...\n",
      "Loading data...\n",
      "Processing batch batch16...\n",
      "Loading data...\n",
      "Processing batch batch17...\n",
      "Loading data...\n",
      "Processing batch batch18...\n",
      "Loading data...\n",
      "Processing batch batch19...\n",
      "Loading data...\n",
      "Processing batch batch20...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 4\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/29: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [04:21<00:00,  9.04s/it, loss=287, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=29` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/29: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [04:21<00:00,  9.03s/it, loss=287, v_num=1]\n",
      "Duration of model training in run 5: 0 hours, 4 minutes and 23 seconds.\n",
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Processing batch batch6...\n",
      "Loading data...\n",
      "Processing batch batch7...\n",
      "Loading data...\n",
      "Processing batch batch8...\n",
      "Loading data...\n",
      "Processing batch batch9...\n",
      "Loading data...\n",
      "Processing batch batch10...\n",
      "Loading data...\n",
      "Processing batch batch11...\n",
      "Loading data...\n",
      "Processing batch batch12...\n",
      "Loading data...\n",
      "Processing batch batch13...\n",
      "Loading data...\n",
      "Processing batch batch14...\n",
      "Loading data...\n",
      "Processing batch batch15...\n",
      "Loading data...\n",
      "Processing batch batch16...\n",
      "Loading data...\n",
      "Processing batch batch17...\n",
      "Loading data...\n",
      "Processing batch batch18...\n",
      "Loading data...\n",
      "Processing batch batch19...\n",
      "Loading data...\n",
      "Processing batch batch20...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 5\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/29: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [04:21<00:00,  9.03s/it, loss=288, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=29` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/29: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [04:21<00:00,  9.02s/it, loss=288, v_num=1]\n",
      "Duration of model training in run 6: 0 hours, 4 minutes and 23 seconds.\n",
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Processing batch batch6...\n",
      "Loading data...\n",
      "Processing batch batch7...\n",
      "Loading data...\n",
      "Processing batch batch8...\n",
      "Loading data...\n",
      "Processing batch batch9...\n",
      "Loading data...\n",
      "Processing batch batch10...\n",
      "Loading data...\n",
      "Processing batch batch11...\n",
      "Loading data...\n",
      "Processing batch batch12...\n",
      "Loading data...\n",
      "Processing batch batch13...\n",
      "Loading data...\n",
      "Processing batch batch14...\n",
      "Loading data...\n",
      "Processing batch batch15...\n",
      "Loading data...\n",
      "Processing batch batch16...\n",
      "Loading data...\n",
      "Processing batch batch17...\n",
      "Loading data...\n",
      "Processing batch batch18...\n",
      "Loading data...\n",
      "Processing batch batch19...\n",
      "Loading data...\n",
      "Processing batch batch20...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 6\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/29: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [04:21<00:00,  9.03s/it, loss=284, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=29` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/29: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [04:21<00:00,  9.03s/it, loss=284, v_num=1]\n",
      "Duration of model training in run 7: 0 hours, 4 minutes and 23 seconds.\n",
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Processing batch batch6...\n",
      "Loading data...\n",
      "Processing batch batch7...\n",
      "Loading data...\n",
      "Processing batch batch8...\n",
      "Loading data...\n",
      "Processing batch batch9...\n",
      "Loading data...\n",
      "Processing batch batch10...\n",
      "Loading data...\n",
      "Processing batch batch11...\n",
      "Loading data...\n",
      "Processing batch batch12...\n",
      "Loading data...\n",
      "Processing batch batch13...\n",
      "Loading data...\n",
      "Processing batch batch14...\n",
      "Loading data...\n",
      "Processing batch batch15...\n",
      "Loading data...\n",
      "Processing batch batch16...\n",
      "Loading data...\n",
      "Processing batch batch17...\n",
      "Loading data...\n",
      "Processing batch batch18...\n",
      "Loading data...\n",
      "Processing batch batch19...\n",
      "Loading data...\n",
      "Processing batch batch20...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 7\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/29: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [04:21<00:00,  9.04s/it, loss=286, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=29` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/29: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [04:21<00:00,  9.03s/it, loss=286, v_num=1]\n",
      "Duration of model training in run 8: 0 hours, 4 minutes and 23 seconds.\n",
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Processing batch batch6...\n",
      "Loading data...\n",
      "Processing batch batch7...\n",
      "Loading data...\n",
      "Processing batch batch8...\n",
      "Loading data...\n",
      "Processing batch batch9...\n",
      "Loading data...\n",
      "Processing batch batch10...\n",
      "Loading data...\n",
      "Processing batch batch11...\n",
      "Loading data...\n",
      "Processing batch batch12...\n",
      "Loading data...\n",
      "Processing batch batch13...\n",
      "Loading data...\n",
      "Processing batch batch14...\n",
      "Loading data...\n",
      "Processing batch batch15...\n",
      "Loading data...\n",
      "Processing batch batch16...\n",
      "Loading data...\n",
      "Processing batch batch17...\n",
      "Loading data...\n",
      "Processing batch batch18...\n",
      "Loading data...\n",
      "Processing batch batch19...\n",
      "Loading data...\n",
      "Processing batch batch20...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 8\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/29: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [04:21<00:00,  9.03s/it, loss=288, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=29` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/29: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [04:21<00:00,  9.02s/it, loss=288, v_num=1]\n",
      "Duration of model training in run 9: 0 hours, 4 minutes and 23 seconds.\n",
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Processing batch batch6...\n",
      "Loading data...\n",
      "Processing batch batch7...\n",
      "Loading data...\n",
      "Processing batch batch8...\n",
      "Loading data...\n",
      "Processing batch batch9...\n",
      "Loading data...\n",
      "Processing batch batch10...\n",
      "Loading data...\n",
      "Processing batch batch11...\n",
      "Loading data...\n",
      "Processing batch batch12...\n",
      "Loading data...\n",
      "Processing batch batch13...\n",
      "Loading data...\n",
      "Processing batch batch14...\n",
      "Loading data...\n",
      "Processing batch batch15...\n",
      "Loading data...\n",
      "Processing batch batch16...\n",
      "Loading data...\n",
      "Processing batch batch17...\n",
      "Loading data...\n",
      "Processing batch batch18...\n",
      "Loading data...\n",
      "Processing batch batch19...\n",
      "Loading data...\n",
      "Processing batch batch20...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 9\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/29: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [04:22<00:00,  9.04s/it, loss=281, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=29` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/29: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [04:22<00:00,  9.04s/it, loss=281, v_num=1]\n",
      "Duration of model training in run 10: 0 hours, 4 minutes and 23 seconds.\n",
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Processing batch batch6...\n",
      "Loading data...\n",
      "Processing batch batch7...\n",
      "Loading data...\n",
      "Processing batch batch8...\n",
      "Loading data...\n",
      "Processing batch batch9...\n",
      "Loading data...\n",
      "Processing batch batch10...\n",
      "Loading data...\n",
      "Processing batch batch11...\n",
      "Loading data...\n",
      "Processing batch batch12...\n",
      "Loading data...\n",
      "Processing batch batch13...\n",
      "Loading data...\n",
      "Processing batch batch14...\n",
      "Loading data...\n",
      "Processing batch batch15...\n",
      "Loading data...\n",
      "Processing batch batch16...\n",
      "Loading data...\n",
      "Processing batch batch17...\n",
      "Loading data...\n",
      "Processing batch batch18...\n",
      "Loading data...\n",
      "Processing batch batch19...\n",
      "Loading data...\n",
      "Processing batch batch20...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/15: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [04:30<00:00, 18.04s/it, loss=291, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/15: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [04:30<00:00, 18.04s/it, loss=291, v_num=1]\n",
      "Duration of model training in run 1: 0 hours, 4 minutes and 33 seconds.\n",
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Processing batch batch6...\n",
      "Loading data...\n",
      "Processing batch batch7...\n",
      "Loading data...\n",
      "Processing batch batch8...\n",
      "Loading data...\n",
      "Processing batch batch9...\n",
      "Loading data...\n",
      "Processing batch batch10...\n",
      "Loading data...\n",
      "Processing batch batch11...\n",
      "Loading data...\n",
      "Processing batch batch12...\n",
      "Loading data...\n",
      "Processing batch batch13...\n",
      "Loading data...\n",
      "Processing batch batch14...\n",
      "Loading data...\n",
      "Processing batch batch15...\n",
      "Loading data...\n",
      "Processing batch batch16...\n",
      "Loading data...\n",
      "Processing batch batch17...\n",
      "Loading data...\n",
      "Processing batch batch18...\n",
      "Loading data...\n",
      "Processing batch batch19...\n",
      "Loading data...\n",
      "Processing batch batch20...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/15: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [04:30<00:00, 18.02s/it, loss=287, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/15: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [04:30<00:00, 18.01s/it, loss=287, v_num=1]\n",
      "Duration of model training in run 2: 0 hours, 4 minutes and 33 seconds.\n",
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Processing batch batch6...\n",
      "Loading data...\n",
      "Processing batch batch7...\n",
      "Loading data...\n",
      "Processing batch batch8...\n",
      "Loading data...\n",
      "Processing batch batch9...\n",
      "Loading data...\n",
      "Processing batch batch10...\n",
      "Loading data...\n",
      "Processing batch batch11...\n",
      "Loading data...\n",
      "Processing batch batch12...\n",
      "Loading data...\n",
      "Processing batch batch13...\n",
      "Loading data...\n",
      "Processing batch batch14...\n",
      "Loading data...\n",
      "Processing batch batch15...\n",
      "Loading data...\n",
      "Processing batch batch16...\n",
      "Loading data...\n",
      "Processing batch batch17...\n",
      "Loading data...\n",
      "Processing batch batch18...\n",
      "Loading data...\n",
      "Processing batch batch19...\n",
      "Loading data...\n",
      "Processing batch batch20...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 2\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/15: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [04:30<00:00, 18.02s/it, loss=291, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/15: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [04:30<00:00, 18.03s/it, loss=291, v_num=1]\n",
      "Duration of model training in run 3: 0 hours, 4 minutes and 33 seconds.\n",
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Processing batch batch6...\n",
      "Loading data...\n",
      "Processing batch batch7...\n",
      "Loading data...\n",
      "Processing batch batch8...\n",
      "Loading data...\n",
      "Processing batch batch9...\n",
      "Loading data...\n",
      "Processing batch batch10...\n",
      "Loading data...\n",
      "Processing batch batch11...\n",
      "Loading data...\n",
      "Processing batch batch12...\n",
      "Loading data...\n",
      "Processing batch batch13...\n",
      "Loading data...\n",
      "Processing batch batch14...\n",
      "Loading data...\n",
      "Processing batch batch15...\n",
      "Loading data...\n",
      "Processing batch batch16...\n",
      "Loading data...\n",
      "Processing batch batch17...\n",
      "Loading data...\n",
      "Processing batch batch18...\n",
      "Loading data...\n",
      "Processing batch batch19...\n",
      "Loading data...\n",
      "Processing batch batch20...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 3\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/15: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [04:32<00:00, 18.11s/it, loss=290, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/15: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [04:32<00:00, 18.18s/it, loss=290, v_num=1]\n",
      "Duration of model training in run 4: 0 hours, 4 minutes and 35 seconds.\n"
     ]
    }
   ],
   "source": [
    "for subsample_pct in [1, 5, 10, 25, 50]:\n",
    "    train_scvi_models(dataset=f\"starmap_plus_mouse_cns_subsample_{subsample_pct}pct\",\n",
    "                      reference_batches=[f\"batch{i}\" for i in range(1,21)],\n",
    "                      cell_type_key=\"Main_molecular_cell_type\",\n",
    "                      adata_new=None,\n",
    "                      n_start_run=1,\n",
    "                      n_end_run=10,\n",
    "                      n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16, 20, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f13b605-e7e2-46e0-86ee-31988c062855",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
