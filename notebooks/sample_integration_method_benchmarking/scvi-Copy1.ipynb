{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "364a9ebc-3e3c-4645-9049-a34bd084c8a8",
   "metadata": {},
   "source": [
    "# scVI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c55227-147e-417f-b0dd-bb0b7f322930",
   "metadata": {},
   "source": [
    "- **Creator**: Sebastian Birk (<sebastian.birk@helmholtz-munich.de>).\n",
    "- **Affiliation:** Helmholtz Munich, Institute of Computational Biology (ICB), Talavera-López Lab\n",
    "- **Date of Creation:** 05.01.2023\n",
    "- **Date of Last Modification:** 19.08.2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f91758d-06e2-478a-a934-5f04ee9344eb",
   "metadata": {},
   "source": [
    "- The scVI source code is available at https://github.com/scverse/scvi-tools.\n",
    "- The corresponding publication is \"Lopez, R., Regier, J., Cole, M. B., Jordan, M. I. & Yosef, N. Deep generative modeling for single-cell transcriptomics. Nat. Methods 15, 1053–1058 (2018)\".\n",
    "- The workflow of this notebook follows the tutorial from https://docs.scvi-tools.org/en/stable/tutorials/notebooks/harmonization.html.\n",
    "- The authors use raw counts as input to scVI. Therefore, we also use raw counts (stored in adata.layers[\"counts\"])."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7529cde5-be12-403b-a94c-07561774b86c",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faad87bd-fef5-4429-a175-d714c491ae76",
   "metadata": {},
   "source": [
    "### 1.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7f93960-c759-424f-8cb2-1d8698acae2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank: 0] Global seed set to 0\n",
      "/home/aih/sebastian.birk/.local/lib/python3.9/site-packages/flax/struct.py:136: FutureWarning: jax.tree_util.register_keypaths is deprecated, and will be removed in a future release. Please use `register_pytree_with_keys()` instead.\n",
      "  jax.tree_util.register_keypaths(data_clz, keypaths)\n",
      "/home/aih/sebastian.birk/.local/lib/python3.9/site-packages/flax/struct.py:136: FutureWarning: jax.tree_util.register_keypaths is deprecated, and will be removed in a future release. Please use `register_pytree_with_keys()` instead.\n",
      "  jax.tree_util.register_keypaths(data_clz, keypaths)\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import anndata as ad\n",
    "import scvi\n",
    "import scanpy as sc\n",
    "import scipy.sparse as sp\n",
    "import squidpy as sq\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b5efa5-2052-4986-8ae5-89cfab018515",
   "metadata": {},
   "source": [
    "### 1.2 Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5c8b48a-ed5e-48b5-8c5c-c1de11493aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"scvi\"\n",
    "latent_key = f\"{model_name}_latent\"\n",
    "mapping_entity_key = \"reference\"\n",
    "condition_key = \"batch\"\n",
    "counts_key = \"counts\"\n",
    "leiden_resolution = 0.5 # used for Leiden clustering of latent space\n",
    "random_seed = 0 # used for Leiden clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28adc110-0f41-4a71-9838-dc7f0687809a",
   "metadata": {},
   "source": [
    "### 1.3 Run Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "334b87ca-3387-4ba9-8567-84bc4754ff0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.set_figure_params(figsize=(6, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ab6b302-1c0b-4937-8624-40629ada2e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get time of notebook execution for timestamping saved artifacts\n",
    "now = datetime.now()\n",
    "current_timestamp = now.strftime(\"%d%m%Y_%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85538952-006b-4b0b-a50c-fe7445ce22e2",
   "metadata": {},
   "source": [
    "### 1.4 Configure Paths and Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ddcc49c-ba22-4155-acd5-05b5b810e091",
   "metadata": {},
   "outputs": [],
   "source": [
    "srt_data_gold_folder_path = \"../../datasets/srt_data/gold/\"\n",
    "srt_data_results_folder_path = \"../../datasets/srt_data/results/\" \n",
    "figure_folder_path = f\"../../figures\"\n",
    "benchmarking_folder_path = \"../../artifacts/sample_integration_method_benchmarking\"\n",
    "\n",
    "# Create required directories\n",
    "os.makedirs(srt_data_gold_folder_path, exist_ok=True)\n",
    "os.makedirs(srt_data_results_folder_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d974cd00-eafa-4432-b172-fafc4058a619",
   "metadata": {},
   "source": [
    "## 2. scVI Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427dec10-5c8b-4eb2-a032-987b22beef9e",
   "metadata": {},
   "source": [
    "### 2.1 Define Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9981586-fc49-4654-a4a8-8224d09dd630",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_scvi_models(dataset,\n",
    "                      reference_batches,\n",
    "                      cell_type_key,\n",
    "                      adata_new=None,\n",
    "                      n_start_run=1,\n",
    "                      n_end_run=8,\n",
    "                      n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16],\n",
    "                      plot_latent_umaps=False):    \n",
    "    # Create new adata to store results from training runs in storage-efficient way\n",
    "    if adata_new is None:  \n",
    "        adata_batch_list = []\n",
    "        if reference_batches is not None:\n",
    "            for batch in reference_batches:\n",
    "                adata_batch = ad.read_h5ad(\n",
    "                    f\"{srt_data_gold_folder_path}/{dataset}_{batch}.h5ad\")\n",
    "                adata_batch.obs[mapping_entity_key] = \"reference\"\n",
    "                adata_batch_list.append(adata_batch)\n",
    "            adata_original = ad.concat(adata_batch_list, join=\"inner\")\n",
    "        else:\n",
    "            adata_original = ad.read_h5ad(f\"{srt_data_gold_folder_path}/{dataset}.h5ad\")\n",
    "\n",
    "        adata_new = sc.AnnData(sp.csr_matrix(\n",
    "            (adata_original.shape[0], adata_original.shape[1]),\n",
    "            dtype=np.float32))\n",
    "        adata_new.var_names = adata_original.var_names\n",
    "        adata_new.obs_names = adata_original.obs_names\n",
    "        adata_new.obs[\"cell_type\"] = adata_original.obs[cell_type_key].values\n",
    "        adata_new.obsm[\"spatial\"] = adata_original.obsm[\"spatial\"]\n",
    "        adata_new.obs[condition_key] = adata_original.obs[condition_key]\n",
    "        adata_new.obs[mapping_entity_key] = adata_original.obs[mapping_entity_key] \n",
    "        del(adata_original)\n",
    "        \n",
    "    model_seeds = list(range(10))\n",
    "    for run_number, n_neighbors in zip(np.arange(n_start_run, n_end_run+1), n_neighbor_list):\n",
    "        # n_neighbors is here only used for the latent neighbor graph construction used for\n",
    "        # UMAP generation and clustering as scVI is not a spatial method\n",
    "        \n",
    "        # Load data\n",
    "        adata_batch_list = []\n",
    "        if reference_batches is not None:\n",
    "            for batch in reference_batches:\n",
    "                print(f\"Processing batch {batch}...\")\n",
    "                print(\"Loading data...\")\n",
    "                adata_batch = ad.read_h5ad(\n",
    "                    f\"{srt_data_gold_folder_path}/{dataset}_{batch}.h5ad\")\n",
    "                adata_batch_list.append(adata_batch)\n",
    "            adata = ad.concat(adata_batch_list, join=\"inner\")\n",
    "        else:\n",
    "            adata = ad.read_h5ad(f\"{srt_data_gold_folder_path}/{dataset}.h5ad\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        scvi.settings.seed = model_seeds[run_number-1]\n",
    "\n",
    "        # Setup adata\n",
    "        scvi.model.SCVI.setup_anndata(adata,\n",
    "                                      layer=counts_key,\n",
    "                                      batch_key=condition_key)\n",
    "\n",
    "        # Initialize model\n",
    "        # Use hyperparams that provenly work well on integration tasks\n",
    "        model = scvi.model.SCVI(adata,\n",
    "                                n_layers=2,\n",
    "                                n_latent=30,\n",
    "                                gene_likelihood=\"nb\")\n",
    "\n",
    "        # Train model\n",
    "        model.train()\n",
    "\n",
    "        # Store latent representation\n",
    "        adata.obsm[latent_key] = model.get_latent_representation()\n",
    "        \n",
    "        # Measure time for model training\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        hours, rem = divmod(elapsed_time, 3600)\n",
    "        minutes, seconds = divmod(rem, 60)\n",
    "        print(f\"Duration of model training in run {run_number}: \"\n",
    "              f\"{int(hours)} hours, {int(minutes)} minutes and {int(seconds)} seconds.\")\n",
    "        adata_new.uns[f\"{model_name}_model_training_duration_run{run_number}\"] = (\n",
    "            elapsed_time)\n",
    "        \n",
    "        if plot_latent_umaps:\n",
    "            # Configure figure folder path\n",
    "            dataset_figure_folder_path = f\"{figure_folder_path}/{dataset}/sample_integration_method_benchmarking/\" \\\n",
    "                                         f\"{model_name}/{current_timestamp}\"\n",
    "            os.makedirs(dataset_figure_folder_path, exist_ok=True)\n",
    "    \n",
    "            # Use scVI latent space for UMAP generation\n",
    "            sc.pp.neighbors(adata,\n",
    "                            use_rep=latent_key,\n",
    "                            n_neighbors=n_neighbors)\n",
    "            sc.tl.umap(adata)\n",
    "            fig = sc.pl.umap(adata,\n",
    "                             color=[cell_type_key],\n",
    "                             title=\"Latent Space with Cell Types: scVI\",\n",
    "                             return_fig=True)\n",
    "            fig.savefig(f\"{dataset_figure_folder_path}/latent_{model_name}\"\n",
    "                        f\"_cell_types_run{run_number}.png\",\n",
    "                        bbox_inches=\"tight\")\n",
    "\n",
    "            # Compute latent Leiden clustering\n",
    "            sc.tl.leiden(adata=adata,\n",
    "                         resolution=leiden_resolution,\n",
    "                         random_state=random_seed,\n",
    "                         key_added=f\"latent_{model_name}_leiden_{str(leiden_resolution)}\")\n",
    "\n",
    "            # Create subplot of latent Leiden cluster annotations in physical and latent space\n",
    "            fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(6, 12))\n",
    "            title = fig.suptitle(t=\"Latent and Physical Space with Leiden Clusters: scVI\")\n",
    "            sc.pl.umap(adata=adata,\n",
    "                       color=[f\"latent_{model_name}_leiden_{str(leiden_resolution)}\"],\n",
    "                       title=f\"Latent Space with Leiden Clusters\",\n",
    "                       ax=axs[0],\n",
    "                       show=False)\n",
    "            sq.pl.spatial_scatter(adata=adata,\n",
    "                                  color=[f\"latent_{model_name}_leiden_{str(leiden_resolution)}\"],\n",
    "                                  title=f\"Physical Space with Leiden Clusters\",\n",
    "                                  shape=None,\n",
    "                                  ax=axs[1])\n",
    "\n",
    "            # Create and position shared legend\n",
    "            handles, labels = axs[0].get_legend_handles_labels()\n",
    "            lgd = fig.legend(handles, labels, bbox_to_anchor=(1.25, 0.9185))\n",
    "            axs[0].get_legend().remove()\n",
    "            axs[1].get_legend().remove()\n",
    "\n",
    "            # Adjust, save and display plot\n",
    "            plt.subplots_adjust(wspace=0, hspace=0.2)\n",
    "            fig.savefig(f\"{dataset_figure_folder_path}/latent_physical_comparison_\"\n",
    "                        f\"{model_name}_run{run_number}.png\",\n",
    "                        bbox_extra_artists=(lgd, title),\n",
    "                        bbox_inches=\"tight\")\n",
    "            plt.show()\n",
    "        \n",
    "        # Store latent representation\n",
    "        adata_new.obsm[latent_key + f\"_run{run_number}\"] = adata.obsm[latent_key]\n",
    "        \n",
    "        # Use latent representation for UMAP generation\n",
    "        sc.pp.neighbors(adata_new,\n",
    "                        use_rep=f\"{latent_key}_run{run_number}\",\n",
    "                        key_added=f\"{latent_key}_run{run_number}\")\n",
    "        sc.tl.umap(adata_new,\n",
    "                   neighbors_key=f\"{latent_key}_run{run_number}\")\n",
    "        adata_new.obsm[f\"{latent_key}_run{run_number}_X_umap\"] = adata_new.obsm[\"X_umap\"]\n",
    "        del(adata_new.obsm[\"X_umap\"])\n",
    "\n",
    "        # Store intermediate adata to disk\n",
    "        adata_new.write(f\"{benchmarking_folder_path}/{dataset}_{model_name}.h5ad\")  \n",
    "\n",
    "        # Free memory\n",
    "        del(adata)\n",
    "        del(model)\n",
    "        gc.collect()\n",
    "        \n",
    "    # Store final adata to disk\n",
    "    adata_new.write(f\"{benchmarking_folder_path}/{dataset}_{model_name}.h5ad\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e1609c-b40c-4bcc-addc-6065287ae21d",
   "metadata": {},
   "source": [
    "### 2.2 Train Models on Benchmarking Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a645699a-5fb8-4795-ae3d-071dd4e41f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scvi_models(dataset=\"seqfish_mouse_organogenesis\",\n",
    "                  reference_batches=[f\"batch{i}\" for i in range(1,7)],\n",
    "                  cell_type_key=\"celltype_mapped_refined\",\n",
    "                  adata_new=None,\n",
    "                  n_start_run=1,\n",
    "                  n_end_run=8,\n",
    "                  n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd5e96b-01bb-4d06-b71d-923a1aa2c23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aih/sebastian.birk/miniconda3/envs/nichecompass-reproducibility/lib/python3.9/site-packages/anndata/_core/anndata.py:1830: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aih/sebastian.birk/miniconda3/envs/nichecompass-reproducibility/lib/python3.9/site-packages/anndata/_core/anndata.py:1830: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "[rank: 0] Global seed set to 0\n",
      "/home/aih/sebastian.birk/.local/lib/python3.9/site-packages/lightning_fabric/plugins/environments/slurm.py:166: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/aih/sebastian.birk/miniconda3/envs/nichecompas ...\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/aih/sebastian.birk/.local/lib/python3.9/site-packages/lightning_fabric/plugins/environments/slurm.py:166: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/aih/sebastian.birk/miniconda3/envs/nichecompas ...\n",
      "  rank_zero_warn(\n",
      "You are using a CUDA device ('NVIDIA A100-PCIE-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/57: 100%|███████████| 57/57 [05:23<00:00,  5.70s/it, loss=452, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=57` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/57: 100%|███████████| 57/57 [05:23<00:00,  5.68s/it, loss=452, v_num=1]\n",
      "Duration of model training in run 1: 0 hours, 5 minutes and 25 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aih/sebastian.birk/miniconda3/envs/nichecompass-reproducibility/lib/python3.9/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/home/aih/sebastian.birk/miniconda3/envs/nichecompass-reproducibility/lib/python3.9/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/home/aih/sebastian.birk/miniconda3/envs/nichecompass-reproducibility/lib/python3.9/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/home/aih/sebastian.birk/miniconda3/envs/nichecompass-reproducibility/lib/python3.9/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aih/sebastian.birk/miniconda3/envs/nichecompass-reproducibility/lib/python3.9/site-packages/anndata/_core/anndata.py:1830: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "[rank: 0] Global seed set to 1\n",
      "/home/aih/sebastian.birk/.local/lib/python3.9/site-packages/lightning_fabric/plugins/environments/slurm.py:166: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/aih/sebastian.birk/miniconda3/envs/nichecompas ...\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/aih/sebastian.birk/.local/lib/python3.9/site-packages/lightning_fabric/plugins/environments/slurm.py:166: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/aih/sebastian.birk/miniconda3/envs/nichecompas ...\n",
      "  rank_zero_warn(\n",
      "You are using a CUDA device ('NVIDIA A100-PCIE-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/57: 100%|███████████| 57/57 [05:22<00:00,  5.65s/it, loss=446, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=57` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/57: 100%|███████████| 57/57 [05:22<00:00,  5.66s/it, loss=446, v_num=1]\n",
      "Duration of model training in run 2: 0 hours, 5 minutes and 24 seconds.\n",
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aih/sebastian.birk/miniconda3/envs/nichecompass-reproducibility/lib/python3.9/site-packages/anndata/_core/anndata.py:1830: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "[rank: 0] Global seed set to 2\n",
      "/home/aih/sebastian.birk/.local/lib/python3.9/site-packages/lightning_fabric/plugins/environments/slurm.py:166: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/aih/sebastian.birk/miniconda3/envs/nichecompas ...\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/aih/sebastian.birk/.local/lib/python3.9/site-packages/lightning_fabric/plugins/environments/slurm.py:166: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/aih/sebastian.birk/miniconda3/envs/nichecompas ...\n",
      "  rank_zero_warn(\n",
      "You are using a CUDA device ('NVIDIA A100-PCIE-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/57: 100%|███████████| 57/57 [05:24<00:00,  5.69s/it, loss=442, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=57` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/57: 100%|███████████| 57/57 [05:24<00:00,  5.70s/it, loss=442, v_num=1]\n",
      "Duration of model training in run 3: 0 hours, 5 minutes and 26 seconds.\n",
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aih/sebastian.birk/miniconda3/envs/nichecompass-reproducibility/lib/python3.9/site-packages/anndata/_core/anndata.py:1830: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "[rank: 0] Global seed set to 3\n",
      "/home/aih/sebastian.birk/.local/lib/python3.9/site-packages/lightning_fabric/plugins/environments/slurm.py:166: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/aih/sebastian.birk/miniconda3/envs/nichecompas ...\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/aih/sebastian.birk/.local/lib/python3.9/site-packages/lightning_fabric/plugins/environments/slurm.py:166: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/aih/sebastian.birk/miniconda3/envs/nichecompas ...\n",
      "  rank_zero_warn(\n",
      "You are using a CUDA device ('NVIDIA A100-PCIE-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/57:  58%|██████▎    | 33/57 [03:09<02:18,  5.78s/it, loss=449, v_num=1]"
     ]
    }
   ],
   "source": [
    "for subsample_pct in [50, 25, 10, 5, 1]:\n",
    "    train_scvi_models(dataset=f\"nanostring_cosmx_human_nsclc_subsample_{subsample_pct}pct\",\n",
    "                      reference_batches=[f\"batch{i}\" for i in range(1,4)],\n",
    "                      cell_type_key=\"cell_type\",\n",
    "                      adata_new=None,\n",
    "                      n_start_run=1,\n",
    "                      n_end_run=8,\n",
    "                      n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4181742c-41d1-46fe-8a7a-2e5f7c367984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Processing batch batch6...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank: 0] Global seed set to 0\n",
      "/home/aih/sebastian.birk/.local/lib/python3.9/site-packages/lightning_fabric/plugins/environments/slurm.py:166: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/aih/sebastian.birk/miniconda3/envs/nichecompas ...\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/aih/sebastian.birk/.local/lib/python3.9/site-packages/lightning_fabric/plugins/environments/slurm.py:166: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/aih/sebastian.birk/miniconda3/envs/nichecompas ...\n",
      "  rank_zero_warn(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 304/304: 100%|████| 304/304 [06:14<00:00,  1.16s/it, loss=258, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=304` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 304/304: 100%|████| 304/304 [06:14<00:00,  1.23s/it, loss=258, v_num=1]\n",
      "Duration of model training in run 1: 0 hours, 6 minutes and 17 seconds.\n",
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Processing batch batch6...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank: 0] Global seed set to 1\n",
      "/home/aih/sebastian.birk/.local/lib/python3.9/site-packages/lightning_fabric/plugins/environments/slurm.py:166: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/aih/sebastian.birk/miniconda3/envs/nichecompas ...\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/aih/sebastian.birk/.local/lib/python3.9/site-packages/lightning_fabric/plugins/environments/slurm.py:166: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/aih/sebastian.birk/miniconda3/envs/nichecompas ...\n",
      "  rank_zero_warn(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 304/304: 100%|████| 304/304 [05:53<00:00,  1.14s/it, loss=256, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=304` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 304/304: 100%|████| 304/304 [05:53<00:00,  1.16s/it, loss=256, v_num=1]\n",
      "Duration of model training in run 2: 0 hours, 5 minutes and 57 seconds.\n",
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Processing batch batch6...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank: 0] Global seed set to 2\n",
      "/home/aih/sebastian.birk/.local/lib/python3.9/site-packages/lightning_fabric/plugins/environments/slurm.py:166: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/aih/sebastian.birk/miniconda3/envs/nichecompas ...\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/aih/sebastian.birk/.local/lib/python3.9/site-packages/lightning_fabric/plugins/environments/slurm.py:166: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/aih/sebastian.birk/miniconda3/envs/nichecompas ...\n",
      "  rank_zero_warn(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 304/304: 100%|████| 304/304 [05:51<00:00,  1.23s/it, loss=257, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=304` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 304/304: 100%|████| 304/304 [05:51<00:00,  1.16s/it, loss=257, v_num=1]\n",
      "Duration of model training in run 3: 0 hours, 5 minutes and 52 seconds.\n",
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Processing batch batch5...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank: 0] Global seed set to 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch batch6...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aih/sebastian.birk/.local/lib/python3.9/site-packages/lightning_fabric/plugins/environments/slurm.py:166: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/aih/sebastian.birk/miniconda3/envs/nichecompas ...\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/aih/sebastian.birk/.local/lib/python3.9/site-packages/lightning_fabric/plugins/environments/slurm.py:166: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/aih/sebastian.birk/miniconda3/envs/nichecompas ...\n",
      "  rank_zero_warn(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166/304:  54%|██▏ | 165/304 [03:08<02:38,  1.14s/it, loss=255, v_num=1]"
     ]
    }
   ],
   "source": [
    "for subsample_pct in [50, 25, 10, 5, 1]:\n",
    "    train_scvi_models(dataset=f\"seqfish_mouse_organogenesis_subsample_{subsample_pct}pct\",\n",
    "                      reference_batches=[f\"batch{i}\" for i in range(1,7)],\n",
    "                      cell_type_key=\"celltype_mapped_refined\",\n",
    "                      adata_new=None,\n",
    "                      n_start_run=1,\n",
    "                      n_end_run=8,\n",
    "                      n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3032c2f4-4721-458a-8870-41bc5fb1990f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scvi_models(dataset=\"nanostring_cosmx_human_nsclc\",\n",
    "                  reference_batches=[f\"batch{i}\" for i in range(1, 4)],\n",
    "                  cell_type_key=\"cell_type\",\n",
    "                  adata_new=None,\n",
    "                  n_start_run=1,\n",
    "                  n_end_run=8,\n",
    "                  n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3324a416-4d74-40db-9a11-0921803a3a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subsample_pct in [1, 5, 10, 25, 50]:\n",
    "    train_scvi_models(dataset=f\"nanostring_cosmx_human_nsclc_{subsample_pct}pct\",\n",
    "                      reference_batches=[f\"batch{i}\" for i in range(1,4)],\n",
    "                      cell_type_key=\"cell_type\",\n",
    "                      adata_new=None,\n",
    "                      n_start_run=1,\n",
    "                      n_end_run=8,\n",
    "                      n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f13b605-e7e2-46e0-86ee-31988c062855",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
