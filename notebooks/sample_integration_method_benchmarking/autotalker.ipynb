{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "364a9ebc-3e3c-4645-9049-a34bd084c8a8",
   "metadata": {},
   "source": [
    "# Autotalker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c55227-147e-417f-b0dd-bb0b7f322930",
   "metadata": {},
   "source": [
    "- **Creator**: Sebastian Birk (<sebastian.birk@helmholtz-munich.de>).\n",
    "- **Affiliation:** Helmholtz Munich, Institute of Computational Biology (ICB), Talavera-LÃ³pez Lab\n",
    "- **Date of Creation:** 13.01.2023\n",
    "- **Date of Last Modification:** 31.03.2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa669117-f347-4666-b112-8ea6669fd9e9",
   "metadata": {},
   "source": [
    "- The Autotalker source code is available at https://github.com/Talavera-Lopez-Lab/autotalker.\n",
    "- The workflow of this notebook follows the tutorial from https://github.com/sebastianbirk/autotalker/blob/main/notebooks/autotalker_tutorial.ipynb.\n",
    "- It is recommended to use raw counts as input to Autotalker. Therefore, we use raw counts (stored in adata.layers[\"counts\"])."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7529cde5-be12-403b-a94c-07561774b86c",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faad87bd-fef5-4429-a175-d714c491ae76",
   "metadata": {},
   "source": [
    "### 1.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "149b5fec-87ba-4bd5-a327-5a37065b6223",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9305ecb-5d4b-4cdd-8e92-f7155426b7f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../../autotalker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7f93960-c759-424f-8cb2-1d8698acae2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import gc\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "\n",
    "import anndata as ad\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import scipy.sparse as sp\n",
    "import seaborn as sns\n",
    "import squidpy as sq\n",
    "import torch\n",
    "from matplotlib.pyplot import rc_context\n",
    "\n",
    "from autotalker.models import Autotalker\n",
    "from autotalker.utils import (add_gps_from_gp_dict_to_adata,\n",
    "                              extract_gp_dict_from_mebocost_es_interactions,\n",
    "                              extract_gp_dict_from_nichenet_ligand_target_mx,\n",
    "                              extract_gp_dict_from_omnipath_lr_interactions,\n",
    "                              filter_and_combine_gp_dict_gps,\n",
    "                              get_unique_genes_from_gp_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b5efa5-2052-4986-8ae5-89cfab018515",
   "metadata": {},
   "source": [
    "### 1.2 Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5c8b48a-ed5e-48b5-8c5c-c1de11493aee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"autotalker\"\n",
    "latent_key = f\"{model_name}_latent\"\n",
    "mapping_entity_key = \"reference\"\n",
    "condition_key = \"batch\"\n",
    "counts_key = \"counts\"\n",
    "spatial_key = \"spatial\"\n",
    "adj_key = \"spatial_connectivities\"\n",
    "nichenet_keep_target_genes_ratio = 0.01\n",
    "nichenet_max_n_target_genes_per_gp = 25344\n",
    "include_mebocost_gps = True\n",
    "mebocost_species = \"mouse\"\n",
    "filter_genes = False\n",
    "gp_filter_mode = \"subset\"\n",
    "combine_overlap_gps = True\n",
    "overlap_thresh_source_genes = 0.9\n",
    "overlap_thresh_target_genes = 0.9\n",
    "overlap_thresh_genes = 0.9\n",
    "active_gp_names_key = \"autotalker_active_gp_names\"\n",
    "gp_targets_mask_key = \"autotalker_gp_targets_mask\"\n",
    "gp_sources_mask_key = \"autotalker_gp_sources_mask\"\n",
    "gp_names_key = \"autotalker_gp_names\"\n",
    "active_gp_thresh_ratio = 0.05\n",
    "gene_expr_recon_dist = \"nb\"\n",
    "cond_embed_injection = [\"gene_expr_decoder\"]\n",
    "log_variational = True\n",
    "n_layers_encoder = 1\n",
    "conv_layer_encoder = \"gcnconv\"\n",
    "n_epochs = 100\n",
    "n_epochs_all_gps = 25\n",
    "lr = 0.001\n",
    "lambda_edge_recon = 500000.\n",
    "lambda_gene_expr_recon = 100.\n",
    "lambda_cond_contrastive = 100000.\n",
    "contrastive_logits_ratio = 0.125 # 0.03125 # 0.015625\n",
    "lambda_group_lasso = 0.\n",
    "lambda_l1_masked = 0.\n",
    "edge_batch_size = 16384 # 32768, 4096, 256\n",
    "node_batch_size = None\n",
    "leiden_resolution = 0.01 # used for Leiden clustering of latent space; 0.1\n",
    "random_seed = 0 # used for Leiden clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7427c455-9174-42ca-aa17-42c761f06584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16384.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32768 / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28adc110-0f41-4a71-9838-dc7f0687809a",
   "metadata": {},
   "source": [
    "### 1.3 Run Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "334b87ca-3387-4ba9-8567-84bc4754ff0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sc.set_figure_params(figsize=(6, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ab6b302-1c0b-4937-8624-40629ada2e46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get time of notebook execution for timestamping saved artifacts\n",
    "now = datetime.now()\n",
    "current_timestamp = now.strftime(\"%d%m%Y_%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85538952-006b-4b0b-a50c-fe7445ce22e2",
   "metadata": {},
   "source": [
    "### 1.4 Configure Paths and Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ddcc49c-ba22-4155-acd5-05b5b810e091",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "srt_data_gold_folder_path = \"../../datasets/srt_data/gold\"\n",
    "figure_folder_path = f\"../../figures\"\n",
    "gp_data_folder_path = \"../../datasets/gp_data\" # gene program data\n",
    "nichenet_ligand_target_mx_file_path = gp_data_folder_path + \"/nichenet_ligand_target_matrix.csv\"\n",
    "omnipath_lr_interactions_file_path = gp_data_folder_path + \"/omnipath_lr_interactions.csv\"\n",
    "\n",
    "# Create required directories\n",
    "os.makedirs(gp_data_folder_path, exist_ok=True)\n",
    "os.makedirs(srt_data_gold_folder_path + \"/results\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d974cd00-eafa-4432-b172-fafc4058a619",
   "metadata": {},
   "source": [
    "## 2. Autotalker Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b908c99c-de2f-4239-8420-00bd1fd58baa",
   "metadata": {},
   "source": [
    "### 2.1 Prepare Gene Program Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06c510ab-e3b1-41e7-848d-e4b9513313cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the gene program mask...\n",
      "Number of gene programs before filtering and combining: 1725.\n",
      "Number of gene programs after filtering and combining: 1575.\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing the gene program mask...\")\n",
    "# OmniPath gene programs\n",
    "omnipath_gp_dict = extract_gp_dict_from_omnipath_lr_interactions(\n",
    "    min_curation_effort=0,\n",
    "    load_from_disk=True,\n",
    "    save_to_disk=False,\n",
    "    file_path=omnipath_lr_interactions_file_path,\n",
    "    plot_gp_gene_count_distributions=False)\n",
    "\n",
    "omnipath_genes = get_unique_genes_from_gp_dict(\n",
    "    gp_dict=omnipath_gp_dict,\n",
    "    retrieved_gene_entities=[\"sources\", \"targets\"])\n",
    "\n",
    "# NicheNet gene programs\n",
    "nichenet_gp_dict = extract_gp_dict_from_nichenet_ligand_target_mx(\n",
    "    keep_target_genes_ratio=nichenet_keep_target_genes_ratio,\n",
    "    max_n_target_genes_per_gp=nichenet_max_n_target_genes_per_gp,\n",
    "    load_from_disk=True,\n",
    "    save_to_disk=False,\n",
    "    file_path=nichenet_ligand_target_mx_file_path,\n",
    "    plot_gp_gene_count_distributions=False)\n",
    "\n",
    "nichenet_source_genes = get_unique_genes_from_gp_dict(\n",
    "    gp_dict=nichenet_gp_dict,\n",
    "    retrieved_gene_entities=[\"sources\"])\n",
    "\n",
    "# Combine gene programs into one dictionary\n",
    "combined_gp_dict = dict(omnipath_gp_dict)\n",
    "combined_gp_dict.update(nichenet_gp_dict)\n",
    "\n",
    "if filter_genes:\n",
    "    # Get gene program relevant genes\n",
    "    gp_relevant_genes = list(set(omnipath_genes + nichenet_source_genes))\n",
    "\n",
    "# Mebocost gene programs\n",
    "if include_mebocost_gps:\n",
    "    mebocost_gp_dict = extract_gp_dict_from_mebocost_es_interactions(\n",
    "    dir_path=f\"{gp_data_folder_path}/metabolite_enzyme_sensor_gps/\",\n",
    "    species=mebocost_species,\n",
    "    genes_uppercase=True,\n",
    "    plot_gp_gene_count_distributions=False)\n",
    "    \n",
    "    mebocost_genes = get_unique_genes_from_gp_dict(\n",
    "        gp_dict=mebocost_gp_dict,\n",
    "        retrieved_gene_entities=[\"sources\", \"targets\"])\n",
    "\n",
    "    combined_gp_dict.update(mebocost_gp_dict)\n",
    "    \n",
    "    if filter_genes:\n",
    "        # Update gene program relevant genes\n",
    "        gp_relevant_genes = list(set(gp_relevant_genes + mebocost_genes))\n",
    "    \n",
    "# Filter and combine gene programs\n",
    "combined_new_gp_dict = filter_and_combine_gp_dict_gps(\n",
    "    gp_dict=combined_gp_dict,\n",
    "    gp_filter_mode=gp_filter_mode,\n",
    "    combine_overlap_gps=combine_overlap_gps,\n",
    "    overlap_thresh_source_genes=overlap_thresh_source_genes,\n",
    "    overlap_thresh_target_genes=overlap_thresh_target_genes,\n",
    "    overlap_thresh_genes=overlap_thresh_genes,\n",
    "    verbose=False)\n",
    "\n",
    "print(\"Number of gene programs before filtering and combining: \"\n",
    "      f\"{len(combined_gp_dict)}.\")\n",
    "print(f\"Number of gene programs after filtering and combining: \"\n",
    "      f\"{len(combined_new_gp_dict)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d712fe8e-6438-4b1d-9ec8-6b6f4408627b",
   "metadata": {},
   "source": [
    "### 2.2 Define Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ea39b0f-9c9a-459a-ba2e-c843802a8e37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_autotalker_models(dataset,\n",
    "                            reference_batches,\n",
    "                            cell_type_key,\n",
    "                            adata_new=None,\n",
    "                            n_start_run=1,\n",
    "                            n_end_run=10,\n",
    "                            n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16, 20, 20],\n",
    "                            plot_latent_umaps: bool=False):\n",
    "    # Create new adata to store results from training runs in storage-efficient way\n",
    "    if adata_new is None:  \n",
    "        adata_batch_list = []\n",
    "        if reference_batches is not None:\n",
    "            for batch in reference_batches:\n",
    "                adata_batch = ad.read_h5ad(\n",
    "                    f\"{srt_data_gold_folder_path}/{dataset}_{batch}.h5ad\")\n",
    "                adata_batch.obs[mapping_entity_key] = \"reference\"\n",
    "                adata_batch_list.append(adata_batch)\n",
    "            adata_original = ad.concat(adata_batch_list, join=\"inner\")\n",
    "        else:\n",
    "            adata_original = ad.read_h5ad(f\"{srt_data_gold_folder_path}/{dataset}.h5ad\")\n",
    "\n",
    "        adata_new = sc.AnnData(sp.csr_matrix(\n",
    "            (adata_original.shape[0], adata_original.shape[1]),\n",
    "            dtype=np.float32))\n",
    "        adata_new.var_names = adata_original.var_names\n",
    "        adata_new.obs_names = adata_original.obs_names\n",
    "        adata_new.obs[\"cell_type\"] = adata_original.obs[cell_type_key].values\n",
    "        adata_new.obsm[\"spatial\"] = adata_original.obsm[\"spatial\"]\n",
    "        adata_new.obs[condition_key] = adata_original.obs[condition_key]\n",
    "        adata_new.obs[mapping_entity_key] = adata_original.obs[mapping_entity_key] \n",
    "        del(adata_original)\n",
    "    \n",
    "    model_seeds = list(range(10))\n",
    "    for run_number, n_neighbors in zip(np.arange(n_start_run, n_end_run+1), n_neighbor_list):\n",
    "        # Load data\n",
    "        adata_batch_list = []\n",
    "        if reference_batches is not None:\n",
    "            for batch in reference_batches:\n",
    "                print(f\"Processing batch {batch}...\")\n",
    "                print(\"Loading data...\")\n",
    "                adata_batch = ad.read_h5ad(\n",
    "                    f\"{srt_data_gold_folder_path}/{dataset}_{batch}.h5ad\")\n",
    "                adata_batch.obs[mapping_entity_key] = \"reference\"\n",
    "                print(\"Computing spatial neighborhood graph...\\n\")\n",
    "                # Compute (separate) spatial neighborhood graphs\n",
    "                sq.gr.spatial_neighbors(adata_batch,\n",
    "                                        coord_type=\"generic\",\n",
    "                                        spatial_key=spatial_key,\n",
    "                                        n_neighs=n_neighbors)\n",
    "                # Make adjacency matrix symmetric\n",
    "                adata_batch.obsp[adj_key] = (\n",
    "                    adata_batch.obsp[adj_key].maximum(\n",
    "                        adata_batch.obsp[adj_key].T))\n",
    "                adata_batch_list.append(adata_batch)\n",
    "            adata = ad.concat(adata_batch_list, join=\"inner\")\n",
    "\n",
    "            # Combine spatial neighborhood graphs as disconnected components\n",
    "            batch_connectivities = []\n",
    "            len_before_batch = 0\n",
    "            for i in range(len(adata_batch_list)):\n",
    "                if i == 0: # first batch\n",
    "                    after_batch_connectivities_extension = sp.csr_matrix(\n",
    "                        (adata_batch_list[0].shape[0],\n",
    "                        (adata.shape[0] -\n",
    "                        adata_batch_list[0].shape[0])))\n",
    "                    batch_connectivities.append(sp.hstack(\n",
    "                        (adata_batch_list[0].obsp[adj_key],\n",
    "                        after_batch_connectivities_extension)))\n",
    "                elif i == (len(adata_batch_list) - 1): # last batch\n",
    "                    before_batch_connectivities_extension = sp.csr_matrix(\n",
    "                        (adata_batch_list[i].shape[0],\n",
    "                        (adata.shape[0] -\n",
    "                        adata_batch_list[i].shape[0])))\n",
    "                    batch_connectivities.append(sp.hstack(\n",
    "                        (before_batch_connectivities_extension,\n",
    "                        adata_batch_list[i].obsp[adj_key])))\n",
    "                else: # middle batches\n",
    "                    before_batch_connectivities_extension = sp.csr_matrix(\n",
    "                        (adata_batch_list[i].shape[0], len_before_batch))\n",
    "                    after_batch_connectivities_extension = sp.csr_matrix(\n",
    "                        (adata_batch_list[i].shape[0],\n",
    "                        (adata.shape[0] -\n",
    "                        adata_batch_list[i].shape[0] -\n",
    "                        len_before_batch)))\n",
    "                    batch_connectivities.append(sp.hstack(\n",
    "                        (before_batch_connectivities_extension,\n",
    "                        adata_batch_list[i].obsp[adj_key],\n",
    "                        after_batch_connectivities_extension)))\n",
    "                len_before_batch += adata_batch_list[i].shape[0]\n",
    "            connectivities = sp.vstack(batch_connectivities)\n",
    "            adata.obsp[adj_key] = connectivities\n",
    "        else:\n",
    "            adata = ad.read_h5ad(f\"{srt_data_gold_folder_path}/{dataset}.h5ad\")\n",
    "            # Compute (separate) spatial neighborhood graphs\n",
    "            sq.gr.spatial_neighbors(adata,\n",
    "                                    coord_type=\"generic\",\n",
    "                                    spatial_key=spatial_key,\n",
    "                                    n_neighs=n_neighbors)\n",
    "            # Make adjacency matrix symmetric\n",
    "            adata.obsp[adj_key] = (\n",
    "                adata.obsp[adj_key].maximum(\n",
    "                    adata.obsp[adj_key].T))\n",
    "            \n",
    "        # Filter genes if specified\n",
    "        if filter_genes:\n",
    "            print(\"\\nFiltering genes...\")\n",
    "            # Filter genes and only keep ligand, receptor, metabolitye enzyme, \n",
    "            # metabolite sensor and the 'n_hvg' highly variable genes (potential target\n",
    "            # genes of nichenet)\n",
    "            gp_dict_genes = get_unique_genes_from_gp_dict(\n",
    "                gp_dict=combined_new_gp_dict,\n",
    "                retrieved_gene_entities=[\"sources\", \"targets\"])\n",
    "            print(f\"Starting with {len(adata.var_names)} genes.\")\n",
    "            sc.pp.filter_genes(adata,\n",
    "                               min_cells=0)\n",
    "            print(f\"Keeping {len(adata.var_names)} genes after filtering \"\n",
    "                  \"genes with expression in 0 cells.\")\n",
    "\n",
    "            if counts_key is not None:\n",
    "                hvg_layer = counts_key\n",
    "                if (adata.layers[counts_key].astype(int).sum() == \n",
    "                adata.layers[counts_key].sum()): # raw counts\n",
    "                    hvg_flavor = \"seurat_v3\"\n",
    "                else:\n",
    "                    hvg_flavor = \"seurat\" # log normalized counts\n",
    "            else:\n",
    "                hvg_layer = None\n",
    "                if adata.X.astype(int).sum() == adata.X.sum(): # raw counts\n",
    "                    hvg_flavor = \"seurat_v3\"\n",
    "                else: # log normalized counts\n",
    "                    hvg_flavor = \"seurat\"\n",
    "\n",
    "            sc.pp.highly_variable_genes(\n",
    "                adata,\n",
    "                layer=hvg_layer,\n",
    "                n_top_genes=n_hvg,\n",
    "                flavor=hvg_flavor,\n",
    "                batch_key=condition_key,\n",
    "                subset=False)\n",
    "\n",
    "            adata.var[\"gp_relevant\"] = (\n",
    "                adata.var.index.str.upper().isin(gp_relevant_genes))\n",
    "            adata.var[\"keep_gene\"] = (adata.var[\"gp_relevant\"] | \n",
    "                                                adata.var[\"highly_variable\"])\n",
    "            adata = (\n",
    "                adata[:, adata.var[\"keep_gene\"] == True])\n",
    "            print(f\"Keeping {len(adata.var_names)} highly variable or gene \"\n",
    "                  \"program relevant genes.\")\n",
    "            adata = (\n",
    "                adata[:, adata.var_names[\n",
    "                    adata.var_names.str.upper().isin(\n",
    "                        gp_dict_genes)].sort_values()])\n",
    "            print(f\"Keeping {len(adata.var_names)} genes after filtering \"\n",
    "                  \"genes not in gp dict.\")\n",
    "        \n",
    "        # Add the gene program dictionary as binary masks to the adata for model \n",
    "        # training\n",
    "        add_gps_from_gp_dict_to_adata(\n",
    "            gp_dict=combined_new_gp_dict,\n",
    "            adata=adata,\n",
    "            genes_uppercase=True,\n",
    "            gp_targets_mask_key=gp_targets_mask_key,\n",
    "            gp_sources_mask_key=gp_sources_mask_key,\n",
    "            gp_names_key=gp_names_key,\n",
    "            min_genes_per_gp=1,\n",
    "            min_source_genes_per_gp=0,\n",
    "            min_target_genes_per_gp=0,\n",
    "            max_genes_per_gp=None,\n",
    "            max_source_genes_per_gp=None,\n",
    "            max_target_genes_per_gp=None,\n",
    "            filter_genes_not_in_masks=False)\n",
    "\n",
    "        # Determine dimensionality of hidden encoder\n",
    "        n_hidden_encoder = len(adata.uns[gp_names_key]) # int(len(adata.var_names))\n",
    "        n_cond_embed = len(adata.uns[gp_names_key]) # int(len(adata.var_names))\n",
    "\n",
    "        start_time = time.time()\n",
    "        \n",
    "        print(\"\\nTraining model...\")\n",
    "        # Initialize model\n",
    "        model = Autotalker(adata,\n",
    "                           counts_key=counts_key,\n",
    "                           adj_key=adj_key,\n",
    "                           condition_key=condition_key,\n",
    "                           cond_embed_injection=cond_embed_injection,\n",
    "                           n_cond_embed=n_cond_embed,\n",
    "                           gp_names_key=gp_names_key,\n",
    "                           active_gp_names_key=active_gp_names_key,\n",
    "                           gp_targets_mask_key=gp_targets_mask_key,\n",
    "                           gp_sources_mask_key=gp_sources_mask_key,\n",
    "                           latent_key=latent_key,\n",
    "                           active_gp_thresh_ratio=active_gp_thresh_ratio,\n",
    "                           gene_expr_recon_dist=gene_expr_recon_dist,\n",
    "                           n_layers_encoder=n_layers_encoder,\n",
    "                           conv_layer_encoder=conv_layer_encoder,\n",
    "                           n_hidden_encoder=n_hidden_encoder,\n",
    "                           log_variational=log_variational)\n",
    "\n",
    "        # Train model\n",
    "        model.train(n_epochs=n_epochs,\n",
    "                    n_epochs_all_gps=n_epochs_all_gps,\n",
    "                    lr=lr,\n",
    "                    lambda_edge_recon=lambda_edge_recon,\n",
    "                    lambda_gene_expr_recon=lambda_gene_expr_recon,\n",
    "                    lambda_cond_contrastive=lambda_cond_contrastive,\n",
    "                    contrastive_logits_ratio=contrastive_logits_ratio,\n",
    "                    lambda_group_lasso=lambda_group_lasso,\n",
    "                    lambda_l1_masked=lambda_l1_masked,\n",
    "                    edge_batch_size=edge_batch_size,\n",
    "                    node_batch_size=node_batch_size,\n",
    "                    seed=model_seeds[run_number-1],\n",
    "                    verbose=True)        \n",
    "        \n",
    "        # Measure time for model training\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        hours, rem = divmod(elapsed_time, 3600)\n",
    "        minutes, seconds = divmod(rem, 60)\n",
    "        print(f\"Duration of model training in run {run_number}: \"\n",
    "              f\"{int(hours)} hours, {int(minutes)} minutes and {int(seconds)} seconds.\")\n",
    "        adata_new.uns[f\"{model_name}_model_training_duration_run{run_number}\"] = (\n",
    "            elapsed_time)\n",
    "\n",
    "        if plot_latent_umaps:\n",
    "            # Configure figure folder path\n",
    "            dataset_figure_folder_path = f\"{figure_folder_path}/{dataset}/sample_integration_method_benchmarking/\" \\\n",
    "                                         f\"{model_name}/{current_timestamp}\"\n",
    "            os.makedirs(dataset_figure_folder_path, exist_ok=True)\n",
    "            \n",
    "            # Use Autotalker latent space for UMAP generation\n",
    "            sc.pp.neighbors(adata,\n",
    "                            use_rep=latent_key,\n",
    "                            n_neighbors=n_neighbors)\n",
    "            sc.tl.umap(adata)\n",
    "            fig = sc.pl.umap(adata,\n",
    "                             color=[cell_type_key],\n",
    "                             title=f\"Latent Space with Cell Types: {model_name.capitalize()}\",\n",
    "                             return_fig=True)\n",
    "            fig.savefig(f\"{dataset_figure_folder_path}/latent_{model_name}\"\n",
    "                        f\"_cell_types_run{run_number}.png\",\n",
    "                        bbox_inches=\"tight\")\n",
    "\n",
    "            # Compute latent Leiden clustering\n",
    "            sc.tl.leiden(adata=adata,\n",
    "                         resolution=leiden_resolution,\n",
    "                         random_state=random_seed,\n",
    "                         key_added=f\"latent_{model_name}_leiden_{str(leiden_resolution)}\")\n",
    "\n",
    "            # Create subplot of latent Leiden cluster annotations in physical and latent space\n",
    "            fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(6, 12))\n",
    "            title = fig.suptitle(t=\"Latent and Physical Space with Leiden Clusters: \"\n",
    "                                   f\"{model_name.capitalize()}\")\n",
    "            sc.pl.umap(adata=adata,\n",
    "                       color=[f\"latent_{model_name}_leiden_{str(leiden_resolution)}\"],\n",
    "                       title=f\"Latent Space with Leiden Clusters\",\n",
    "                       ax=axs[0],\n",
    "                       show=False)\n",
    "            sq.pl.spatial_scatter(adata=adata,\n",
    "                                  color=[f\"latent_{model_name}_leiden_{str(leiden_resolution)}\"],\n",
    "                                  title=f\"Physical Space with Leiden Clusters\",\n",
    "                                  shape=None,\n",
    "                                  ax=axs[1])\n",
    "\n",
    "            # Create and position shared legend\n",
    "            handles, labels = axs[0].get_legend_handles_labels()\n",
    "            lgd = fig.legend(handles, labels, bbox_to_anchor=(1.25, 0.9185))\n",
    "            axs[0].get_legend().remove()\n",
    "            axs[1].get_legend().remove()\n",
    "\n",
    "            # Adjust, save and display plot\n",
    "            plt.subplots_adjust(wspace=0, hspace=0.2)\n",
    "            fig.savefig(f\"{dataset_figure_folder_path}/latent_physical_comparison_\"\n",
    "                        f\"{model_name}_run{run_number}.png\",\n",
    "                        bbox_extra_artists=(lgd, title),\n",
    "                        bbox_inches=\"tight\")\n",
    "            plt.show()\n",
    "\n",
    "        # Store latent representation\n",
    "        adata_new.obsm[latent_key + f\"_run{run_number}\"] = adata.obsm[latent_key]\n",
    "        \n",
    "        # Use latent representation for UMAP generation\n",
    "        sc.pp.neighbors(adata_new,\n",
    "                        use_rep=f\"{latent_key}_run{run_number}\",\n",
    "                        key_added=f\"{latent_key}_run{run_number}\")\n",
    "        sc.tl.umap(adata_new,\n",
    "                   neighbors_key=f\"{latent_key}_run{run_number}\")\n",
    "        adata_new.obsm[f\"{latent_key}_run{run_number}_X_umap\"] = adata_new.obsm[\"X_umap\"]\n",
    "        del(adata_new.obsm[\"X_umap\"])\n",
    "\n",
    "        # Store intermediate adata to disk\n",
    "        adata_new.write(f\"{srt_data_gold_folder_path}/results/{dataset}_{model_name}_oneshot_integrated.h5ad\")\n",
    "        \n",
    "        # Free memory\n",
    "        del(adata)\n",
    "        del(model)\n",
    "        gc.collect()\n",
    "\n",
    "    # Store final adata to disk\n",
    "    adata_new.write(f\"{srt_data_gold_folder_path}/results/{dataset}_{model_name}_oneshot_integrated.h5ad\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "368dcfcb-d793-47c0-8cb4-5bf8fc6dbc47",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "1 / 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "08c4c314-9412-4198-b326-f140ed1d7851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ef48d85-7c71-4c28-905e-27cb1819458f",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc8f345-ddd2-4a88-b5e2-6106643b20b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Computing spatial neighborhood graph...\n",
      "\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Computing spatial neighborhood graph...\n",
      "\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Computing spatial neighborhood graph...\n",
      "\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Computing spatial neighborhood graph...\n",
      "\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Computing spatial neighborhood graph...\n",
      "\n",
      "Processing batch batch6...\n",
      "Loading data...\n",
      "Computing spatial neighborhood graph...\n",
      "\n",
      "Processing batch batch7...\n",
      "Loading data...\n",
      "Computing spatial neighborhood graph...\n",
      "\n",
      "Processing batch batch8...\n",
      "Loading data...\n",
      "Computing spatial neighborhood graph...\n",
      "\n",
      "Processing batch batch9...\n",
      "Loading data...\n",
      "Computing spatial neighborhood graph...\n",
      "\n",
      "Processing batch batch10...\n",
      "Loading data...\n",
      "Computing spatial neighborhood graph...\n",
      "\n",
      "Processing batch batch11...\n",
      "Loading data...\n",
      "Computing spatial neighborhood graph...\n",
      "\n",
      "Processing batch batch12...\n",
      "Loading data...\n",
      "Computing spatial neighborhood graph...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_autotalker_models(dataset=\"starmap_plus_mouse_cns_subsample_50pct\",\n",
    "                        reference_batches=[f\"batch{i}\" for i in range(1,21)],\n",
    "                        cell_type_key=\"Main_molecular_cell_type\",\n",
    "                        adata_new=None,\n",
    "                        n_start_run=1,\n",
    "                        n_end_run=10,\n",
    "                        n_neighbor_list=[16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "418dc4e9-c406-4a5e-a912-9fbcca26df2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Computing spatial neighborhood graph...\n",
      "\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Computing spatial neighborhood graph...\n",
      "\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Computing spatial neighborhood graph...\n",
      "\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Computing spatial neighborhood graph...\n",
      "\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Computing spatial neighborhood graph...\n",
      "\n",
      "Processing batch batch6...\n",
      "Loading data...\n",
      "Computing spatial neighborhood graph...\n",
      "\n",
      "\n",
      "Training model...\n",
      "--- INITIALIZING NEW NETWORK MODULE: VARIATIONAL GENE PROGRAM GRAPH AUTOENCODER ---\n",
      "LOSS -> include_edge_recon_loss: True, include_gene_expr_recon_loss: True, gene_expr_recon_dist: nb\n",
      "NODE LABEL METHOD -> one-hop-attention\n",
      "ACTIVE GP THRESHOLD RATIO -> 0.05\n",
      "LOG VARIATIONAL -> True\n",
      "CONDITIONAL EMBEDDING INJECTION -> ['gene_expr_decoder']\n",
      "ENCODER -> n_input: 351, n_cond_embed_input: 0, n_layers: 1, n_hidden: 489, n_latent: 489, n_addon_latent: 0, conv_layer: gcnconv, n_attention_heads: 0, dropout_rate: 0.0\n",
      "COSINE SIM GRAPH DECODER -> n_cond_embed_input: 0, n_cond_embed_output: 489, dropout_rate: 0.0\n",
      "MASKED GENE EXPRESSION DECODER -> n_input: 489, n_cond_embed_input: 489, n_addon_input: 0, n_output: 702\n",
      "\n",
      "--- INITIALIZING TRAINER ---\n",
      "Number of training nodes: 47311\n",
      "Number of validation nodes: 5257\n",
      "Number of training edges: 109836\n",
      "Number of validation edges: 12204\n",
      "\n",
      "--- MODEL TRAINING ---\n",
      "Epoch 1/100 |--------------------| 1.0% val_auroc_score: 0.9737; val_auprc_score: 0.9942; val_best_acc_score: 0.9475; val_best_f1_score: 0.9693; train_kl_reg_loss: 121.5021; train_edge_recon_loss: 101410.9542; train_cond_contrastive_loss: 64408.1144; train_gene_expr_recon_loss: 39180.0742; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 205120.6496; train_optim_loss: 140712.5312; val_kl_reg_loss: 198.0952; val_edge_recon_loss: 103246.9766; val_cond_contrastive_loss: 60351.9727; val_gene_expr_recon_loss: 34867.7305; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 198664.7812; val_optim_loss: 198664.7812\n",
      "Epoch 2/100 |--------------------| 2.0% val_auroc_score: 0.9330; val_auprc_score: 0.9845; val_best_acc_score: 0.9296; val_best_f1_score: 0.9595; train_kl_reg_loss: 522.5396; train_edge_recon_loss: 93793.4319; train_cond_contrastive_loss: 57301.1367; train_gene_expr_recon_loss: 34590.6161; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 186207.7299; train_optim_loss: 128906.5904; val_kl_reg_loss: 1395.5653; val_edge_recon_loss: 81157.5234; val_cond_contrastive_loss: 38142.0156; val_gene_expr_recon_loss: 34197.6641; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 154892.7656; val_optim_loss: 154892.7656\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_autotalker_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseqfish_mouse_organogenesis\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mreference_batches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mcell_type_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcelltype_mapped_refined\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                        \u001b[49m\u001b[43madata_new\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mn_start_run\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mn_end_run\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mn_neighbor_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 200\u001b[0m, in \u001b[0;36mtrain_autotalker_models\u001b[0;34m(dataset, reference_batches, cell_type_key, adata_new, n_start_run, n_end_run, n_neighbor_list, plot_latent_umaps)\u001b[0m\n\u001b[1;32m    181\u001b[0m model \u001b[38;5;241m=\u001b[39m Autotalker(adata,\n\u001b[1;32m    182\u001b[0m                    counts_key\u001b[38;5;241m=\u001b[39mcounts_key,\n\u001b[1;32m    183\u001b[0m                    adj_key\u001b[38;5;241m=\u001b[39madj_key,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    196\u001b[0m                    n_hidden_encoder\u001b[38;5;241m=\u001b[39mn_hidden_encoder,\n\u001b[1;32m    197\u001b[0m                    log_variational\u001b[38;5;241m=\u001b[39mlog_variational)\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_epochs_all_gps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs_all_gps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlambda_edge_recon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlambda_edge_recon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlambda_gene_expr_recon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlambda_gene_expr_recon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlambda_cond_contrastive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlambda_cond_contrastive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontrastive_logits_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontrastive_logits_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlambda_group_lasso\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlambda_group_lasso\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlambda_l1_masked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlambda_l1_masked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m            \u001b[49m\u001b[43medge_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnode_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnode_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m            \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_seeds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrun_number\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m        \n\u001b[1;32m    214\u001b[0m \u001b[38;5;66;03m# Measure time for model training\u001b[39;00m\n\u001b[1;32m    215\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/storage/autotalker-reproducibility/notebooks/sample_integration_method_benchmarking/../../../autotalker/autotalker/models/autotalker.py:445\u001b[0m, in \u001b[0;36mAutotalker.train\u001b[0;34m(self, n_epochs, n_epochs_all_gps, n_epochs_no_edge_recon, n_epochs_no_cond_contrastive, lr, weight_decay, lambda_edge_recon, lambda_gene_expr_recon, lambda_cond_contrastive, contrastive_logits_ratio, lambda_group_lasso, lambda_l1_masked, lambda_l1_addon, edge_val_ratio, node_val_ratio, edge_batch_size, node_batch_size, mlflow_experiment_id, retrieve_cond_embeddings, retrieve_recon_edge_probs, retrieve_att_weights, **trainer_kwargs)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_batch_size \u001b[38;5;241m=\u001b[39m node_batch_size\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m    433\u001b[0m     adata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madata,\n\u001b[1;32m    434\u001b[0m     adata_atac\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madata_atac,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    442\u001b[0m     node_batch_size\u001b[38;5;241m=\u001b[39mnode_batch_size,\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrainer_kwargs)\n\u001b[0;32m--> 445\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_epochs_no_edge_recon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs_no_edge_recon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_epochs_no_cond_contrastive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs_no_cond_contrastive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_epochs_all_gps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs_all_gps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlambda_edge_recon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlambda_edge_recon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlambda_gene_expr_recon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlambda_gene_expr_recon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlambda_cond_contrastive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlambda_cond_contrastive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontrastive_logits_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontrastive_logits_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlambda_group_lasso\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlambda_group_lasso\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlambda_l1_masked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlambda_l1_masked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlambda_l1_addon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlambda_l1_addon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmlflow_experiment_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmlflow_experiment_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_trained_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madata\u001b[38;5;241m.\u001b[39mobsm[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatent_key_], _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_latent_representation(\n\u001b[1;32m    463\u001b[0m    adata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madata,\n\u001b[1;32m    464\u001b[0m    counts_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcounts_key_,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    468\u001b[0m    return_mu_std\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    469\u001b[0m    node_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mnode_batch_size_)\n",
      "File \u001b[0;32m~/storage/autotalker-reproducibility/notebooks/sample_integration_method_benchmarking/../../../autotalker/autotalker/train/trainer.py:356\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, n_epochs, n_epochs_all_gps, n_epochs_no_edge_recon, n_epochs_no_cond_contrastive, lr, weight_decay, lambda_edge_recon, lambda_cond_contrastive, contrastive_logits_ratio, lambda_gene_expr_recon, lambda_group_lasso, lambda_l1_masked, lambda_l1_addon, mlflow_experiment_id)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;66;03m# Optimize for training loss\u001b[39;00m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 356\u001b[0m \u001b[43mtrain_optim_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;66;03m# Clip gradients\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad_clip_value_ \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/autotalker/lib/python3.9/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/autotalker/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_autotalker_models(dataset=\"seqfish_mouse_organogenesis\",\n",
    "                        reference_batches=[f\"batch{i}\" for i in range(1,7)],\n",
    "                        cell_type_key=\"celltype_mapped_refined\",\n",
    "                        adata_new=None,\n",
    "                        n_start_run=1,\n",
    "                        n_end_run=10,\n",
    "                        n_neighbor_list=[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43617a84-1c81-473e-b275-c6b15a1b9fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_autotalker_models(dataset=\"seqfish_mouse_organogenesis\",\n",
    "                        reference_batches=[f\"batch{i}\" for i in range(1,7)],\n",
    "                        cell_type_key=\"celltype_mapped_refined\",\n",
    "                        adata_new=None,\n",
    "                        n_start_run=1,\n",
    "                        n_end_run=10,\n",
    "                        n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16, 20, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c47f4c-41bb-44ff-b88f-771e52f1eca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_autotalker_models(dataset=\"starmap_plus_mouse_cns\",\n",
    "                        reference_batches=[f\"batch{i}\" for i in range(1,21)],\n",
    "                        cell_type_key=\"Main_molecular_cell_type\",\n",
    "                        adata_new=None,\n",
    "                        n_start_run=1,\n",
    "                        n_end_run=10,\n",
    "                        n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16, 20, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e2d199-174f-4e6e-aa67-e50149b4c4b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(\"../../datasets/srt_data/gold/seqfish_mouse_organogenesis.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38da8b32-f839-494f-a31a-a19f661c0290",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(\"../../datasets/srt_data/gold/results/seqfish_mouse_organogenesis_autotalker_oneshot_integrated.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b6c04b-e1e7-4825-a9ec-5ee46f66ca8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d92d6d-e323-4a04-ae08-26ee096a02e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")\n",
    "from color_utils import seqfish_mouse_organogenesis_cell_type_colors\n",
    "\n",
    "adata.obsm[\"X_umap\"] = adata.obsm[\"autotalker_latent_run1_X_umap\"]\n",
    "cell_type_key = \"cell_type\"\n",
    "\n",
    "# Plot UMAP with batch annotations\n",
    "fig = sc.pl.umap(adata,\n",
    "                 color=[condition_key],\n",
    "                 legend_fontsize=12,\n",
    "                 size=240000/len(adata),\n",
    "                 return_fig=True)\n",
    "fig.set_figheight(7)\n",
    "fig.set_figwidth(7)\n",
    "plt.title(f\"One-Shot Integration: {model_name} Latent Batch Annotations\", size=20, pad=15)\n",
    "\n",
    "# Plot UMAP with cell type annotations\n",
    "fig = sc.pl.umap(adata,\n",
    "                 color=[cell_type_key],\n",
    "                 palette=seqfish_mouse_organogenesis_cell_type_colors,\n",
    "                 legend_fontsize=12,\n",
    "                 size=240000/len(adata),\n",
    "                 return_fig=True)\n",
    "fig.set_figheight(7)\n",
    "fig.set_figwidth(7)\n",
    "plt.title(f\"One-Shot Integration: {model_name} Latent Cell Type Annotations\", size=20, pad=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee102dc-b9fe-47b8-9fb0-e47cae2bb759",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autotalker.benchmarking import compute_clisis, compute_cas\n",
    "import scib\n",
    "\n",
    "spatial_knng_key = \"autotalker_spatial_knng\"\n",
    "latent_knng_key = \"autotalker_latent_run1\"\n",
    "\n",
    "# Compute metrics\n",
    "metrics_dict = {}\n",
    "\n",
    "# Spatial conservation metrics\n",
    "metrics_dict[\"cas\"] = compute_cas(\n",
    "    adata=adata,\n",
    "    cell_type_key=cell_type_key,\n",
    "    condition_key=condition_key,\n",
    "    spatial_knng_key=spatial_knng_key,\n",
    "    latent_knng_key=latent_knng_key,\n",
    "    spatial_key=spatial_key,\n",
    "    latent_key=latent_key)\n",
    "metrics_dict[\"clisis\"] = compute_clisis(\n",
    "    adata=adata,\n",
    "    cell_type_key=cell_type_key,\n",
    "    condition_key=condition_key,\n",
    "    spatial_knng_key=spatial_knng_key,\n",
    "    latent_knng_key=latent_knng_key,\n",
    "    spatial_key=spatial_key,\n",
    "    latent_key=latent_key)\n",
    "\n",
    "# Batch correction metrics\n",
    "metrics_dict[\"asw\"] = scib.me.silhouette_batch(\n",
    "    adata=adata,\n",
    "    batch_key=condition_key,\n",
    "    label_key=cell_type_key,\n",
    "    embed=latent_key)\n",
    "metrics_dict[\"ilisi\"] = scib.me.ilisi_graph(\n",
    "    adata=adata,\n",
    "    batch_key=condition_key,\n",
    "    type_=\"embed\",\n",
    "    use_rep=latent_key)\n",
    "    #type_=\"knn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b528e64-9ee4-4cc8-9936-a225130b4b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147568e6-b055-4181-900f-d47d5984bf0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
