{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "364a9ebc-3e3c-4645-9049-a34bd084c8a8",
   "metadata": {},
   "source": [
    "# Autotalker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c55227-147e-417f-b0dd-bb0b7f322930",
   "metadata": {},
   "source": [
    "- **Creator**: Sebastian Birk (<sebastian.birk@helmholtz-munich.de>).\n",
    "- **Affiliation:** Helmholtz Munich, Institute of Computational Biology (ICB), Talavera-LÃ³pez Lab\n",
    "- **Date of Creation:** 13.01.2023\n",
    "- **Date of Last Modification:** 31.03.2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa669117-f347-4666-b112-8ea6669fd9e9",
   "metadata": {},
   "source": [
    "- The Autotalker source code is available at https://github.com/Talavera-Lopez-Lab/autotalker.\n",
    "- The workflow of this notebook follows the tutorial from https://github.com/sebastianbirk/autotalker/blob/main/notebooks/autotalker_tutorial.ipynb.\n",
    "- It is recommended to use raw counts as input to Autotalker. Therefore, we use raw counts (stored in adata.layers[\"counts\"])."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7529cde5-be12-403b-a94c-07561774b86c",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faad87bd-fef5-4429-a175-d714c491ae76",
   "metadata": {},
   "source": [
    "### 1.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "149b5fec-87ba-4bd5-a327-5a37065b6223",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9305ecb-5d4b-4cdd-8e92-f7155426b7f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../../autotalker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7f93960-c759-424f-8cb2-1d8698acae2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import gc\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "\n",
    "import anndata as ad\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import scipy.sparse as sp\n",
    "import seaborn as sns\n",
    "import squidpy as sq\n",
    "import torch\n",
    "from matplotlib.pyplot import rc_context\n",
    "\n",
    "from autotalker.models import Autotalker\n",
    "from autotalker.utils import (add_gps_from_gp_dict_to_adata,\n",
    "                              extract_gp_dict_from_mebocost_es_interactions,\n",
    "                              extract_gp_dict_from_nichenet_ligand_target_mx,\n",
    "                              extract_gp_dict_from_omnipath_lr_interactions,\n",
    "                              filter_and_combine_gp_dict_gps,\n",
    "                              get_unique_genes_from_gp_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b5efa5-2052-4986-8ae5-89cfab018515",
   "metadata": {},
   "source": [
    "### 1.2 Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e5c8b48a-ed5e-48b5-8c5c-c1de11493aee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"autotalker\"\n",
    "latent_key = f\"{model_name}_latent\"\n",
    "mapping_entity_key = \"reference\"\n",
    "condition_key = \"batch\"\n",
    "counts_key = \"counts\"\n",
    "spatial_key = \"spatial\"\n",
    "adj_key = \"spatial_connectivities\"\n",
    "nichenet_keep_target_genes_ratio = 0.01\n",
    "nichenet_max_n_target_genes_per_gp = 25344\n",
    "include_mebocost_gps = True\n",
    "mebocost_species = \"mouse\"\n",
    "filter_genes = False\n",
    "gp_filter_mode = \"subset\"\n",
    "combine_overlap_gps = True\n",
    "overlap_thresh_source_genes = 0.9\n",
    "overlap_thresh_target_genes = 0.9\n",
    "overlap_thresh_genes = 0.9\n",
    "active_gp_names_key = \"autotalker_active_gp_names\"\n",
    "gp_targets_mask_key = \"autotalker_gp_targets_mask\"\n",
    "gp_sources_mask_key = \"autotalker_gp_sources_mask\"\n",
    "gp_names_key = \"autotalker_gp_names\"\n",
    "active_gp_thresh_ratio = 0.03\n",
    "gene_expr_recon_dist = \"nb\"\n",
    "cond_embed_injection = [\"encoder\", \"gene_expr_decoder\"]\n",
    "log_variational = True\n",
    "n_layers_encoder = 1\n",
    "conv_layer_encoder = \"gcnconv\"\n",
    "n_epochs = 40\n",
    "n_epochs_all_gps = 20\n",
    "lr = 0.001\n",
    "lambda_edge_recon = 1000.\n",
    "lambda_gene_expr_recon = 1.\n",
    "lambda_cond_contrastive = 500.\n",
    "cond_contrastive_thresh = 0.9\n",
    "lambda_group_lasso = 0.\n",
    "lambda_l1_masked = 0.\n",
    "edge_batch_size = 128\n",
    "node_batch_size = 16\n",
    "leiden_resolution = 0.01 # used for Leiden clustering of latent space; 0.1\n",
    "random_seed = 0 # used for Leiden clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28adc110-0f41-4a71-9838-dc7f0687809a",
   "metadata": {},
   "source": [
    "### 1.3 Run Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "334b87ca-3387-4ba9-8567-84bc4754ff0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sc.set_figure_params(figsize=(6, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ab6b302-1c0b-4937-8624-40629ada2e46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get time of notebook execution for timestamping saved artifacts\n",
    "now = datetime.now()\n",
    "current_timestamp = now.strftime(\"%d%m%Y_%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85538952-006b-4b0b-a50c-fe7445ce22e2",
   "metadata": {},
   "source": [
    "### 1.4 Configure Paths and Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ddcc49c-ba22-4155-acd5-05b5b810e091",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "srt_data_gold_folder_path = \"../../datasets/srt_data/gold\"\n",
    "figure_folder_path = f\"../../figures\"\n",
    "gp_data_folder_path = \"../../datasets/gp_data\" # gene program data\n",
    "nichenet_ligand_target_mx_file_path = gp_data_folder_path + \"/nichenet_ligand_target_matrix.csv\"\n",
    "omnipath_lr_interactions_file_path = gp_data_folder_path + \"/omnipath_lr_interactions.csv\"\n",
    "\n",
    "# Create required directories\n",
    "os.makedirs(gp_data_folder_path, exist_ok=True)\n",
    "os.makedirs(srt_data_gold_folder_path + \"/results\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d974cd00-eafa-4432-b172-fafc4058a619",
   "metadata": {},
   "source": [
    "## 2. Autotalker Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b908c99c-de2f-4239-8420-00bd1fd58baa",
   "metadata": {},
   "source": [
    "### 2.1 Prepare Gene Program Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06c510ab-e3b1-41e7-848d-e4b9513313cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the gene program mask...\n",
      "Number of gene programs before filtering and combining: 1725.\n",
      "Number of gene programs after filtering and combining: 1575.\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing the gene program mask...\")\n",
    "# OmniPath gene programs\n",
    "omnipath_gp_dict = extract_gp_dict_from_omnipath_lr_interactions(\n",
    "    min_curation_effort=0,\n",
    "    load_from_disk=True,\n",
    "    save_to_disk=False,\n",
    "    file_path=omnipath_lr_interactions_file_path,\n",
    "    plot_gp_gene_count_distributions=False)\n",
    "\n",
    "omnipath_genes = get_unique_genes_from_gp_dict(\n",
    "    gp_dict=omnipath_gp_dict,\n",
    "    retrieved_gene_entities=[\"sources\", \"targets\"])\n",
    "\n",
    "# NicheNet gene programs\n",
    "nichenet_gp_dict = extract_gp_dict_from_nichenet_ligand_target_mx(\n",
    "    keep_target_genes_ratio=nichenet_keep_target_genes_ratio,\n",
    "    max_n_target_genes_per_gp=nichenet_max_n_target_genes_per_gp,\n",
    "    load_from_disk=True,\n",
    "    save_to_disk=False,\n",
    "    file_path=nichenet_ligand_target_mx_file_path,\n",
    "    plot_gp_gene_count_distributions=False)\n",
    "\n",
    "nichenet_source_genes = get_unique_genes_from_gp_dict(\n",
    "    gp_dict=nichenet_gp_dict,\n",
    "    retrieved_gene_entities=[\"sources\"])\n",
    "\n",
    "# Combine gene programs into one dictionary\n",
    "combined_gp_dict = dict(omnipath_gp_dict)\n",
    "combined_gp_dict.update(nichenet_gp_dict)\n",
    "\n",
    "if filter_genes:\n",
    "    # Get gene program relevant genes\n",
    "    gp_relevant_genes = list(set(omnipath_genes + nichenet_source_genes))\n",
    "\n",
    "# Mebocost gene programs\n",
    "if include_mebocost_gps:\n",
    "    mebocost_gp_dict = extract_gp_dict_from_mebocost_es_interactions(\n",
    "    dir_path=f\"{gp_data_folder_path}/metabolite_enzyme_sensor_gps/\",\n",
    "    species=mebocost_species,\n",
    "    genes_uppercase=True,\n",
    "    plot_gp_gene_count_distributions=False)\n",
    "    \n",
    "    mebocost_genes = get_unique_genes_from_gp_dict(\n",
    "        gp_dict=mebocost_gp_dict,\n",
    "        retrieved_gene_entities=[\"sources\", \"targets\"])\n",
    "\n",
    "    combined_gp_dict.update(mebocost_gp_dict)\n",
    "    \n",
    "    if filter_genes:\n",
    "        # Update gene program relevant genes\n",
    "        gp_relevant_genes = list(set(gp_relevant_genes + mebocost_genes))\n",
    "    \n",
    "# Filter and combine gene programs\n",
    "combined_new_gp_dict = filter_and_combine_gp_dict_gps(\n",
    "    gp_dict=combined_gp_dict,\n",
    "    gp_filter_mode=gp_filter_mode,\n",
    "    combine_overlap_gps=combine_overlap_gps,\n",
    "    overlap_thresh_source_genes=overlap_thresh_source_genes,\n",
    "    overlap_thresh_target_genes=overlap_thresh_target_genes,\n",
    "    overlap_thresh_genes=overlap_thresh_genes,\n",
    "    verbose=False)\n",
    "\n",
    "print(\"Number of gene programs before filtering and combining: \"\n",
    "      f\"{len(combined_gp_dict)}.\")\n",
    "print(f\"Number of gene programs after filtering and combining: \"\n",
    "      f\"{len(combined_new_gp_dict)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d712fe8e-6438-4b1d-9ec8-6b6f4408627b",
   "metadata": {},
   "source": [
    "### 2.2 Define Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ea39b0f-9c9a-459a-ba2e-c843802a8e37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_autotalker_models(dataset,\n",
    "                            reference_batches,\n",
    "                            cell_type_key,\n",
    "                            adata_new=None,\n",
    "                            n_start_run=1,\n",
    "                            n_end_run=10,\n",
    "                            n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16, 20, 20],\n",
    "                            plot_latent_umaps: bool=False):\n",
    "    # Create new adata to store results from training runs in storage-efficient way\n",
    "    if adata_new is None:  \n",
    "        adata_batch_list = []\n",
    "        if reference_batches is not None:\n",
    "            for batch in reference_batches:\n",
    "                adata_batch = ad.read_h5ad(\n",
    "                    f\"{srt_data_gold_folder_path}/{dataset}_{batch}.h5ad\")\n",
    "                adata_batch.obs[mapping_entity_key] = \"reference\"\n",
    "                adata_batch_list.append(adata_batch)\n",
    "            adata_original = ad.concat(adata_batch_list, join=\"inner\")\n",
    "        else:\n",
    "            adata_original = ad.read_h5ad(f\"{srt_data_gold_folder_path}/{dataset}.h5ad\")\n",
    "\n",
    "        adata_new = sc.AnnData(sp.csr_matrix(\n",
    "            (adata_original.shape[0], adata_original.shape[1]),\n",
    "            dtype=np.float32))\n",
    "        adata_new.var_names = adata_original.var_names\n",
    "        adata_new.obs_names = adata_original.obs_names\n",
    "        adata_new.obs[\"cell_type\"] = adata_original.obs[cell_type_key].values\n",
    "        adata_new.obsm[\"spatial\"] = adata_original.obsm[\"spatial\"]\n",
    "        adata_new.obs[condition_key] = adata_original.obs[condition_key]\n",
    "        adata_new.obs[mapping_entity_key] = adata_original.obs[mapping_entity_key] \n",
    "        del(adata_original)\n",
    "    \n",
    "    model_seeds = list(range(10))\n",
    "    for run_number, n_neighbors in zip(np.arange(n_start_run, n_end_run+1), n_neighbor_list):\n",
    "        # Load data\n",
    "        adata_batch_list = []\n",
    "        if reference_batches is not None:\n",
    "            for batch in reference_batches:\n",
    "                print(f\"Processing batch {batch}...\")\n",
    "                print(\"Loading data...\")\n",
    "                adata_batch = ad.read_h5ad(\n",
    "                    f\"{srt_data_gold_folder_path}/{dataset}_{batch}.h5ad\")\n",
    "                adata_batch.obs[mapping_entity_key] = \"reference\"\n",
    "                print(\"Computing spatial neighborhood graph...\\n\")\n",
    "                # Compute (separate) spatial neighborhood graphs\n",
    "                sq.gr.spatial_neighbors(adata_batch,\n",
    "                                        coord_type=\"generic\",\n",
    "                                        spatial_key=spatial_key,\n",
    "                                        n_neighs=n_neighbors)\n",
    "                # Make adjacency matrix symmetric\n",
    "                adata_batch.obsp[adj_key] = (\n",
    "                    adata_batch.obsp[adj_key].maximum(\n",
    "                        adata_batch.obsp[adj_key].T))\n",
    "                adata_batch_list.append(adata_batch)\n",
    "            adata = ad.concat(adata_batch_list, join=\"inner\")\n",
    "\n",
    "            # Combine spatial neighborhood graphs as disconnected components\n",
    "            batch_connectivities = []\n",
    "            len_before_batch = 0\n",
    "            for i in range(len(adata_batch_list)):\n",
    "                if i == 0: # first batch\n",
    "                    after_batch_connectivities_extension = sp.csr_matrix(\n",
    "                        (adata_batch_list[0].shape[0],\n",
    "                        (adata.shape[0] -\n",
    "                        adata_batch_list[0].shape[0])))\n",
    "                    batch_connectivities.append(sp.hstack(\n",
    "                        (adata_batch_list[0].obsp[adj_key],\n",
    "                        after_batch_connectivities_extension)))\n",
    "                elif i == (len(adata_batch_list) - 1): # last batch\n",
    "                    before_batch_connectivities_extension = sp.csr_matrix(\n",
    "                        (adata_batch_list[i].shape[0],\n",
    "                        (adata.shape[0] -\n",
    "                        adata_batch_list[i].shape[0])))\n",
    "                    batch_connectivities.append(sp.hstack(\n",
    "                        (before_batch_connectivities_extension,\n",
    "                        adata_batch_list[i].obsp[adj_key])))\n",
    "                else: # middle batches\n",
    "                    before_batch_connectivities_extension = sp.csr_matrix(\n",
    "                        (adata_batch_list[i].shape[0], len_before_batch))\n",
    "                    after_batch_connectivities_extension = sp.csr_matrix(\n",
    "                        (adata_batch_list[i].shape[0],\n",
    "                        (adata.shape[0] -\n",
    "                        adata_batch_list[i].shape[0] -\n",
    "                        len_before_batch)))\n",
    "                    batch_connectivities.append(sp.hstack(\n",
    "                        (before_batch_connectivities_extension,\n",
    "                        adata_batch_list[i].obsp[adj_key],\n",
    "                        after_batch_connectivities_extension)))\n",
    "                len_before_batch += adata_batch_list[i].shape[0]\n",
    "            connectivities = sp.vstack(batch_connectivities)\n",
    "            adata.obsp[adj_key] = connectivities\n",
    "        else:\n",
    "            adata = ad.read_h5ad(f\"{srt_data_gold_folder_path}/{dataset}.h5ad\")\n",
    "            # Compute (separate) spatial neighborhood graphs\n",
    "            sq.gr.spatial_neighbors(adata,\n",
    "                                    coord_type=\"generic\",\n",
    "                                    spatial_key=spatial_key,\n",
    "                                    n_neighs=n_neighbors)\n",
    "            # Make adjacency matrix symmetric\n",
    "            adata.obsp[adj_key] = (\n",
    "                adata.obsp[adj_key].maximum(\n",
    "                    adata.obsp[adj_key].T))\n",
    "            \n",
    "        # Filter genes if specified\n",
    "        if filter_genes:\n",
    "            print(\"\\nFiltering genes...\")\n",
    "            # Filter genes and only keep ligand, receptor, metabolitye enzyme, \n",
    "            # metabolite sensor and the 'n_hvg' highly variable genes (potential target\n",
    "            # genes of nichenet)\n",
    "            gp_dict_genes = get_unique_genes_from_gp_dict(\n",
    "                gp_dict=combined_new_gp_dict,\n",
    "                retrieved_gene_entities=[\"sources\", \"targets\"])\n",
    "            print(f\"Starting with {len(adata.var_names)} genes.\")\n",
    "            sc.pp.filter_genes(adata,\n",
    "                               min_cells=0)\n",
    "            print(f\"Keeping {len(adata.var_names)} genes after filtering \"\n",
    "                  \"genes with expression in 0 cells.\")\n",
    "\n",
    "            if counts_key is not None:\n",
    "                hvg_layer = counts_key\n",
    "                if (adata.layers[counts_key].astype(int).sum() == \n",
    "                adata.layers[counts_key].sum()): # raw counts\n",
    "                    hvg_flavor = \"seurat_v3\"\n",
    "                else:\n",
    "                    hvg_flavor = \"seurat\" # log normalized counts\n",
    "            else:\n",
    "                hvg_layer = None\n",
    "                if adata.X.astype(int).sum() == adata.X.sum(): # raw counts\n",
    "                    hvg_flavor = \"seurat_v3\"\n",
    "                else: # log normalized counts\n",
    "                    hvg_flavor = \"seurat\"\n",
    "\n",
    "            sc.pp.highly_variable_genes(\n",
    "                adata,\n",
    "                layer=hvg_layer,\n",
    "                n_top_genes=n_hvg,\n",
    "                flavor=hvg_flavor,\n",
    "                batch_key=condition_key,\n",
    "                subset=False)\n",
    "\n",
    "            adata.var[\"gp_relevant\"] = (\n",
    "                adata.var.index.str.upper().isin(gp_relevant_genes))\n",
    "            adata.var[\"keep_gene\"] = (adata.var[\"gp_relevant\"] | \n",
    "                                                adata.var[\"highly_variable\"])\n",
    "            adata = (\n",
    "                adata[:, adata.var[\"keep_gene\"] == True])\n",
    "            print(f\"Keeping {len(adata.var_names)} highly variable or gene \"\n",
    "                  \"program relevant genes.\")\n",
    "            adata = (\n",
    "                adata[:, adata.var_names[\n",
    "                    adata.var_names.str.upper().isin(\n",
    "                        gp_dict_genes)].sort_values()])\n",
    "            print(f\"Keeping {len(adata.var_names)} genes after filtering \"\n",
    "                  \"genes not in gp dict.\")\n",
    "        \n",
    "        # Add the gene program dictionary as binary masks to the adata for model \n",
    "        # training\n",
    "        add_gps_from_gp_dict_to_adata(\n",
    "            gp_dict=combined_new_gp_dict,\n",
    "            adata=adata,\n",
    "            genes_uppercase=True,\n",
    "            gp_targets_mask_key=gp_targets_mask_key,\n",
    "            gp_sources_mask_key=gp_sources_mask_key,\n",
    "            gp_names_key=gp_names_key,\n",
    "            min_genes_per_gp=1,\n",
    "            min_source_genes_per_gp=0,\n",
    "            min_target_genes_per_gp=0,\n",
    "            max_genes_per_gp=None,\n",
    "            max_source_genes_per_gp=None,\n",
    "            max_target_genes_per_gp=None,\n",
    "            filter_genes_not_in_masks=False)\n",
    "\n",
    "        # Determine dimensionality of hidden encoder\n",
    "        n_hidden_encoder = len(adata.uns[f\"{model_name}_gp_names\"])\n",
    "        n_cond_embed = int(len(adata.var_names) / 2)\n",
    "\n",
    "        start_time = time.time()\n",
    "        \n",
    "        print(\"\\nTraining model...\")\n",
    "        # Initialize model\n",
    "        model = Autotalker(adata,\n",
    "                           counts_key=counts_key,\n",
    "                           adj_key=adj_key,\n",
    "                           condition_key=condition_key,\n",
    "                           cond_embed_injection=cond_embed_injection,\n",
    "                           n_cond_embed=n_cond_embed,\n",
    "                           gp_names_key=gp_names_key,\n",
    "                           active_gp_names_key=active_gp_names_key,\n",
    "                           gp_targets_mask_key=gp_targets_mask_key,\n",
    "                           gp_sources_mask_key=gp_sources_mask_key,\n",
    "                           latent_key=latent_key,\n",
    "                           active_gp_thresh_ratio=active_gp_thresh_ratio,\n",
    "                           gene_expr_recon_dist=gene_expr_recon_dist,\n",
    "                           n_layers_encoder=n_layers_encoder,\n",
    "                           conv_layer_encoder=conv_layer_encoder,\n",
    "                           n_hidden_encoder=n_hidden_encoder,\n",
    "                           log_variational=log_variational)\n",
    "\n",
    "        # Train model\n",
    "        model.train(n_epochs=n_epochs,\n",
    "                    n_epochs_all_gps=n_epochs_all_gps,\n",
    "                    lr=lr,\n",
    "                    lambda_edge_recon=lambda_edge_recon,\n",
    "                    lambda_gene_expr_recon=lambda_gene_expr_recon,\n",
    "                    lambda_cond_contrastive=lambda_cond_contrastive,\n",
    "                    cond_contrastive_thresh=cond_contrastive_thresh,\n",
    "                    lambda_group_lasso=lambda_group_lasso,\n",
    "                    lambda_l1_masked=lambda_l1_masked,\n",
    "                    edge_batch_size=edge_batch_size,\n",
    "                    node_batch_size=node_batch_size,\n",
    "                    seed=model_seeds[run_number-1],\n",
    "                    verbose=True)        \n",
    "        \n",
    "        # Measure time for model training\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        hours, rem = divmod(elapsed_time, 3600)\n",
    "        minutes, seconds = divmod(rem, 60)\n",
    "        print(f\"Duration of model training in run {run_number}: \"\n",
    "              f\"{int(hours)} hours, {int(minutes)} minutes and {int(seconds)} seconds.\")\n",
    "        adata_new.uns[f\"{model_name}_model_training_duration_run{run_number}\"] = (\n",
    "            elapsed_time)\n",
    "\n",
    "        if plot_latent_umaps:\n",
    "            # Configure figure folder path\n",
    "            dataset_figure_folder_path = f\"{figure_folder_path}/{dataset}/sample_integration_method_benchmarking/\" \\\n",
    "                                         f\"{model_name}/{current_timestamp}\"\n",
    "            os.makedirs(dataset_figure_folder_path, exist_ok=True)\n",
    "            \n",
    "            # Use Autotalker latent space for UMAP generation\n",
    "            sc.pp.neighbors(adata,\n",
    "                            use_rep=latent_key,\n",
    "                            n_neighbors=n_neighbors)\n",
    "            sc.tl.umap(adata)\n",
    "            fig = sc.pl.umap(adata,\n",
    "                             color=[cell_type_key],\n",
    "                             title=f\"Latent Space with Cell Types: {model_name.capitalize()}\",\n",
    "                             return_fig=True)\n",
    "            fig.savefig(f\"{dataset_figure_folder_path}/latent_{model_name}\"\n",
    "                        f\"_cell_types_run{run_number}.png\",\n",
    "                        bbox_inches=\"tight\")\n",
    "\n",
    "            # Compute latent Leiden clustering\n",
    "            sc.tl.leiden(adata=adata,\n",
    "                         resolution=leiden_resolution,\n",
    "                         random_state=random_seed,\n",
    "                         key_added=f\"latent_{model_name}_leiden_{str(leiden_resolution)}\")\n",
    "\n",
    "            # Create subplot of latent Leiden cluster annotations in physical and latent space\n",
    "            fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(6, 12))\n",
    "            title = fig.suptitle(t=\"Latent and Physical Space with Leiden Clusters: \"\n",
    "                                   f\"{model_name.capitalize()}\")\n",
    "            sc.pl.umap(adata=adata,\n",
    "                       color=[f\"latent_{model_name}_leiden_{str(leiden_resolution)}\"],\n",
    "                       title=f\"Latent Space with Leiden Clusters\",\n",
    "                       ax=axs[0],\n",
    "                       show=False)\n",
    "            sq.pl.spatial_scatter(adata=adata,\n",
    "                                  color=[f\"latent_{model_name}_leiden_{str(leiden_resolution)}\"],\n",
    "                                  title=f\"Physical Space with Leiden Clusters\",\n",
    "                                  shape=None,\n",
    "                                  ax=axs[1])\n",
    "\n",
    "            # Create and position shared legend\n",
    "            handles, labels = axs[0].get_legend_handles_labels()\n",
    "            lgd = fig.legend(handles, labels, bbox_to_anchor=(1.25, 0.9185))\n",
    "            axs[0].get_legend().remove()\n",
    "            axs[1].get_legend().remove()\n",
    "\n",
    "            # Adjust, save and display plot\n",
    "            plt.subplots_adjust(wspace=0, hspace=0.2)\n",
    "            fig.savefig(f\"{dataset_figure_folder_path}/latent_physical_comparison_\"\n",
    "                        f\"{model_name}_run{run_number}.png\",\n",
    "                        bbox_extra_artists=(lgd, title),\n",
    "                        bbox_inches=\"tight\")\n",
    "            plt.show()\n",
    "\n",
    "        # Store latent representation\n",
    "        adata_new.obsm[latent_key + f\"_run{run_number}\"] = adata.obsm[latent_key]\n",
    "        \n",
    "        # Use latent representation for UMAP generation\n",
    "        sc.pp.neighbors(adata_new,\n",
    "                        use_rep=f\"{latent_key}_run{run_number}\",\n",
    "                        key_added=f\"{latent_key}_run{run_number}\")\n",
    "        sc.tl.umap(adata_new,\n",
    "                   neighbors_key=f\"{latent_key}_run{run_number}\")\n",
    "        adata_new.obsm[f\"{latent_key}_run{run_number}_X_umap\"] = adata_new.obsm[\"X_umap\"]\n",
    "        del(adata_new.obsm[\"X_umap\"])\n",
    "\n",
    "        # Store intermediate adata to disk\n",
    "        adata_new.write(f\"{srt_data_gold_folder_path}/results/{dataset}_{model_name}_oneshot_integrated.h5ad\")\n",
    "        \n",
    "        # Free memory\n",
    "        del(adata)\n",
    "        del(model)\n",
    "        gc.collect()\n",
    "\n",
    "    # Store final adata to disk\n",
    "    adata_new.write(f\"{srt_data_gold_folder_path}/results/{dataset}_{model_name}_oneshot_integrated.h5ad\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5471d723-2807-44a9-aea2-4736131b614d",
   "metadata": {},
   "source": [
    "### 2.3 Train Models on Benchmarking Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3592bdd4-a763-4323-ae3a-8087f4c77af9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Computing spatial neighborhood graph...\n",
      "\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Computing spatial neighborhood graph...\n",
      "\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Computing spatial neighborhood graph...\n",
      "\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Computing spatial neighborhood graph...\n",
      "\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Computing spatial neighborhood graph...\n",
      "\n",
      "Processing batch batch6...\n",
      "Loading data...\n",
      "Computing spatial neighborhood graph...\n",
      "\n",
      "\n",
      "Training model...\n",
      "--- INITIALIZING NEW NETWORK MODULE: VARIATIONAL GENE PROGRAM GRAPH AUTOENCODER ---\n",
      "LOSS -> include_edge_recon_loss: True, include_gene_expr_recon_loss: True, gene_expr_recon_dist: nb\n",
      "NODE LABEL METHOD -> one-hop-attention\n",
      "ACTIVE GP THRESHOLD RATIO -> 0.03\n",
      "LOG VARIATIONAL -> True\n",
      "CONDITIONAL EMBEDDING INJECTION -> ['encoder', 'gene_expr_decoder']\n",
      "GRAPH ENCODER -> n_input: 351, n_cond_embed_input: 175, n_layers: 1, n_hidden: 489, n_latent: 489, n_addon_latent: 0, conv_layer: gcnconv, n_attention_heads: 0, dropout_rate: 0.0\n",
      "COSINE SIM GRAPH DECODER -> n_cond_embed_input: 0, n_output: 489, dropout_rate: 0.0\n",
      "MASKED GENE EXPRESSION DECODER -> n_input: 489, n_cond_embed_input: 175, n_addon_input: 0, n_output: 702\n",
      "\n",
      "--- INITIALIZING TRAINER ---\n",
      "Number of training nodes: 47311\n",
      "Number of validation nodes: 5257\n",
      "Number of training edges: 109836\n",
      "Number of validation edges: 12204\n",
      "\n",
      "--- MODEL TRAINING ---\n",
      "Epoch 1/40 |--------------------| 2.5% val_auroc_score: 0.9366; val_auprc_score: 0.9143; val_best_acc_score: 0.8894; val_best_f1_score: 0.8952; train_kl_reg_loss: 0.3546; train_edge_recon_loss: 165.2211; train_cond_contrastive_loss: 377.3786; train_gene_expr_recon_loss: 320.7127; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 863.6670; train_optim_loss: 863.6670; val_kl_reg_loss: 0.4641; val_edge_recon_loss: 163.1607; val_cond_contrastive_loss: 486.0818; val_gene_expr_recon_loss: 307.8810; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 957.5875; val_optim_loss: 957.5875\n",
      "Epoch 2/40 |â-------------------| 5.0% val_auroc_score: 0.9415; val_auprc_score: 0.9197; val_best_acc_score: 0.9035; val_best_f1_score: 0.9064; train_kl_reg_loss: 0.5204; train_edge_recon_loss: 155.6318; train_cond_contrastive_loss: 483.0056; train_gene_expr_recon_loss: 303.2717; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 942.4295; train_optim_loss: 942.4295; val_kl_reg_loss: 0.5729; val_edge_recon_loss: 156.9722; val_cond_contrastive_loss: 481.9099; val_gene_expr_recon_loss: 303.7816; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 943.2366; val_optim_loss: 943.2366\n",
      "Epoch 3/40 |â-------------------| 7.5% val_auroc_score: 0.9399; val_auprc_score: 0.9126; val_best_acc_score: 0.9090; val_best_f1_score: 0.9121; train_kl_reg_loss: 0.5967; train_edge_recon_loss: 154.0651; train_cond_contrastive_loss: 481.0546; train_gene_expr_recon_loss: 297.9741; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 933.6905; train_optim_loss: 933.6905; val_kl_reg_loss: 0.6237; val_edge_recon_loss: 154.1461; val_cond_contrastive_loss: 476.5406; val_gene_expr_recon_loss: 294.7557; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 926.0660; val_optim_loss: 926.0660\n",
      "Epoch 4/40 |ââ------------------| 10.0% val_auroc_score: 0.9341; val_auprc_score: 0.9034; val_best_acc_score: 0.9088; val_best_f1_score: 0.9116; train_kl_reg_loss: 0.6347; train_edge_recon_loss: 154.5957; train_cond_contrastive_loss: 476.4816; train_gene_expr_recon_loss: 293.3508; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 925.0628; train_optim_loss: 925.0628; val_kl_reg_loss: 0.6521; val_edge_recon_loss: 161.2102; val_cond_contrastive_loss: 476.1931; val_gene_expr_recon_loss: 291.7257; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 929.7811; val_optim_loss: 929.7811\n",
      "Epoch 5/40 |ââ------------------| 12.5% val_auroc_score: 0.9385; val_auprc_score: 0.9091; val_best_acc_score: 0.9126; val_best_f1_score: 0.9160; train_kl_reg_loss: 0.6441; train_edge_recon_loss: 152.8241; train_cond_contrastive_loss: 476.6822; train_gene_expr_recon_loss: 288.9987; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 919.1491; train_optim_loss: 919.1491; val_kl_reg_loss: 0.6509; val_edge_recon_loss: 156.3102; val_cond_contrastive_loss: 475.8021; val_gene_expr_recon_loss: 289.9784; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 922.7416; val_optim_loss: 922.7416\n",
      "Epoch 6/40 |âââ-----------------| 15.0% val_auroc_score: 0.9381; val_auprc_score: 0.9083; val_best_acc_score: 0.9132; val_best_f1_score: 0.9170; train_kl_reg_loss: 0.6519; train_edge_recon_loss: 152.8146; train_cond_contrastive_loss: 475.6650; train_gene_expr_recon_loss: 287.2882; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 916.4197; train_optim_loss: 916.4197; val_kl_reg_loss: 0.6679; val_edge_recon_loss: 152.9860; val_cond_contrastive_loss: 476.4335; val_gene_expr_recon_loss: 287.3534; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 917.4409; val_optim_loss: 917.4409\n",
      "Epoch 7/40 |âââ-----------------| 17.5% val_auroc_score: 0.9322; val_auprc_score: 0.8993; val_best_acc_score: 0.9122; val_best_f1_score: 0.9169; train_kl_reg_loss: 0.6613; train_edge_recon_loss: 155.0087; train_cond_contrastive_loss: 476.2975; train_gene_expr_recon_loss: 285.4611; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 917.4287; train_optim_loss: 917.4287; val_kl_reg_loss: 0.6697; val_edge_recon_loss: 154.3871; val_cond_contrastive_loss: 473.8974; val_gene_expr_recon_loss: 283.7997; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 912.7539; val_optim_loss: 912.7539\n",
      "Epoch 8/40 |ââââ----------------| 20.0% val_auroc_score: 0.9299; val_auprc_score: 0.8958; val_best_acc_score: 0.9120; val_best_f1_score: 0.9165; train_kl_reg_loss: 0.6668; train_edge_recon_loss: 155.8750; train_cond_contrastive_loss: 474.5549; train_gene_expr_recon_loss: 284.3376; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 915.4343; train_optim_loss: 915.4343; val_kl_reg_loss: 0.6711; val_edge_recon_loss: 163.1259; val_cond_contrastive_loss: 474.5768; val_gene_expr_recon_loss: 282.1167; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 920.4905; val_optim_loss: 920.4905\n",
      "Epoch 9/40 |ââââ----------------| 22.5% val_auroc_score: 0.9347; val_auprc_score: 0.9025; val_best_acc_score: 0.9139; val_best_f1_score: 0.9173; train_kl_reg_loss: 0.6683; train_edge_recon_loss: 154.6726; train_cond_contrastive_loss: 473.2381; train_gene_expr_recon_loss: 282.4162; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 910.9952; train_optim_loss: 910.9952; val_kl_reg_loss: 0.6830; val_edge_recon_loss: 160.3965; val_cond_contrastive_loss: 470.2566; val_gene_expr_recon_loss: 280.7538; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 912.0898; val_optim_loss: 912.0898\n",
      "Epoch 10/40 |âââââ---------------| 25.0% val_auroc_score: 0.9326; val_auprc_score: 0.8982; val_best_acc_score: 0.9125; val_best_f1_score: 0.9159; train_kl_reg_loss: 0.6778; train_edge_recon_loss: 154.2214; train_cond_contrastive_loss: 474.6171; train_gene_expr_recon_loss: 282.6557; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 912.1720; train_optim_loss: 912.1720; val_kl_reg_loss: 0.6804; val_edge_recon_loss: 159.4444; val_cond_contrastive_loss: 474.1722; val_gene_expr_recon_loss: 277.6681; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 911.9651; val_optim_loss: 911.9651\n",
      "Epoch 11/40 |âââââ---------------| 27.5% val_auroc_score: 0.9324; val_auprc_score: 0.8994; val_best_acc_score: 0.9126; val_best_f1_score: 0.9168; train_kl_reg_loss: 0.6791; train_edge_recon_loss: 155.4184; train_cond_contrastive_loss: 473.4417; train_gene_expr_recon_loss: 280.0150; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 909.5542; train_optim_loss: 909.5542; val_kl_reg_loss: 0.6858; val_edge_recon_loss: 160.2697; val_cond_contrastive_loss: 473.3933; val_gene_expr_recon_loss: 276.6082; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 910.9571; val_optim_loss: 910.9571\n",
      "Epoch 12/40 |ââââââ--------------| 30.0% val_auroc_score: 0.9335; val_auprc_score: 0.8978; val_best_acc_score: 0.9133; val_best_f1_score: 0.9164; train_kl_reg_loss: 0.6845; train_edge_recon_loss: 153.6935; train_cond_contrastive_loss: 473.9949; train_gene_expr_recon_loss: 279.0976; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 907.4706; train_optim_loss: 907.4706; val_kl_reg_loss: 0.6898; val_edge_recon_loss: 156.0746; val_cond_contrastive_loss: 475.2682; val_gene_expr_recon_loss: 280.5955; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 912.6280; val_optim_loss: 912.6280\n",
      "Epoch 13/40 |ââââââ--------------| 32.5% val_auroc_score: 0.9347; val_auprc_score: 0.8997; val_best_acc_score: 0.9169; val_best_f1_score: 0.9206; train_kl_reg_loss: 0.6909; train_edge_recon_loss: 153.3242; train_cond_contrastive_loss: 472.9089; train_gene_expr_recon_loss: 279.7669; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 906.6909; train_optim_loss: 906.6909; val_kl_reg_loss: 0.7023; val_edge_recon_loss: 158.5266; val_cond_contrastive_loss: 473.5087; val_gene_expr_recon_loss: 276.4623; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 909.1998; val_optim_loss: 909.1998\n",
      "Epoch 14/40 |âââââââ-------------| 35.0% val_auroc_score: 0.9327; val_auprc_score: 0.8963; val_best_acc_score: 0.9156; val_best_f1_score: 0.9186; train_kl_reg_loss: 0.6962; train_edge_recon_loss: 154.8572; train_cond_contrastive_loss: 473.8330; train_gene_expr_recon_loss: 277.7933; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 907.1796; train_optim_loss: 907.1796; val_kl_reg_loss: 0.7056; val_edge_recon_loss: 158.2476; val_cond_contrastive_loss: 474.4132; val_gene_expr_recon_loss: 279.5128; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 912.8792; val_optim_loss: 912.8792\n",
      "Epoch 15/40 |âââââââ-------------| 37.5% val_auroc_score: 0.9293; val_auprc_score: 0.8922; val_best_acc_score: 0.9138; val_best_f1_score: 0.9176; train_kl_reg_loss: 0.7022; train_edge_recon_loss: 155.0547; train_cond_contrastive_loss: 474.4704; train_gene_expr_recon_loss: 278.0152; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 908.2425; train_optim_loss: 908.2425; val_kl_reg_loss: 0.7073; val_edge_recon_loss: 159.7216; val_cond_contrastive_loss: 473.4376; val_gene_expr_recon_loss: 281.1500; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 915.0166; val_optim_loss: 915.0166\n",
      "Epoch 16/40 |ââââââââ------------| 40.0% val_auroc_score: 0.9362; val_auprc_score: 0.9034; val_best_acc_score: 0.9159; val_best_f1_score: 0.9196; train_kl_reg_loss: 0.7129; train_edge_recon_loss: 152.5559; train_cond_contrastive_loss: 471.6191; train_gene_expr_recon_loss: 277.2283; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 902.1162; train_optim_loss: 902.1162; val_kl_reg_loss: 0.7235; val_edge_recon_loss: 152.8025; val_cond_contrastive_loss: 473.6762; val_gene_expr_recon_loss: 277.7520; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 904.9542; val_optim_loss: 904.9542\n",
      "Epoch 17/40 |ââââââââ------------| 42.5% val_auroc_score: 0.9307; val_auprc_score: 0.8936; val_best_acc_score: 0.9141; val_best_f1_score: 0.9179; train_kl_reg_loss: 0.7218; train_edge_recon_loss: 153.5926; train_cond_contrastive_loss: 472.8525; train_gene_expr_recon_loss: 275.7934; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 902.9603; train_optim_loss: 902.9603; val_kl_reg_loss: 0.7301; val_edge_recon_loss: 153.1394; val_cond_contrastive_loss: 474.0223; val_gene_expr_recon_loss: 279.8885; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 907.7803; val_optim_loss: 907.7803\n",
      "Epoch 18/40 |âââââââââ-----------| 45.0% val_auroc_score: 0.9340; val_auprc_score: 0.8986; val_best_acc_score: 0.9153; val_best_f1_score: 0.9185; train_kl_reg_loss: 0.7215; train_edge_recon_loss: 153.7329; train_cond_contrastive_loss: 472.8766; train_gene_expr_recon_loss: 276.6954; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 904.0265; train_optim_loss: 904.0265; val_kl_reg_loss: 0.7288; val_edge_recon_loss: 157.2599; val_cond_contrastive_loss: 474.0846; val_gene_expr_recon_loss: 278.7898; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 910.8632; val_optim_loss: 910.8632\n",
      "Epoch 19/40 |âââââââââ-----------| 47.5% val_auroc_score: 0.9354; val_auprc_score: 0.8993; val_best_acc_score: 0.9203; val_best_f1_score: 0.9234; train_kl_reg_loss: 0.7332; train_edge_recon_loss: 155.0584; train_cond_contrastive_loss: 470.9957; train_gene_expr_recon_loss: 276.7868; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 903.5740; train_optim_loss: 903.5740; val_kl_reg_loss: 0.7388; val_edge_recon_loss: 157.0208; val_cond_contrastive_loss: 472.9263; val_gene_expr_recon_loss: 272.5978; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 903.2836; val_optim_loss: 903.2836\n",
      "Epoch 20/40 |ââââââââââ----------| 50.0% val_auroc_score: 0.9353; val_auprc_score: 0.9009; val_best_acc_score: 0.9186; val_best_f1_score: 0.9225; train_kl_reg_loss: 0.7420; train_edge_recon_loss: 153.9576; train_cond_contrastive_loss: 471.7865; train_gene_expr_recon_loss: 276.0859; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 902.5721; train_optim_loss: 902.5721; val_kl_reg_loss: 0.7406; val_edge_recon_loss: 154.4095; val_cond_contrastive_loss: 474.3163; val_gene_expr_recon_loss: 274.4645; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 903.9309; val_optim_loss: 903.9309\n",
      "Epoch 21/40 |ââââââââââ----------| 52.5% val_auroc_score: 0.9280; val_auprc_score: 0.8888; val_best_acc_score: 0.9137; val_best_f1_score: 0.9173; train_kl_reg_loss: 0.7453; train_edge_recon_loss: 154.4588; train_cond_contrastive_loss: 474.0517; train_gene_expr_recon_loss: 275.0078; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 904.2636; train_optim_loss: 904.2636; val_kl_reg_loss: 0.6553; val_edge_recon_loss: 163.3988; val_cond_contrastive_loss: 468.6799; val_gene_expr_recon_loss: 276.7732; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 909.5071; val_optim_loss: 909.5071\n",
      "Epoch 22/40 |âââââââââââ---------| 55.0% val_auroc_score: 0.9267; val_auprc_score: 0.8857; val_best_acc_score: 0.9118; val_best_f1_score: 0.9157; train_kl_reg_loss: 0.7406; train_edge_recon_loss: 154.1578; train_cond_contrastive_loss: 473.1472; train_gene_expr_recon_loss: 274.9879; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 903.0334; train_optim_loss: 903.0334; val_kl_reg_loss: 0.6605; val_edge_recon_loss: 161.1151; val_cond_contrastive_loss: 473.4036; val_gene_expr_recon_loss: 274.2131; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 909.3923; val_optim_loss: 909.3923\n",
      "\n",
      "Reducing learning rate: metric has not improved more than 0.0 in the last 3 epochs.\n",
      "New learning rate is 0.0001.\n",
      "\n",
      "Epoch 23/40 |âââââââââââ---------| 57.5% val_auroc_score: 0.9291; val_auprc_score: 0.8912; val_best_acc_score: 0.9142; val_best_f1_score: 0.9182; train_kl_reg_loss: 0.7363; train_edge_recon_loss: 155.2192; train_cond_contrastive_loss: 473.5113; train_gene_expr_recon_loss: 272.6123; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 902.0791; train_optim_loss: 902.0791; val_kl_reg_loss: 0.6521; val_edge_recon_loss: 156.6149; val_cond_contrastive_loss: 472.8328; val_gene_expr_recon_loss: 272.7484; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 902.8482; val_optim_loss: 902.8482\n",
      "Epoch 24/40 |ââââââââââââ--------| 60.0% val_auroc_score: 0.9314; val_auprc_score: 0.8910; val_best_acc_score: 0.9145; val_best_f1_score: 0.9176; train_kl_reg_loss: 0.7294; train_edge_recon_loss: 154.2908; train_cond_contrastive_loss: 473.2307; train_gene_expr_recon_loss: 272.3847; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 900.6357; train_optim_loss: 900.6357; val_kl_reg_loss: 0.6450; val_edge_recon_loss: 154.7888; val_cond_contrastive_loss: 473.1317; val_gene_expr_recon_loss: 273.3086; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 901.8741; val_optim_loss: 901.8741\n",
      "Epoch 25/40 |ââââââââââââ--------| 62.5% val_auroc_score: 0.9321; val_auprc_score: 0.8955; val_best_acc_score: 0.9180; val_best_f1_score: 0.9214; train_kl_reg_loss: 0.7191; train_edge_recon_loss: 153.3367; train_cond_contrastive_loss: 473.0773; train_gene_expr_recon_loss: 273.1876; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 900.3207; train_optim_loss: 900.3207; val_kl_reg_loss: 0.6386; val_edge_recon_loss: 156.6274; val_cond_contrastive_loss: 472.3402; val_gene_expr_recon_loss: 275.5222; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 905.1284; val_optim_loss: 905.1284\n",
      "Epoch 26/40 |âââââââââââââ-------| 65.0% val_auroc_score: 0.9315; val_auprc_score: 0.8932; val_best_acc_score: 0.9148; val_best_f1_score: 0.9189; train_kl_reg_loss: 0.7158; train_edge_recon_loss: 154.8905; train_cond_contrastive_loss: 472.8310; train_gene_expr_recon_loss: 273.1928; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 901.6300; train_optim_loss: 901.6300; val_kl_reg_loss: 0.6382; val_edge_recon_loss: 162.5042; val_cond_contrastive_loss: 472.4609; val_gene_expr_recon_loss: 274.1643; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 909.7676; val_optim_loss: 909.7676\n",
      "Epoch 27/40 |âââââââââââââ-------| 67.5% val_auroc_score: 0.9335; val_auprc_score: 0.8965; val_best_acc_score: 0.9148; val_best_f1_score: 0.9178; train_kl_reg_loss: 0.7113; train_edge_recon_loss: 151.9644; train_cond_contrastive_loss: 471.8526; train_gene_expr_recon_loss: 274.4493; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 898.9776; train_optim_loss: 898.9776; val_kl_reg_loss: 0.6349; val_edge_recon_loss: 158.3059; val_cond_contrastive_loss: 475.0327; val_gene_expr_recon_loss: 269.5607; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 903.5343; val_optim_loss: 903.5343\n",
      "\n",
      "Reducing learning rate: metric has not improved more than 0.0 in the last 3 epochs.\n",
      "New learning rate is 1e-05.\n",
      "\n",
      "Epoch 28/40 |ââââââââââââââ------| 70.0% val_auroc_score: 0.9302; val_auprc_score: 0.8897; val_best_acc_score: 0.9141; val_best_f1_score: 0.9166; train_kl_reg_loss: 0.7075; train_edge_recon_loss: 152.9139; train_cond_contrastive_loss: 471.3100; train_gene_expr_recon_loss: 273.5719; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 898.5033; train_optim_loss: 898.5033; val_kl_reg_loss: 0.6360; val_edge_recon_loss: 161.6092; val_cond_contrastive_loss: 473.7871; val_gene_expr_recon_loss: 274.0597; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 910.0919; val_optim_loss: 910.0919\n",
      "Epoch 29/40 |ââââââââââââââ------| 72.5% val_auroc_score: 0.9355; val_auprc_score: 0.8996; val_best_acc_score: 0.9175; val_best_f1_score: 0.9203; train_kl_reg_loss: 0.7042; train_edge_recon_loss: 155.7326; train_cond_contrastive_loss: 472.6236; train_gene_expr_recon_loss: 274.0950; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 903.1552; train_optim_loss: 903.1552; val_kl_reg_loss: 0.6304; val_edge_recon_loss: 158.8685; val_cond_contrastive_loss: 474.4822; val_gene_expr_recon_loss: 271.4480; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 905.4292; val_optim_loss: 905.4292\n",
      "Epoch 30/40 |âââââââââââââââ-----| 75.0% val_auroc_score: 0.9304; val_auprc_score: 0.8899; val_best_acc_score: 0.9159; val_best_f1_score: 0.9191; train_kl_reg_loss: 0.7055; train_edge_recon_loss: 153.3530; train_cond_contrastive_loss: 473.1571; train_gene_expr_recon_loss: 273.1328; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 900.3484; train_optim_loss: 900.3484; val_kl_reg_loss: 0.6336; val_edge_recon_loss: 153.0915; val_cond_contrastive_loss: 466.9735; val_gene_expr_recon_loss: 270.0266; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 890.7252; val_optim_loss: 890.7252\n"
     ]
    }
   ],
   "source": [
    "train_autotalker_models(dataset=\"seqfish_mouse_organogenesis\",\n",
    "                        reference_batches=[f\"batch{i}\" for i in range(1,7)],\n",
    "                        cell_type_key=\"celltype_mapped_refined\",\n",
    "                        adata_new=None,\n",
    "                        n_start_run=1,\n",
    "                        n_end_run=1,\n",
    "                        n_neighbor_list=[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a6b839-f7ba-41b3-a6cd-b818de304344",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_autotalker_models(dataset=\"seqfish_mouse_organogenesis\",\n",
    "                        reference_batches=[f\"batch{i}\" for i in range(1,7)],\n",
    "                        cell_type_key=\"celltype_mapped_refined\",\n",
    "                        adata_new=None,\n",
    "                        n_start_run=1,\n",
    "                        n_end_run=1,\n",
    "                        n_neighbor_list=[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43617a84-1c81-473e-b275-c6b15a1b9fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_autotalker_models(dataset=\"seqfish_mouse_organogenesis\",\n",
    "                        reference_batches=[f\"batch{i}\" for i in range(1,7)],\n",
    "                        cell_type_key=\"celltype_mapped_refined\",\n",
    "                        adata_new=None,\n",
    "                        n_start_run=1,\n",
    "                        n_end_run=10,\n",
    "                        n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16, 20, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e2d199-174f-4e6e-aa67-e50149b4c4b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(\"../../datasets/srt_data/gold/seqfish_mouse_organogenesis.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38da8b32-f839-494f-a31a-a19f661c0290",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(\"../../datasets/srt_data/gold/results/seqfish_mouse_organogenesis_autotalker_oneshot_integrated.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b6c04b-e1e7-4825-a9ec-5ee46f66ca8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d92d6d-e323-4a04-ae08-26ee096a02e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")\n",
    "from color_utils import seqfish_mouse_organogenesis_cell_type_colors\n",
    "\n",
    "adata.obsm[\"X_umap\"] = adata.obsm[\"autotalker_latent_run1_X_umap\"]\n",
    "cell_type_key = \"cell_type\"\n",
    "\n",
    "# Plot UMAP with batch annotations\n",
    "fig = sc.pl.umap(adata,\n",
    "                 color=[condition_key],\n",
    "                 legend_fontsize=12,\n",
    "                 size=240000/len(adata),\n",
    "                 return_fig=True)\n",
    "fig.set_figheight(7)\n",
    "fig.set_figwidth(7)\n",
    "plt.title(f\"One-Shot Integration: {model_name} Latent Batch Annotations\", size=20, pad=15)\n",
    "\n",
    "# Plot UMAP with cell type annotations\n",
    "fig = sc.pl.umap(adata,\n",
    "                 color=[cell_type_key],\n",
    "                 palette=seqfish_mouse_organogenesis_cell_type_colors,\n",
    "                 legend_fontsize=12,\n",
    "                 size=240000/len(adata),\n",
    "                 return_fig=True)\n",
    "fig.set_figheight(7)\n",
    "fig.set_figwidth(7)\n",
    "plt.title(f\"One-Shot Integration: {model_name} Latent Cell Type Annotations\", size=20, pad=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee102dc-b9fe-47b8-9fb0-e47cae2bb759",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autotalker.benchmarking import compute_clisis, compute_cas\n",
    "import scib\n",
    "\n",
    "spatial_knng_key = \"autotalker_spatial_knng\"\n",
    "latent_knng_key = \"autotalker_latent_run1\"\n",
    "\n",
    "# Compute metrics\n",
    "metrics_dict = {}\n",
    "\n",
    "# Spatial conservation metrics\n",
    "metrics_dict[\"cas\"] = compute_cas(\n",
    "    adata=adata,\n",
    "    cell_type_key=cell_type_key,\n",
    "    condition_key=condition_key,\n",
    "    spatial_knng_key=spatial_knng_key,\n",
    "    latent_knng_key=latent_knng_key,\n",
    "    spatial_key=spatial_key,\n",
    "    latent_key=latent_key)\n",
    "metrics_dict[\"clisis\"] = compute_clisis(\n",
    "    adata=adata,\n",
    "    cell_type_key=cell_type_key,\n",
    "    condition_key=condition_key,\n",
    "    spatial_knng_key=spatial_knng_key,\n",
    "    latent_knng_key=latent_knng_key,\n",
    "    spatial_key=spatial_key,\n",
    "    latent_key=latent_key)\n",
    "\n",
    "# Batch correction metrics\n",
    "metrics_dict[\"asw\"] = scib.me.silhouette_batch(\n",
    "    adata=adata,\n",
    "    batch_key=condition_key,\n",
    "    label_key=cell_type_key,\n",
    "    embed=latent_key)\n",
    "metrics_dict[\"ilisi\"] = scib.me.ilisi_graph(\n",
    "    adata=adata,\n",
    "    batch_key=condition_key,\n",
    "    type_=\"embed\",\n",
    "    use_rep=latent_key)\n",
    "    #type_=\"knn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b528e64-9ee4-4cc8-9936-a225130b4b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147568e6-b055-4181-900f-d47d5984bf0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
