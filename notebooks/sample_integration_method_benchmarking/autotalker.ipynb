{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "364a9ebc-3e3c-4645-9049-a34bd084c8a8",
   "metadata": {},
   "source": [
    "# Autotalker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c55227-147e-417f-b0dd-bb0b7f322930",
   "metadata": {},
   "source": [
    "- **Creator**: Sebastian Birk (<sebastian.birk@helmholtz-munich.de>).\n",
    "- **Affiliation:** Helmholtz Munich, Institute of Computational Biology (ICB), Talavera-LÃ³pez Lab\n",
    "- **Date of Creation:** 13.01.2023\n",
    "- **Date of Last Modification:** 31.03.2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa669117-f347-4666-b112-8ea6669fd9e9",
   "metadata": {},
   "source": [
    "- The Autotalker source code is available at https://github.com/Talavera-Lopez-Lab/autotalker.\n",
    "- The workflow of this notebook follows the tutorial from https://github.com/sebastianbirk/autotalker/blob/main/notebooks/autotalker_tutorial.ipynb.\n",
    "- It is recommended to use raw counts as input to Autotalker. Therefore, we use raw counts (stored in adata.layers[\"counts\"])."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7529cde5-be12-403b-a94c-07561774b86c",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faad87bd-fef5-4429-a175-d714c491ae76",
   "metadata": {},
   "source": [
    "### 1.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "149b5fec-87ba-4bd5-a327-5a37065b6223",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9305ecb-5d4b-4cdd-8e92-f7155426b7f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../../autotalker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7f93960-c759-424f-8cb2-1d8698acae2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import gc\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "\n",
    "import anndata as ad\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import scipy.sparse as sp\n",
    "import seaborn as sns\n",
    "import squidpy as sq\n",
    "import torch\n",
    "from matplotlib.pyplot import rc_context\n",
    "\n",
    "from autotalker.models import Autotalker\n",
    "from autotalker.utils import (add_gps_from_gp_dict_to_adata,\n",
    "                              extract_gp_dict_from_mebocost_es_interactions,\n",
    "                              extract_gp_dict_from_nichenet_ligand_target_mx,\n",
    "                              extract_gp_dict_from_omnipath_lr_interactions,\n",
    "                              filter_and_combine_gp_dict_gps,\n",
    "                              get_unique_genes_from_gp_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b5efa5-2052-4986-8ae5-89cfab018515",
   "metadata": {},
   "source": [
    "### 1.2 Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e5c8b48a-ed5e-48b5-8c5c-c1de11493aee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"autotalker\"\n",
    "latent_key = f\"{model_name}_latent\"\n",
    "mapping_entity_key = \"reference\"\n",
    "condition_key = \"batch\"\n",
    "counts_key = \"counts\"\n",
    "spatial_key = \"spatial\"\n",
    "adj_key = \"spatial_connectivities\"\n",
    "nichenet_keep_target_genes_ratio = 0.01\n",
    "nichenet_max_n_target_genes_per_gp = 25344\n",
    "include_mebocost_gps = True\n",
    "mebocost_species = \"mouse\"\n",
    "filter_genes = False\n",
    "gp_filter_mode = \"subset\"\n",
    "combine_overlap_gps = True\n",
    "overlap_thresh_source_genes = 0.9\n",
    "overlap_thresh_target_genes = 0.9\n",
    "overlap_thresh_genes = 0.9\n",
    "active_gp_names_key = \"autotalker_active_gp_names\"\n",
    "gp_targets_mask_key = \"autotalker_gp_targets_mask\"\n",
    "gp_sources_mask_key = \"autotalker_gp_sources_mask\"\n",
    "gp_names_key = \"autotalker_gp_names\"\n",
    "active_gp_thresh_ratio = 0.03\n",
    "gene_expr_recon_dist = \"nb\"\n",
    "cond_embed_injection = [\"encoder\", \"gene_expr_decoder\"]\n",
    "log_variational = True\n",
    "n_layers_encoder = 2\n",
    "conv_layer_encoder = \"gcnconv\"\n",
    "n_epochs = 40\n",
    "n_epochs_all_gps = 20\n",
    "lr = 0.001\n",
    "lambda_edge_recon = 1000.\n",
    "lambda_gene_expr_recon = 1.\n",
    "lambda_cond_contrastive = 1000.\n",
    "cond_contrastive_thresh = 0.8\n",
    "lambda_group_lasso = 0.\n",
    "lambda_l1_masked = 0.\n",
    "edge_batch_size = 128\n",
    "node_batch_size = 16\n",
    "leiden_resolution = 0.01 # used for Leiden clustering of latent space; 0.1\n",
    "random_seed = 0 # used for Leiden clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28adc110-0f41-4a71-9838-dc7f0687809a",
   "metadata": {},
   "source": [
    "### 1.3 Run Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "334b87ca-3387-4ba9-8567-84bc4754ff0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sc.set_figure_params(figsize=(6, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ab6b302-1c0b-4937-8624-40629ada2e46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get time of notebook execution for timestamping saved artifacts\n",
    "now = datetime.now()\n",
    "current_timestamp = now.strftime(\"%d%m%Y_%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85538952-006b-4b0b-a50c-fe7445ce22e2",
   "metadata": {},
   "source": [
    "### 1.4 Configure Paths and Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ddcc49c-ba22-4155-acd5-05b5b810e091",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "srt_data_gold_folder_path = \"../../datasets/srt_data/gold\"\n",
    "figure_folder_path = f\"../../figures\"\n",
    "gp_data_folder_path = \"../../datasets/gp_data\" # gene program data\n",
    "nichenet_ligand_target_mx_file_path = gp_data_folder_path + \"/nichenet_ligand_target_matrix.csv\"\n",
    "omnipath_lr_interactions_file_path = gp_data_folder_path + \"/omnipath_lr_interactions.csv\"\n",
    "\n",
    "# Create required directories\n",
    "os.makedirs(gp_data_folder_path, exist_ok=True)\n",
    "os.makedirs(srt_data_gold_folder_path + \"/results\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d974cd00-eafa-4432-b172-fafc4058a619",
   "metadata": {},
   "source": [
    "## 2. Autotalker Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b908c99c-de2f-4239-8420-00bd1fd58baa",
   "metadata": {},
   "source": [
    "### 2.1 Prepare Gene Program Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06c510ab-e3b1-41e7-848d-e4b9513313cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the gene program mask...\n",
      "Number of gene programs before filtering and combining: 1725.\n",
      "Number of gene programs after filtering and combining: 1575.\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing the gene program mask...\")\n",
    "# OmniPath gene programs\n",
    "omnipath_gp_dict = extract_gp_dict_from_omnipath_lr_interactions(\n",
    "    min_curation_effort=0,\n",
    "    load_from_disk=True,\n",
    "    save_to_disk=False,\n",
    "    file_path=omnipath_lr_interactions_file_path,\n",
    "    plot_gp_gene_count_distributions=False)\n",
    "\n",
    "omnipath_genes = get_unique_genes_from_gp_dict(\n",
    "    gp_dict=omnipath_gp_dict,\n",
    "    retrieved_gene_entities=[\"sources\", \"targets\"])\n",
    "\n",
    "# NicheNet gene programs\n",
    "nichenet_gp_dict = extract_gp_dict_from_nichenet_ligand_target_mx(\n",
    "    keep_target_genes_ratio=nichenet_keep_target_genes_ratio,\n",
    "    max_n_target_genes_per_gp=nichenet_max_n_target_genes_per_gp,\n",
    "    load_from_disk=True,\n",
    "    save_to_disk=False,\n",
    "    file_path=nichenet_ligand_target_mx_file_path,\n",
    "    plot_gp_gene_count_distributions=False)\n",
    "\n",
    "nichenet_source_genes = get_unique_genes_from_gp_dict(\n",
    "    gp_dict=nichenet_gp_dict,\n",
    "    retrieved_gene_entities=[\"sources\"])\n",
    "\n",
    "# Combine gene programs into one dictionary\n",
    "combined_gp_dict = dict(omnipath_gp_dict)\n",
    "combined_gp_dict.update(nichenet_gp_dict)\n",
    "\n",
    "if filter_genes:\n",
    "    # Get gene program relevant genes\n",
    "    gp_relevant_genes = list(set(omnipath_genes + nichenet_source_genes))\n",
    "\n",
    "# Mebocost gene programs\n",
    "if include_mebocost_gps:\n",
    "    mebocost_gp_dict = extract_gp_dict_from_mebocost_es_interactions(\n",
    "    dir_path=f\"{gp_data_folder_path}/metabolite_enzyme_sensor_gps/\",\n",
    "    species=mebocost_species,\n",
    "    genes_uppercase=True,\n",
    "    plot_gp_gene_count_distributions=False)\n",
    "    \n",
    "    mebocost_genes = get_unique_genes_from_gp_dict(\n",
    "        gp_dict=mebocost_gp_dict,\n",
    "        retrieved_gene_entities=[\"sources\", \"targets\"])\n",
    "\n",
    "    combined_gp_dict.update(mebocost_gp_dict)\n",
    "    \n",
    "    if filter_genes:\n",
    "        # Update gene program relevant genes\n",
    "        gp_relevant_genes = list(set(gp_relevant_genes + mebocost_genes))\n",
    "    \n",
    "# Filter and combine gene programs\n",
    "combined_new_gp_dict = filter_and_combine_gp_dict_gps(\n",
    "    gp_dict=combined_gp_dict,\n",
    "    gp_filter_mode=gp_filter_mode,\n",
    "    combine_overlap_gps=combine_overlap_gps,\n",
    "    overlap_thresh_source_genes=overlap_thresh_source_genes,\n",
    "    overlap_thresh_target_genes=overlap_thresh_target_genes,\n",
    "    overlap_thresh_genes=overlap_thresh_genes,\n",
    "    verbose=False)\n",
    "\n",
    "print(\"Number of gene programs before filtering and combining: \"\n",
    "      f\"{len(combined_gp_dict)}.\")\n",
    "print(f\"Number of gene programs after filtering and combining: \"\n",
    "      f\"{len(combined_new_gp_dict)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d712fe8e-6438-4b1d-9ec8-6b6f4408627b",
   "metadata": {},
   "source": [
    "### 2.2 Define Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ea39b0f-9c9a-459a-ba2e-c843802a8e37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_autotalker_models(dataset,\n",
    "                            reference_batches,\n",
    "                            cell_type_key,\n",
    "                            adata_new=None,\n",
    "                            n_start_run=1,\n",
    "                            n_end_run=10,\n",
    "                            n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16, 20, 20],\n",
    "                            plot_latent_umaps: bool=False):\n",
    "    # Create new adata to store results from training runs in storage-efficient way\n",
    "    if adata_new is None:  \n",
    "        adata_batch_list = []\n",
    "        if reference_batches is not None:\n",
    "            for batch in reference_batches:\n",
    "                adata_batch = ad.read_h5ad(\n",
    "                    f\"{srt_data_gold_folder_path}/{dataset}_{batch}.h5ad\")\n",
    "                adata_batch.obs[mapping_entity_key] = \"reference\"\n",
    "                adata_batch_list.append(adata_batch)\n",
    "            adata_original = ad.concat(adata_batch_list, join=\"inner\")\n",
    "        else:\n",
    "            adata_original = ad.read_h5ad(f\"{srt_data_gold_folder_path}/{dataset}.h5ad\")\n",
    "\n",
    "        adata_new = sc.AnnData(sp.csr_matrix(\n",
    "            (adata_original.shape[0], adata_original.shape[1]),\n",
    "            dtype=np.float32))\n",
    "        adata_new.var_names = adata_original.var_names\n",
    "        adata_new.obs_names = adata_original.obs_names\n",
    "        adata_new.obs[\"cell_type\"] = adata_original.obs[cell_type_key].values\n",
    "        adata_new.obsm[\"spatial\"] = adata_original.obsm[\"spatial\"]\n",
    "        adata_new.obs[condition_key] = adata_original.obs[condition_key]\n",
    "        adata_new.obs[mapping_entity_key] = adata_original.obs[mapping_entity_key] \n",
    "        del(adata_original)\n",
    "    \n",
    "    model_seeds = list(range(10))\n",
    "    for run_number, n_neighbors in zip(np.arange(n_start_run, n_end_run+1), n_neighbor_list):\n",
    "        # Load data\n",
    "        adata_batch_list = []\n",
    "        if reference_batches is not None:\n",
    "            for batch in reference_batches:\n",
    "                print(f\"Processing batch {batch}...\")\n",
    "                print(\"Loading data...\")\n",
    "                adata_batch = ad.read_h5ad(\n",
    "                    f\"{srt_data_gold_folder_path}/{dataset}_{batch}.h5ad\")\n",
    "                adata_batch.obs[mapping_entity_key] = \"reference\"\n",
    "                print(\"Computing spatial neighborhood graph...\\n\")\n",
    "                # Compute (separate) spatial neighborhood graphs\n",
    "                sq.gr.spatial_neighbors(adata_batch,\n",
    "                                        coord_type=\"generic\",\n",
    "                                        spatial_key=spatial_key,\n",
    "                                        n_neighs=n_neighbors)\n",
    "                # Make adjacency matrix symmetric\n",
    "                adata_batch.obsp[adj_key] = (\n",
    "                    adata_batch.obsp[adj_key].maximum(\n",
    "                        adata_batch.obsp[adj_key].T))\n",
    "                adata_batch_list.append(adata_batch)\n",
    "            adata = ad.concat(adata_batch_list, join=\"inner\")\n",
    "\n",
    "            # Combine spatial neighborhood graphs as disconnected components\n",
    "            batch_connectivities = []\n",
    "            len_before_batch = 0\n",
    "            for i in range(len(adata_batch_list)):\n",
    "                if i == 0: # first batch\n",
    "                    after_batch_connectivities_extension = sp.csr_matrix(\n",
    "                        (adata_batch_list[0].shape[0],\n",
    "                        (adata.shape[0] -\n",
    "                        adata_batch_list[0].shape[0])))\n",
    "                    batch_connectivities.append(sp.hstack(\n",
    "                        (adata_batch_list[0].obsp[adj_key],\n",
    "                        after_batch_connectivities_extension)))\n",
    "                elif i == (len(adata_batch_list) - 1): # last batch\n",
    "                    before_batch_connectivities_extension = sp.csr_matrix(\n",
    "                        (adata_batch_list[i].shape[0],\n",
    "                        (adata.shape[0] -\n",
    "                        adata_batch_list[i].shape[0])))\n",
    "                    batch_connectivities.append(sp.hstack(\n",
    "                        (before_batch_connectivities_extension,\n",
    "                        adata_batch_list[i].obsp[adj_key])))\n",
    "                else: # middle batches\n",
    "                    before_batch_connectivities_extension = sp.csr_matrix(\n",
    "                        (adata_batch_list[i].shape[0], len_before_batch))\n",
    "                    after_batch_connectivities_extension = sp.csr_matrix(\n",
    "                        (adata_batch_list[i].shape[0],\n",
    "                        (adata.shape[0] -\n",
    "                        adata_batch_list[i].shape[0] -\n",
    "                        len_before_batch)))\n",
    "                    batch_connectivities.append(sp.hstack(\n",
    "                        (before_batch_connectivities_extension,\n",
    "                        adata_batch_list[i].obsp[adj_key],\n",
    "                        after_batch_connectivities_extension)))\n",
    "                len_before_batch += adata_batch_list[i].shape[0]\n",
    "            connectivities = sp.vstack(batch_connectivities)\n",
    "            adata.obsp[adj_key] = connectivities\n",
    "        else:\n",
    "            adata = ad.read_h5ad(f\"{srt_data_gold_folder_path}/{dataset}.h5ad\")\n",
    "            # Compute (separate) spatial neighborhood graphs\n",
    "            sq.gr.spatial_neighbors(adata,\n",
    "                                    coord_type=\"generic\",\n",
    "                                    spatial_key=spatial_key,\n",
    "                                    n_neighs=n_neighbors)\n",
    "            # Make adjacency matrix symmetric\n",
    "            adata.obsp[adj_key] = (\n",
    "                adata.obsp[adj_key].maximum(\n",
    "                    adata.obsp[adj_key].T))\n",
    "            \n",
    "        # Filter genes if specified\n",
    "        if filter_genes:\n",
    "            print(\"\\nFiltering genes...\")\n",
    "            # Filter genes and only keep ligand, receptor, metabolitye enzyme, \n",
    "            # metabolite sensor and the 'n_hvg' highly variable genes (potential target\n",
    "            # genes of nichenet)\n",
    "            gp_dict_genes = get_unique_genes_from_gp_dict(\n",
    "                gp_dict=combined_new_gp_dict,\n",
    "                retrieved_gene_entities=[\"sources\", \"targets\"])\n",
    "            print(f\"Starting with {len(adata.var_names)} genes.\")\n",
    "            sc.pp.filter_genes(adata,\n",
    "                               min_cells=0)\n",
    "            print(f\"Keeping {len(adata.var_names)} genes after filtering \"\n",
    "                  \"genes with expression in 0 cells.\")\n",
    "\n",
    "            if counts_key is not None:\n",
    "                hvg_layer = counts_key\n",
    "                if (adata.layers[counts_key].astype(int).sum() == \n",
    "                adata.layers[counts_key].sum()): # raw counts\n",
    "                    hvg_flavor = \"seurat_v3\"\n",
    "                else:\n",
    "                    hvg_flavor = \"seurat\" # log normalized counts\n",
    "            else:\n",
    "                hvg_layer = None\n",
    "                if adata.X.astype(int).sum() == adata.X.sum(): # raw counts\n",
    "                    hvg_flavor = \"seurat_v3\"\n",
    "                else: # log normalized counts\n",
    "                    hvg_flavor = \"seurat\"\n",
    "\n",
    "            sc.pp.highly_variable_genes(\n",
    "                adata,\n",
    "                layer=hvg_layer,\n",
    "                n_top_genes=n_hvg,\n",
    "                flavor=hvg_flavor,\n",
    "                batch_key=condition_key,\n",
    "                subset=False)\n",
    "\n",
    "            adata.var[\"gp_relevant\"] = (\n",
    "                adata.var.index.str.upper().isin(gp_relevant_genes))\n",
    "            adata.var[\"keep_gene\"] = (adata.var[\"gp_relevant\"] | \n",
    "                                                adata.var[\"highly_variable\"])\n",
    "            adata = (\n",
    "                adata[:, adata.var[\"keep_gene\"] == True])\n",
    "            print(f\"Keeping {len(adata.var_names)} highly variable or gene \"\n",
    "                  \"program relevant genes.\")\n",
    "            adata = (\n",
    "                adata[:, adata.var_names[\n",
    "                    adata.var_names.str.upper().isin(\n",
    "                        gp_dict_genes)].sort_values()])\n",
    "            print(f\"Keeping {len(adata.var_names)} genes after filtering \"\n",
    "                  \"genes not in gp dict.\")\n",
    "        \n",
    "        # Add the gene program dictionary as binary masks to the adata for model \n",
    "        # training\n",
    "        add_gps_from_gp_dict_to_adata(\n",
    "            gp_dict=combined_new_gp_dict,\n",
    "            adata=adata,\n",
    "            genes_uppercase=True,\n",
    "            gp_targets_mask_key=gp_targets_mask_key,\n",
    "            gp_sources_mask_key=gp_sources_mask_key,\n",
    "            gp_names_key=gp_names_key,\n",
    "            min_genes_per_gp=1,\n",
    "            min_source_genes_per_gp=0,\n",
    "            min_target_genes_per_gp=0,\n",
    "            max_genes_per_gp=None,\n",
    "            max_source_genes_per_gp=None,\n",
    "            max_target_genes_per_gp=None,\n",
    "            filter_genes_not_in_masks=False)\n",
    "\n",
    "        # Determine dimensionality of hidden encoder\n",
    "        n_hidden_encoder = len(adata.uns[f\"{model_name}_gp_names\"])\n",
    "        n_cond_embed = int(len(adata.var_names) / 2)\n",
    "\n",
    "        start_time = time.time()\n",
    "        \n",
    "        print(\"\\nTraining model...\")\n",
    "        # Initialize model\n",
    "        model = Autotalker(adata,\n",
    "                           counts_key=counts_key,\n",
    "                           adj_key=adj_key,\n",
    "                           condition_key=condition_key,\n",
    "                           cond_embed_injection=cond_embed_injection,\n",
    "                           n_cond_embed=n_cond_embed,\n",
    "                           gp_names_key=gp_names_key,\n",
    "                           active_gp_names_key=active_gp_names_key,\n",
    "                           gp_targets_mask_key=gp_targets_mask_key,\n",
    "                           gp_sources_mask_key=gp_sources_mask_key,\n",
    "                           latent_key=latent_key,\n",
    "                           active_gp_thresh_ratio=active_gp_thresh_ratio,\n",
    "                           gene_expr_recon_dist=gene_expr_recon_dist,\n",
    "                           n_layers_encoder=n_layers_encoder,\n",
    "                           conv_layer_encoder=conv_layer_encoder,\n",
    "                           n_hidden_encoder=n_hidden_encoder,\n",
    "                           log_variational=log_variational)\n",
    "\n",
    "        # Train model\n",
    "        model.train(n_epochs=n_epochs,\n",
    "                    n_epochs_all_gps=n_epochs_all_gps,\n",
    "                    lr=lr,\n",
    "                    lambda_edge_recon=lambda_edge_recon,\n",
    "                    lambda_gene_expr_recon=lambda_gene_expr_recon,\n",
    "                    lambda_cond_contrastive=lambda_cond_contrastive,\n",
    "                    cond_contrastive_thresh=cond_contrastive_thresh,\n",
    "                    lambda_group_lasso=lambda_group_lasso,\n",
    "                    lambda_l1_masked=lambda_l1_masked,\n",
    "                    edge_batch_size=edge_batch_size,\n",
    "                    node_batch_size=node_batch_size,\n",
    "                    seed=model_seeds[run_number-1],\n",
    "                    verbose=True)        \n",
    "        \n",
    "        # Measure time for model training\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        hours, rem = divmod(elapsed_time, 3600)\n",
    "        minutes, seconds = divmod(rem, 60)\n",
    "        print(f\"Duration of model training in run {run_number}: \"\n",
    "              f\"{int(hours)} hours, {int(minutes)} minutes and {int(seconds)} seconds.\")\n",
    "        adata_new.uns[f\"{model_name}_model_training_duration_run{run_number}\"] = (\n",
    "            elapsed_time)\n",
    "\n",
    "        if plot_latent_umaps:\n",
    "            # Configure figure folder path\n",
    "            dataset_figure_folder_path = f\"{figure_folder_path}/{dataset}/sample_integration_method_benchmarking/\" \\\n",
    "                                         f\"{model_name}/{current_timestamp}\"\n",
    "            os.makedirs(dataset_figure_folder_path, exist_ok=True)\n",
    "            \n",
    "            # Use Autotalker latent space for UMAP generation\n",
    "            sc.pp.neighbors(adata,\n",
    "                            use_rep=latent_key,\n",
    "                            n_neighbors=n_neighbors)\n",
    "            sc.tl.umap(adata)\n",
    "            fig = sc.pl.umap(adata,\n",
    "                             color=[cell_type_key],\n",
    "                             title=f\"Latent Space with Cell Types: {model_name.capitalize()}\",\n",
    "                             return_fig=True)\n",
    "            fig.savefig(f\"{dataset_figure_folder_path}/latent_{model_name}\"\n",
    "                        f\"_cell_types_run{run_number}.png\",\n",
    "                        bbox_inches=\"tight\")\n",
    "\n",
    "            # Compute latent Leiden clustering\n",
    "            sc.tl.leiden(adata=adata,\n",
    "                         resolution=leiden_resolution,\n",
    "                         random_state=random_seed,\n",
    "                         key_added=f\"latent_{model_name}_leiden_{str(leiden_resolution)}\")\n",
    "\n",
    "            # Create subplot of latent Leiden cluster annotations in physical and latent space\n",
    "            fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(6, 12))\n",
    "            title = fig.suptitle(t=\"Latent and Physical Space with Leiden Clusters: \"\n",
    "                                   f\"{model_name.capitalize()}\")\n",
    "            sc.pl.umap(adata=adata,\n",
    "                       color=[f\"latent_{model_name}_leiden_{str(leiden_resolution)}\"],\n",
    "                       title=f\"Latent Space with Leiden Clusters\",\n",
    "                       ax=axs[0],\n",
    "                       show=False)\n",
    "            sq.pl.spatial_scatter(adata=adata,\n",
    "                                  color=[f\"latent_{model_name}_leiden_{str(leiden_resolution)}\"],\n",
    "                                  title=f\"Physical Space with Leiden Clusters\",\n",
    "                                  shape=None,\n",
    "                                  ax=axs[1])\n",
    "\n",
    "            # Create and position shared legend\n",
    "            handles, labels = axs[0].get_legend_handles_labels()\n",
    "            lgd = fig.legend(handles, labels, bbox_to_anchor=(1.25, 0.9185))\n",
    "            axs[0].get_legend().remove()\n",
    "            axs[1].get_legend().remove()\n",
    "\n",
    "            # Adjust, save and display plot\n",
    "            plt.subplots_adjust(wspace=0, hspace=0.2)\n",
    "            fig.savefig(f\"{dataset_figure_folder_path}/latent_physical_comparison_\"\n",
    "                        f\"{model_name}_run{run_number}.png\",\n",
    "                        bbox_extra_artists=(lgd, title),\n",
    "                        bbox_inches=\"tight\")\n",
    "            plt.show()\n",
    "\n",
    "        # Store latent representation\n",
    "        adata_new.obsm[latent_key + f\"_run{run_number}\"] = adata.obsm[latent_key]\n",
    "        \n",
    "        # Use latent representation for UMAP generation\n",
    "        sc.pp.neighbors(adata_new,\n",
    "                        use_rep=f\"{latent_key}_run{run_number}\",\n",
    "                        key_added=f\"{latent_key}_run{run_number}\")\n",
    "        sc.tl.umap(adata_new,\n",
    "                   neighbors_key=f\"{latent_key}_run{run_number}\")\n",
    "        adata_new.obsm[f\"{latent_key}_run{run_number}_X_umap\"] = adata_new.obsm[\"X_umap\"]\n",
    "        del(adata_new.obsm[\"X_umap\"])\n",
    "\n",
    "        # Store intermediate adata to disk\n",
    "        adata_new.write(f\"{srt_data_gold_folder_path}/results/{dataset}_{model_name}_oneshot_integrated.h5ad\")\n",
    "        \n",
    "        # Free memory\n",
    "        del(adata)\n",
    "        del(model)\n",
    "        gc.collect()\n",
    "\n",
    "    # Store final adata to disk\n",
    "    adata_new.write(f\"{srt_data_gold_folder_path}/results/{dataset}_{model_name}_oneshot_integrated.h5ad\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5471d723-2807-44a9-aea2-4736131b614d",
   "metadata": {},
   "source": [
    "### 2.3 Train Models on Benchmarking Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3592bdd4-a763-4323-ae3a-8087f4c77af9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Computing spatial neighborhood graph...\n",
      "\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Computing spatial neighborhood graph...\n",
      "\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Computing spatial neighborhood graph...\n",
      "\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Computing spatial neighborhood graph...\n",
      "\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Computing spatial neighborhood graph...\n",
      "\n",
      "Processing batch batch6...\n",
      "Loading data...\n",
      "Computing spatial neighborhood graph...\n",
      "\n",
      "\n",
      "Training model...\n",
      "--- INITIALIZING NEW NETWORK MODULE: VARIATIONAL GENE PROGRAM GRAPH AUTOENCODER ---\n",
      "LOSS -> include_edge_recon_loss: True, include_gene_expr_recon_loss: True, gene_expr_recon_dist: nb\n",
      "NODE LABEL METHOD -> one-hop-attention\n",
      "ACTIVE GP THRESHOLD RATIO -> 0.03\n",
      "LOG VARIATIONAL -> True\n",
      "CONDITIONAL EMBEDDING INJECTION -> ['encoder', 'gene_expr_decoder']\n",
      "GRAPH ENCODER -> n_input: 351, n_cond_embed_input: 175, n_layers: 2, n_hidden: 489, n_latent: 489, n_addon_latent: 0, conv_layer: gcnconv, n_attention_heads: 0, dropout_rate: 0.0\n",
      "COSINE SIM GRAPH DECODER -> n_cond_embed_input: 0, n_output: 489, dropout_rate: 0.0\n",
      "MASKED GENE EXPRESSION DECODER -> n_input: 489, n_cond_embed_input: 175, n_addon_input: 0, n_output: 702\n",
      "\n",
      "--- INITIALIZING TRAINER ---\n",
      "Number of training nodes: 47311\n",
      "Number of validation nodes: 5257\n",
      "Number of training edges: 109836\n",
      "Number of validation edges: 12204\n",
      "\n",
      "--- MODEL TRAINING ---\n",
      "Epoch 1/40 |--------------------| 2.5% val_auroc_score: 0.9194; val_auprc_score: 0.9247; val_best_acc_score: 0.8138; val_best_f1_score: 0.8364; train_kl_reg_loss: 1.0005; train_edge_recon_loss: 169.5294; train_cond_contrastive_loss: 617.3339; train_gene_expr_recon_loss: 324.0302; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 1111.8940; train_optim_loss: 1111.8940; val_kl_reg_loss: 1.3109; val_edge_recon_loss: 166.9329; val_cond_contrastive_loss: 699.2924; val_gene_expr_recon_loss: 312.9174; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 1180.4537; val_optim_loss: 1180.4537\n",
      "Epoch 2/40 |â-------------------| 5.0% val_auroc_score: 0.9287; val_auprc_score: 0.9376; val_best_acc_score: 0.8150; val_best_f1_score: 0.8377; train_kl_reg_loss: 1.6603; train_edge_recon_loss: 159.3697; train_cond_contrastive_loss: 688.7633; train_gene_expr_recon_loss: 308.9269; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 1158.7203; train_optim_loss: 1158.7203; val_kl_reg_loss: 2.1202; val_edge_recon_loss: 161.1000; val_cond_contrastive_loss: 673.5342; val_gene_expr_recon_loss: 309.7365; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 1146.4909; val_optim_loss: 1146.4909\n",
      "Epoch 3/40 |â-------------------| 7.5% val_auroc_score: 0.9383; val_auprc_score: 0.9460; val_best_acc_score: 0.8338; val_best_f1_score: 0.8401; train_kl_reg_loss: 1.9911; train_edge_recon_loss: 159.5171; train_cond_contrastive_loss: 678.0811; train_gene_expr_recon_loss: 304.4140; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 1144.0032; train_optim_loss: 1144.0032; val_kl_reg_loss: 2.2251; val_edge_recon_loss: 157.6364; val_cond_contrastive_loss: 666.2706; val_gene_expr_recon_loss: 300.9004; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 1127.0324; val_optim_loss: 1127.0324\n",
      "Epoch 4/40 |ââ------------------| 10.0% val_auroc_score: 0.9424; val_auprc_score: 0.9494; val_best_acc_score: 0.8433; val_best_f1_score: 0.8429; train_kl_reg_loss: 2.1359; train_edge_recon_loss: 159.1224; train_cond_contrastive_loss: 669.9081; train_gene_expr_recon_loss: 300.3009; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 1131.4674; train_optim_loss: 1131.4674; val_kl_reg_loss: 2.1040; val_edge_recon_loss: 165.4176; val_cond_contrastive_loss: 673.8319; val_gene_expr_recon_loss: 298.3611; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 1139.7146; val_optim_loss: 1139.7146\n",
      "Epoch 5/40 |ââ------------------| 12.5% val_auroc_score: 0.9438; val_auprc_score: 0.9500; val_best_acc_score: 0.8483; val_best_f1_score: 0.8444; train_kl_reg_loss: 2.2039; train_edge_recon_loss: 157.6807; train_cond_contrastive_loss: 667.7897; train_gene_expr_recon_loss: 296.2976; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 1123.9718; train_optim_loss: 1123.9718; val_kl_reg_loss: 2.2084; val_edge_recon_loss: 159.8456; val_cond_contrastive_loss: 667.9645; val_gene_expr_recon_loss: 297.6722; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 1127.6907; val_optim_loss: 1127.6907\n",
      "Epoch 6/40 |âââ-----------------| 15.0% val_auroc_score: 0.9395; val_auprc_score: 0.9479; val_best_acc_score: 0.8320; val_best_f1_score: 0.8462; train_kl_reg_loss: 2.1777; train_edge_recon_loss: 157.9098; train_cond_contrastive_loss: 665.4673; train_gene_expr_recon_loss: 294.9451; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 1120.4999; train_optim_loss: 1120.4999; val_kl_reg_loss: 2.4485; val_edge_recon_loss: 155.7267; val_cond_contrastive_loss: 658.5450; val_gene_expr_recon_loss: 294.4844; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 1111.2046; val_optim_loss: 1111.2046\n",
      "Epoch 7/40 |âââ-----------------| 17.5% val_auroc_score: 0.9445; val_auprc_score: 0.9527; val_best_acc_score: 0.8403; val_best_f1_score: 0.8464; train_kl_reg_loss: 2.2862; train_edge_recon_loss: 160.1311; train_cond_contrastive_loss: 663.9420; train_gene_expr_recon_loss: 293.2170; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 1119.5763; train_optim_loss: 1119.5763; val_kl_reg_loss: 2.3525; val_edge_recon_loss: 156.8745; val_cond_contrastive_loss: 658.1765; val_gene_expr_recon_loss: 291.1549; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 1108.5583; val_optim_loss: 1108.5583\n",
      "Epoch 8/40 |ââââ----------------| 20.0% val_auroc_score: 0.9425; val_auprc_score: 0.9503; val_best_acc_score: 0.8385; val_best_f1_score: 0.8442; train_kl_reg_loss: 2.2346; train_edge_recon_loss: 160.7851; train_cond_contrastive_loss: 663.9115; train_gene_expr_recon_loss: 292.0786; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 1119.0097; train_optim_loss: 1119.0097; val_kl_reg_loss: 2.4764; val_edge_recon_loss: 165.8891; val_cond_contrastive_loss: 667.3529; val_gene_expr_recon_loss: 289.9751; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 1125.6934; val_optim_loss: 1125.6934\n",
      "Epoch 9/40 |ââââ----------------| 22.5% val_auroc_score: 0.9463; val_auprc_score: 0.9534; val_best_acc_score: 0.8564; val_best_f1_score: 0.8522; train_kl_reg_loss: 2.2568; train_edge_recon_loss: 159.6746; train_cond_contrastive_loss: 664.0819; train_gene_expr_recon_loss: 289.9547; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 1115.9680; train_optim_loss: 1115.9680; val_kl_reg_loss: 2.0074; val_edge_recon_loss: 163.6511; val_cond_contrastive_loss: 669.4896; val_gene_expr_recon_loss: 288.8654; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 1124.0135; val_optim_loss: 1124.0135\n",
      "Epoch 10/40 |âââââ---------------| 25.0% val_auroc_score: 0.9452; val_auprc_score: 0.9527; val_best_acc_score: 0.8478; val_best_f1_score: 0.8470; train_kl_reg_loss: 2.1816; train_edge_recon_loss: 159.3830; train_cond_contrastive_loss: 664.7380; train_gene_expr_recon_loss: 290.2029; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 1116.5054; train_optim_loss: 1116.5054; val_kl_reg_loss: 2.2325; val_edge_recon_loss: 162.9026; val_cond_contrastive_loss: 662.8594; val_gene_expr_recon_loss: 284.7311; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 1112.7256; val_optim_loss: 1112.7256\n",
      "\n",
      "Reducing learning rate: metric has not improved more than 0.0 in the last 3 epochs.\n",
      "New learning rate is 0.0001.\n",
      "\n",
      "Epoch 11/40 |âââââ---------------| 27.5% val_auroc_score: 0.9474; val_auprc_score: 0.9568; val_best_acc_score: 0.8487; val_best_f1_score: 0.8506; train_kl_reg_loss: 2.2551; train_edge_recon_loss: 160.5072; train_cond_contrastive_loss: 660.4876; train_gene_expr_recon_loss: 285.3625; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 1108.6124; train_optim_loss: 1108.6124; val_kl_reg_loss: 2.3390; val_edge_recon_loss: 164.8465; val_cond_contrastive_loss: 658.9832; val_gene_expr_recon_loss: 281.8631; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 1108.0317; val_optim_loss: 1108.0317\n",
      "Epoch 12/40 |ââââââ--------------| 30.0% val_auroc_score: 0.9475; val_auprc_score: 0.9556; val_best_acc_score: 0.8588; val_best_f1_score: 0.8561; train_kl_reg_loss: 2.2889; train_edge_recon_loss: 159.0265; train_cond_contrastive_loss: 659.2803; train_gene_expr_recon_loss: 284.4782; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 1105.0740; train_optim_loss: 1105.0740; val_kl_reg_loss: 2.1595; val_edge_recon_loss: 157.3197; val_cond_contrastive_loss: 651.9004; val_gene_expr_recon_loss: 286.1086; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 1097.4882; val_optim_loss: 1097.4882\n",
      "Epoch 13/40 |ââââââ--------------| 32.5% val_auroc_score: 0.9501; val_auprc_score: 0.9581; val_best_acc_score: 0.8486; val_best_f1_score: 0.8506; train_kl_reg_loss: 2.2529; train_edge_recon_loss: 158.7841; train_cond_contrastive_loss: 655.8676; train_gene_expr_recon_loss: 285.6432; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 1102.5478; train_optim_loss: 1102.5478; val_kl_reg_loss: 2.3530; val_edge_recon_loss: 162.4012; val_cond_contrastive_loss: 658.3821; val_gene_expr_recon_loss: 282.4428; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 1105.5790; val_optim_loss: 1105.5790\n",
      "Epoch 14/40 |âââââââ-------------| 35.0% val_auroc_score: 0.9503; val_auprc_score: 0.9581; val_best_acc_score: 0.8614; val_best_f1_score: 0.8600; train_kl_reg_loss: 2.2600; train_edge_recon_loss: 160.0322; train_cond_contrastive_loss: 658.0670; train_gene_expr_recon_loss: 284.0897; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 1104.4489; train_optim_loss: 1104.4489; val_kl_reg_loss: 2.1828; val_edge_recon_loss: 161.6709; val_cond_contrastive_loss: 659.5417; val_gene_expr_recon_loss: 285.6343; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 1109.0297; val_optim_loss: 1109.0297\n",
      "Epoch 15/40 |âââââââ-------------| 37.5% val_auroc_score: 0.9467; val_auprc_score: 0.9550; val_best_acc_score: 0.8494; val_best_f1_score: 0.8500; train_kl_reg_loss: 2.2313; train_edge_recon_loss: 159.7958; train_cond_contrastive_loss: 660.8154; train_gene_expr_recon_loss: 284.6465; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 1107.4891; train_optim_loss: 1107.4891; val_kl_reg_loss: 2.2623; val_edge_recon_loss: 163.2568; val_cond_contrastive_loss: 663.1455; val_gene_expr_recon_loss: 288.1133; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 1116.7779; val_optim_loss: 1116.7779\n",
      "\n",
      "Reducing learning rate: metric has not improved more than 0.0 in the last 3 epochs.\n",
      "New learning rate is 1e-05.\n",
      "\n",
      "Epoch 16/40 |ââââââââ------------| 40.0% val_auroc_score: 0.9496; val_auprc_score: 0.9577; val_best_acc_score: 0.8568; val_best_f1_score: 0.8569; train_kl_reg_loss: 2.2537; train_edge_recon_loss: 157.0935; train_cond_contrastive_loss: 655.8883; train_gene_expr_recon_loss: 283.9638; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 1099.1992; train_optim_loss: 1099.1992; val_kl_reg_loss: 2.2654; val_edge_recon_loss: 157.4408; val_cond_contrastive_loss: 656.1352; val_gene_expr_recon_loss: 284.4958; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 1100.3372; val_optim_loss: 1100.3372\n",
      "Epoch 17/40 |ââââââââ------------| 42.5% val_auroc_score: 0.9473; val_auprc_score: 0.9558; val_best_acc_score: 0.8504; val_best_f1_score: 0.8517; train_kl_reg_loss: 2.2482; train_edge_recon_loss: 158.5602; train_cond_contrastive_loss: 656.9363; train_gene_expr_recon_loss: 282.8763; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 1100.6209; train_optim_loss: 1100.6209; val_kl_reg_loss: 2.2606; val_edge_recon_loss: 155.2604; val_cond_contrastive_loss: 653.2642; val_gene_expr_recon_loss: 286.6913; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 1097.4765; val_optim_loss: 1097.4765\n",
      "Epoch 18/40 |âââââââââ-----------| 45.0% val_auroc_score: 0.9476; val_auprc_score: 0.9551; val_best_acc_score: 0.8518; val_best_f1_score: 0.8520; train_kl_reg_loss: 2.2483; train_edge_recon_loss: 158.7780; train_cond_contrastive_loss: 658.0075; train_gene_expr_recon_loss: 284.0981; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 1103.1319; train_optim_loss: 1103.1319; val_kl_reg_loss: 2.2590; val_edge_recon_loss: 158.3146; val_cond_contrastive_loss: 653.7780; val_gene_expr_recon_loss: 286.2174; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 1100.5690; val_optim_loss: 1100.5690\n",
      "Epoch 19/40 |âââââââââ-----------| 47.5% val_auroc_score: 0.9478; val_auprc_score: 0.9556; val_best_acc_score: 0.8531; val_best_f1_score: 0.8526; train_kl_reg_loss: 2.2376; train_edge_recon_loss: 160.1382; train_cond_contrastive_loss: 659.4393; train_gene_expr_recon_loss: 284.5549; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 1106.3700; train_optim_loss: 1106.3700; val_kl_reg_loss: 2.2417; val_edge_recon_loss: 160.6205; val_cond_contrastive_loss: 652.4251; val_gene_expr_recon_loss: 280.1322; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 1095.4196; val_optim_loss: 1095.4196\n",
      "Epoch 20/40 |ââââââââââ----------| 50.0% val_auroc_score: 0.9506; val_auprc_score: 0.9586; val_best_acc_score: 0.8584; val_best_f1_score: 0.8590; train_kl_reg_loss: 2.2349; train_edge_recon_loss: 159.3510; train_cond_contrastive_loss: 656.7047; train_gene_expr_recon_loss: 284.1326; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 1102.4232; train_optim_loss: 1102.4232; val_kl_reg_loss: 2.2443; val_edge_recon_loss: 157.1237; val_cond_contrastive_loss: 651.9938; val_gene_expr_recon_loss: 282.2090; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 1093.5708; val_optim_loss: 1093.5708\n",
      "Epoch 21/40 |ââââââââââ----------| 52.5% val_auroc_score: 0.9524; val_auprc_score: 0.9597; val_best_acc_score: 0.8636; val_best_f1_score: 0.8438; train_kl_reg_loss: 2.3443; train_edge_recon_loss: 159.0409; train_cond_contrastive_loss: 669.0309; train_gene_expr_recon_loss: 284.4765; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 1114.8925; train_optim_loss: 1114.8925; val_kl_reg_loss: 0.8135; val_edge_recon_loss: 165.6865; val_cond_contrastive_loss: 667.2846; val_gene_expr_recon_loss: 285.5512; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 1119.3359; val_optim_loss: 1119.3359\n",
      "Epoch 22/40 |âââââââââââ---------| 55.0% val_auroc_score: 0.9533; val_auprc_score: 0.9600; val_best_acc_score: 0.8743; val_best_f1_score: 0.8567; train_kl_reg_loss: 2.5132; train_edge_recon_loss: 158.7894; train_cond_contrastive_loss: 667.4942; train_gene_expr_recon_loss: 284.2888; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 1113.0855; train_optim_loss: 1113.0855; val_kl_reg_loss: 0.8448; val_edge_recon_loss: 164.0495; val_cond_contrastive_loss: 665.3298; val_gene_expr_recon_loss: 282.6720; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 1112.8961; val_optim_loss: 1112.8961\n",
      "Epoch 23/40 |âââââââââââ---------| 57.5% val_auroc_score: 0.9541; val_auprc_score: 0.9614; val_best_acc_score: 0.8762; val_best_f1_score: 0.8612; train_kl_reg_loss: 2.5888; train_edge_recon_loss: 160.1957; train_cond_contrastive_loss: 667.5643; train_gene_expr_recon_loss: 283.2215; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 1113.5703; train_optim_loss: 1113.5703; val_kl_reg_loss: 0.8523; val_edge_recon_loss: 159.3040; val_cond_contrastive_loss: 665.8294; val_gene_expr_recon_loss: 282.9622; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 1108.9480; val_optim_loss: 1108.9480\n",
      "\n",
      "Reducing learning rate: metric has not improved more than 0.0 in the last 3 epochs.\n",
      "New learning rate is 1.0000000000000002e-06.\n",
      "\n",
      "Epoch 24/40 |ââââââââââââ--------| 60.0% val_auroc_score: 0.9548; val_auprc_score: 0.9604; val_best_acc_score: 0.8766; val_best_f1_score: 0.8603; train_kl_reg_loss: 2.6055; train_edge_recon_loss: 159.2289; train_cond_contrastive_loss: 666.4922; train_gene_expr_recon_loss: 283.3757; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 1111.7024; train_optim_loss: 1111.7024; val_kl_reg_loss: 0.8577; val_edge_recon_loss: 156.7457; val_cond_contrastive_loss: 665.9011; val_gene_expr_recon_loss: 283.8639; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 1107.3683; val_optim_loss: 1107.3683\n"
     ]
    }
   ],
   "source": [
    "train_autotalker_models(dataset=\"seqfish_mouse_organogenesis\",\n",
    "                        reference_batches=[f\"batch{i}\" for i in range(1,7)],\n",
    "                        cell_type_key=\"celltype_mapped_refined\",\n",
    "                        adata_new=None,\n",
    "                        n_start_run=1,\n",
    "                        n_end_run=1,\n",
    "                        n_neighbor_list=[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a6b839-f7ba-41b3-a6cd-b818de304344",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_autotalker_models(dataset=\"seqfish_mouse_organogenesis\",\n",
    "                        reference_batches=[f\"batch{i}\" for i in range(1,7)],\n",
    "                        cell_type_key=\"celltype_mapped_refined\",\n",
    "                        adata_new=None,\n",
    "                        n_start_run=1,\n",
    "                        n_end_run=1,\n",
    "                        n_neighbor_list=[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43617a84-1c81-473e-b275-c6b15a1b9fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_autotalker_models(dataset=\"seqfish_mouse_organogenesis\",\n",
    "                        reference_batches=[f\"batch{i}\" for i in range(1,7)],\n",
    "                        cell_type_key=\"celltype_mapped_refined\",\n",
    "                        adata_new=None,\n",
    "                        n_start_run=1,\n",
    "                        n_end_run=10,\n",
    "                        n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16, 20, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e2d199-174f-4e6e-aa67-e50149b4c4b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(\"../../datasets/srt_data/gold/seqfish_mouse_organogenesis.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38da8b32-f839-494f-a31a-a19f661c0290",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(\"../../datasets/srt_data/gold/results/seqfish_mouse_organogenesis_autotalker_oneshot_integrated.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b6c04b-e1e7-4825-a9ec-5ee46f66ca8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d92d6d-e323-4a04-ae08-26ee096a02e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")\n",
    "from color_utils import seqfish_mouse_organogenesis_cell_type_colors\n",
    "\n",
    "adata.obsm[\"X_umap\"] = adata.obsm[\"autotalker_latent_run1_X_umap\"]\n",
    "cell_type_key = \"cell_type\"\n",
    "\n",
    "# Plot UMAP with batch annotations\n",
    "fig = sc.pl.umap(adata,\n",
    "                 color=[condition_key],\n",
    "                 legend_fontsize=12,\n",
    "                 size=240000/len(adata),\n",
    "                 return_fig=True)\n",
    "fig.set_figheight(7)\n",
    "fig.set_figwidth(7)\n",
    "plt.title(f\"One-Shot Integration: {model_name} Latent Batch Annotations\", size=20, pad=15)\n",
    "\n",
    "# Plot UMAP with cell type annotations\n",
    "fig = sc.pl.umap(adata,\n",
    "                 color=[cell_type_key],\n",
    "                 palette=seqfish_mouse_organogenesis_cell_type_colors,\n",
    "                 legend_fontsize=12,\n",
    "                 size=240000/len(adata),\n",
    "                 return_fig=True)\n",
    "fig.set_figheight(7)\n",
    "fig.set_figwidth(7)\n",
    "plt.title(f\"One-Shot Integration: {model_name} Latent Cell Type Annotations\", size=20, pad=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee102dc-b9fe-47b8-9fb0-e47cae2bb759",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autotalker.benchmarking import compute_clisis, compute_cas\n",
    "import scib\n",
    "\n",
    "spatial_knng_key = \"autotalker_spatial_knng\"\n",
    "latent_knng_key = \"autotalker_latent_run1\"\n",
    "\n",
    "# Compute metrics\n",
    "metrics_dict = {}\n",
    "\n",
    "# Spatial conservation metrics\n",
    "metrics_dict[\"cas\"] = compute_cas(\n",
    "    adata=adata,\n",
    "    cell_type_key=cell_type_key,\n",
    "    condition_key=condition_key,\n",
    "    spatial_knng_key=spatial_knng_key,\n",
    "    latent_knng_key=latent_knng_key,\n",
    "    spatial_key=spatial_key,\n",
    "    latent_key=latent_key)\n",
    "metrics_dict[\"clisis\"] = compute_clisis(\n",
    "    adata=adata,\n",
    "    cell_type_key=cell_type_key,\n",
    "    condition_key=condition_key,\n",
    "    spatial_knng_key=spatial_knng_key,\n",
    "    latent_knng_key=latent_knng_key,\n",
    "    spatial_key=spatial_key,\n",
    "    latent_key=latent_key)\n",
    "\n",
    "# Batch correction metrics\n",
    "metrics_dict[\"asw\"] = scib.me.silhouette_batch(\n",
    "    adata=adata,\n",
    "    batch_key=condition_key,\n",
    "    label_key=cell_type_key,\n",
    "    embed=latent_key)\n",
    "metrics_dict[\"ilisi\"] = scib.me.ilisi_graph(\n",
    "    adata=adata,\n",
    "    batch_key=condition_key,\n",
    "    type_=\"embed\",\n",
    "    use_rep=latent_key)\n",
    "    #type_=\"knn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b528e64-9ee4-4cc8-9936-a225130b4b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147568e6-b055-4181-900f-d47d5984bf0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
