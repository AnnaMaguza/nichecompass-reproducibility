{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "364a9ebc-3e3c-4645-9049-a34bd084c8a8",
   "metadata": {},
   "source": [
    "# Autotalker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c55227-147e-417f-b0dd-bb0b7f322930",
   "metadata": {},
   "source": [
    "- **Creator**: Sebastian Birk (<sebastian.birk@helmholtz-munich.de>).\n",
    "- **Affiliation:** Helmholtz Munich, Institute of Computational Biology (ICB), Talavera-LÃ³pez Lab\n",
    "- **Date of Creation:** 13.01.2023\n",
    "- **Date of Last Modification:** 31.03.2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa669117-f347-4666-b112-8ea6669fd9e9",
   "metadata": {},
   "source": [
    "- The Autotalker source code is available at https://github.com/Talavera-Lopez-Lab/autotalker.\n",
    "- The workflow of this notebook follows the tutorial from https://github.com/sebastianbirk/autotalker/blob/main/notebooks/autotalker_tutorial.ipynb.\n",
    "- It is recommended to use raw counts as input to Autotalker. Therefore, we use raw counts (stored in adata.layers[\"counts\"])."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7529cde5-be12-403b-a94c-07561774b86c",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faad87bd-fef5-4429-a175-d714c491ae76",
   "metadata": {},
   "source": [
    "### 1.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9305ecb-5d4b-4cdd-8e92-f7155426b7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../../autotalker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7f93960-c759-424f-8cb2-1d8698acae2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import gc\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "\n",
    "import anndata as ad\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import scipy.sparse as sp\n",
    "import seaborn as sns\n",
    "import squidpy as sq\n",
    "import torch\n",
    "from matplotlib.pyplot import rc_context\n",
    "\n",
    "from autotalker.models import Autotalker\n",
    "from autotalker.utils import (add_gps_from_gp_dict_to_adata,\n",
    "                              extract_gp_dict_from_mebocost_es_interactions,\n",
    "                              extract_gp_dict_from_nichenet_ligand_target_mx,\n",
    "                              extract_gp_dict_from_omnipath_lr_interactions,\n",
    "                              filter_and_combine_gp_dict_gps,\n",
    "                              get_unique_genes_from_gp_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b5efa5-2052-4986-8ae5-89cfab018515",
   "metadata": {},
   "source": [
    "### 1.2 Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5c8b48a-ed5e-48b5-8c5c-c1de11493aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"autotalker\"\n",
    "latent_key = f\"{model_name}_latent\"\n",
    "mapping_entity_key = \"reference\"\n",
    "condition_key = \"batch\"\n",
    "counts_key = \"counts\"\n",
    "spatial_key = \"spatial\"\n",
    "adj_key = \"spatial_connectivities\"\n",
    "nichenet_keep_target_genes_ratio = 0.01\n",
    "nichenet_max_n_target_genes_per_gp = 25344\n",
    "include_mebocost_gps = True\n",
    "mebocost_species = \"mouse\"\n",
    "filter_genes = False\n",
    "gp_filter_mode = \"subset\"\n",
    "combine_overlap_gps = True\n",
    "overlap_thresh_source_genes = 0.9\n",
    "overlap_thresh_target_genes = 0.9\n",
    "overlap_thresh_genes = 0.9\n",
    "active_gp_names_key = \"autotalker_active_gp_names\"\n",
    "gp_targets_mask_key = \"autotalker_gp_targets_mask\"\n",
    "gp_sources_mask_key = \"autotalker_gp_sources_mask\"\n",
    "gp_names_key = \"autotalker_gp_names\"\n",
    "active_gp_thresh_ratio = 0.03\n",
    "gene_expr_recon_dist = \"nb\"\n",
    "cond_embed_injection = \"gene_expr_decoder\"\n",
    "log_variational = True\n",
    "n_layers_encoder = 2\n",
    "conv_layer_encoder = \"gcnconv\"\n",
    "n_epochs = 40\n",
    "n_epochs_all_gps = 20\n",
    "lr = 0.001\n",
    "lambda_edge_recon = 1000.\n",
    "lambda_gene_expr_recon = 1.\n",
    "lambda_cond_contrastive = 300.\n",
    "cond_contrastive_thresh = 0.9\n",
    "lambda_group_lasso = 0.\n",
    "lambda_l1_masked = 0.\n",
    "edge_batch_size = 256\n",
    "node_batch_size = 32\n",
    "leiden_resolution = 0.01 # used for Leiden clustering of latent space; 0.1\n",
    "random_seed = 0 # used for Leiden clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28adc110-0f41-4a71-9838-dc7f0687809a",
   "metadata": {},
   "source": [
    "### 1.3 Run Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "334b87ca-3387-4ba9-8567-84bc4754ff0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.set_figure_params(figsize=(6, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ab6b302-1c0b-4937-8624-40629ada2e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get time of notebook execution for timestamping saved artifacts\n",
    "now = datetime.now()\n",
    "current_timestamp = now.strftime(\"%d%m%Y_%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85538952-006b-4b0b-a50c-fe7445ce22e2",
   "metadata": {},
   "source": [
    "### 1.4 Configure Paths and Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ddcc49c-ba22-4155-acd5-05b5b810e091",
   "metadata": {},
   "outputs": [],
   "source": [
    "srt_data_gold_folder_path = \"../../datasets/srt_data/gold/\"\n",
    "figure_folder_path = f\"../../figures\"\n",
    "gp_data_folder_path = \"../../datasets/gp_data\" # gene program data\n",
    "nichenet_ligand_target_mx_file_path = gp_data_folder_path + \"/nichenet_ligand_target_matrix.csv\"\n",
    "omnipath_lr_interactions_file_path = gp_data_folder_path + \"/omnipath_lr_interactions.csv\"\n",
    "\n",
    "# Create required directories\n",
    "os.makedirs(gp_data_folder_path, exist_ok=True)\n",
    "os.makedirs(srt_data_gold_folder_path + \"/results\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d974cd00-eafa-4432-b172-fafc4058a619",
   "metadata": {},
   "source": [
    "## 2. Autotalker Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b908c99c-de2f-4239-8420-00bd1fd58baa",
   "metadata": {},
   "source": [
    "### 2.1 Prepare Gene Program Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06c510ab-e3b1-41e7-848d-e4b9513313cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the gene program mask...\n",
      "Number of gene programs before filtering and combining: 1725.\n",
      "Number of gene programs after filtering and combining: 1575.\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing the gene program mask...\")\n",
    "# OmniPath gene programs\n",
    "omnipath_gp_dict = extract_gp_dict_from_omnipath_lr_interactions(\n",
    "    min_curation_effort=0,\n",
    "    load_from_disk=True,\n",
    "    save_to_disk=False,\n",
    "    file_path=omnipath_lr_interactions_file_path,\n",
    "    plot_gp_gene_count_distributions=False)\n",
    "\n",
    "omnipath_genes = get_unique_genes_from_gp_dict(\n",
    "    gp_dict=omnipath_gp_dict,\n",
    "    retrieved_gene_entities=[\"sources\", \"targets\"])\n",
    "\n",
    "# NicheNet gene programs\n",
    "nichenet_gp_dict = extract_gp_dict_from_nichenet_ligand_target_mx(\n",
    "    keep_target_genes_ratio=nichenet_keep_target_genes_ratio,\n",
    "    max_n_target_genes_per_gp=nichenet_max_n_target_genes_per_gp,\n",
    "    load_from_disk=True,\n",
    "    save_to_disk=False,\n",
    "    file_path=nichenet_ligand_target_mx_file_path,\n",
    "    plot_gp_gene_count_distributions=False)\n",
    "\n",
    "nichenet_source_genes = get_unique_genes_from_gp_dict(\n",
    "    gp_dict=nichenet_gp_dict,\n",
    "    retrieved_gene_entities=[\"sources\"])\n",
    "\n",
    "# Combine gene programs into one dictionary\n",
    "combined_gp_dict = dict(omnipath_gp_dict)\n",
    "combined_gp_dict.update(nichenet_gp_dict)\n",
    "\n",
    "if filter_genes:\n",
    "    # Get gene program relevant genes\n",
    "    gp_relevant_genes = list(set(omnipath_genes + nichenet_source_genes))\n",
    "\n",
    "# Mebocost gene programs\n",
    "if include_mebocost_gps:\n",
    "    mebocost_gp_dict = extract_gp_dict_from_mebocost_es_interactions(\n",
    "    dir_path=f\"{gp_data_folder_path}/metabolite_enzyme_sensor_gps/\",\n",
    "    species=mebocost_species,\n",
    "    genes_uppercase=True,\n",
    "    plot_gp_gene_count_distributions=False)\n",
    "    \n",
    "    mebocost_genes = get_unique_genes_from_gp_dict(\n",
    "        gp_dict=mebocost_gp_dict,\n",
    "        retrieved_gene_entities=[\"sources\", \"targets\"])\n",
    "\n",
    "    combined_gp_dict.update(mebocost_gp_dict)\n",
    "    \n",
    "    if filter_genes:\n",
    "        # Update gene program relevant genes\n",
    "        gp_relevant_genes = list(set(gp_relevant_genes + mebocost_genes))\n",
    "    \n",
    "# Filter and combine gene programs\n",
    "combined_new_gp_dict = filter_and_combine_gp_dict_gps(\n",
    "    gp_dict=combined_gp_dict,\n",
    "    gp_filter_mode=gp_filter_mode,\n",
    "    combine_overlap_gps=combine_overlap_gps,\n",
    "    overlap_thresh_source_genes=overlap_thresh_source_genes,\n",
    "    overlap_thresh_target_genes=overlap_thresh_target_genes,\n",
    "    overlap_thresh_genes=overlap_thresh_genes,\n",
    "    verbose=False)\n",
    "\n",
    "print(\"Number of gene programs before filtering and combining: \"\n",
    "      f\"{len(combined_gp_dict)}.\")\n",
    "print(f\"Number of gene programs after filtering and combining: \"\n",
    "      f\"{len(combined_new_gp_dict)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d712fe8e-6438-4b1d-9ec8-6b6f4408627b",
   "metadata": {},
   "source": [
    "### 2.2 Define Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ea39b0f-9c9a-459a-ba2e-c843802a8e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_autotalker_models(dataset,\n",
    "                            reference_batches,\n",
    "                            cell_type_key,\n",
    "                            adata_new=None,\n",
    "                            n_start_run=1,\n",
    "                            n_end_run=10,\n",
    "                            n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16, 20, 20],\n",
    "                            plot_latent_umaps: bool=False):\n",
    "    # Create new adata to store results from training runs in storage-efficient way\n",
    "    if adata_new is None:  \n",
    "        adata_batch_list = []\n",
    "        if reference_batches is not None:\n",
    "            for batch in reference_batches:\n",
    "                adata_batch = ad.read_h5ad(\n",
    "                    f\"{srt_data_gold_folder_path}/{dataset}_{batch}.h5ad\")\n",
    "                adata_batch.obs[mapping_entity_key] = \"reference\"\n",
    "                adata_batch_list.append(adata_batch)\n",
    "            adata_original = ad.concat(adata_batch_list, join=\"inner\")\n",
    "        else:\n",
    "            adata_original = ad.read_h5ad(f\"{srt_data_gold_folder_path}/{dataset}.h5ad\")\n",
    "\n",
    "        adata_new = sc.AnnData(sp.csr_matrix(\n",
    "            (adata_original.shape[0], adata_original.shape[1]),\n",
    "            dtype=np.float32))\n",
    "        adata_new.var_names = adata_original.var_names\n",
    "        adata_new.obs_names = adata_original.obs_names\n",
    "        adata_new.obs[\"cell_type\"] = adata_original.obs[cell_type_key].values\n",
    "        adata_new.obsm[\"spatial\"] = adata_original.obsm[\"spatial\"]\n",
    "        adata_new.obs[condition_key] = adata_original.obs[condition_key]\n",
    "        adata_new.obs[mapping_entity_key] = adata_original.obs[mapping_entity_key] \n",
    "        del(adata_original)\n",
    "    \n",
    "    model_seeds = list(range(10))\n",
    "    for run_number, n_neighbors in zip(np.arange(n_start_run, n_end_run+1), n_neighbor_list):\n",
    "        # Load data\n",
    "        adata_batch_list = []\n",
    "        if reference_batches is not None:\n",
    "            for batch in reference_batches:\n",
    "                print(f\"Processing batch {batch}...\")\n",
    "                print(\"Loading data...\")\n",
    "                adata_batch = ad.read_h5ad(\n",
    "                    f\"{srt_data_gold_folder_path}/{dataset}_{batch}.h5ad\")\n",
    "                adata_batch.obs[mapping_entity_key] = \"reference\"\n",
    "                print(\"Computing spatial neighborhood graph...\\n\")\n",
    "                # Compute (separate) spatial neighborhood graphs\n",
    "                sq.gr.spatial_neighbors(adata_batch,\n",
    "                                        coord_type=\"generic\",\n",
    "                                        spatial_key=spatial_key,\n",
    "                                        n_neighs=n_neighbors)\n",
    "                # Make adjacency matrix symmetric\n",
    "                adata_batch.obsp[adj_key] = (\n",
    "                    adata_batch.obsp[adj_key].maximum(\n",
    "                        adata_batch.obsp[adj_key].T))\n",
    "                adata_batch_list.append(adata_batch)\n",
    "            adata = ad.concat(adata_batch_list, join=\"inner\")\n",
    "\n",
    "            # Combine spatial neighborhood graphs as disconnected components\n",
    "            batch_connectivities = []\n",
    "            len_before_batch = 0\n",
    "            for i in range(len(adata_batch_list)):\n",
    "                if i == 0: # first batch\n",
    "                    after_batch_connectivities_extension = sp.csr_matrix(\n",
    "                        (adata_batch_list[0].shape[0],\n",
    "                        (adata.shape[0] -\n",
    "                        adata_batch_list[0].shape[0])))\n",
    "                    batch_connectivities.append(sp.hstack(\n",
    "                        (adata_batch_list[0].obsp[adj_key],\n",
    "                        after_batch_connectivities_extension)))\n",
    "                elif i == (len(adata_batch_list) - 1): # last batch\n",
    "                    before_batch_connectivities_extension = sp.csr_matrix(\n",
    "                        (adata_batch_list[i].shape[0],\n",
    "                        (adata.shape[0] -\n",
    "                        adata_batch_list[i].shape[0])))\n",
    "                    batch_connectivities.append(sp.hstack(\n",
    "                        (before_batch_connectivities_extension,\n",
    "                        adata_batch_list[i].obsp[adj_key])))\n",
    "                else: # middle batches\n",
    "                    before_batch_connectivities_extension = sp.csr_matrix(\n",
    "                        (adata_batch_list[i].shape[0], len_before_batch))\n",
    "                    after_batch_connectivities_extension = sp.csr_matrix(\n",
    "                        (adata_batch_list[i].shape[0],\n",
    "                        (adata.shape[0] -\n",
    "                        adata_batch_list[i].shape[0] -\n",
    "                        len_before_batch)))\n",
    "                    batch_connectivities.append(sp.hstack(\n",
    "                        (before_batch_connectivities_extension,\n",
    "                        adata_batch_list[i].obsp[adj_key],\n",
    "                        after_batch_connectivities_extension)))\n",
    "                len_before_batch += adata_batch_list[i].shape[0]\n",
    "            connectivities = sp.vstack(batch_connectivities)\n",
    "            adata.obsp[adj_key] = connectivities\n",
    "        else:\n",
    "            adata = ad.read_h5ad(f\"{srt_data_gold_folder_path}/{dataset}.h5ad\")\n",
    "            # Compute (separate) spatial neighborhood graphs\n",
    "            sq.gr.spatial_neighbors(adata,\n",
    "                                    coord_type=\"generic\",\n",
    "                                    spatial_key=spatial_key,\n",
    "                                    n_neighs=n_neighbors)\n",
    "            # Make adjacency matrix symmetric\n",
    "            adata.obsp[adj_key] = (\n",
    "                adata.obsp[adj_key].maximum(\n",
    "                    adata.obsp[adj_key].T))\n",
    "            \n",
    "        # Filter genes if specified\n",
    "        if filter_genes:\n",
    "            print(\"\\nFiltering genes...\")\n",
    "            # Filter genes and only keep ligand, receptor, metabolitye enzyme, \n",
    "            # metabolite sensor and the 'n_hvg' highly variable genes (potential target\n",
    "            # genes of nichenet)\n",
    "            gp_dict_genes = get_unique_genes_from_gp_dict(\n",
    "                gp_dict=combined_new_gp_dict,\n",
    "                retrieved_gene_entities=[\"sources\", \"targets\"])\n",
    "            print(f\"Starting with {len(adata.var_names)} genes.\")\n",
    "            sc.pp.filter_genes(adata,\n",
    "                               min_cells=0)\n",
    "            print(f\"Keeping {len(adata.var_names)} genes after filtering \"\n",
    "                  \"genes with expression in 0 cells.\")\n",
    "\n",
    "            if counts_key is not None:\n",
    "                hvg_layer = counts_key\n",
    "                if (adata.layers[counts_key].astype(int).sum() == \n",
    "                adata.layers[counts_key].sum()): # raw counts\n",
    "                    hvg_flavor = \"seurat_v3\"\n",
    "                else:\n",
    "                    hvg_flavor = \"seurat\" # log normalized counts\n",
    "            else:\n",
    "                hvg_layer = None\n",
    "                if adata.X.astype(int).sum() == adata.X.sum(): # raw counts\n",
    "                    hvg_flavor = \"seurat_v3\"\n",
    "                else: # log normalized counts\n",
    "                    hvg_flavor = \"seurat\"\n",
    "\n",
    "            sc.pp.highly_variable_genes(\n",
    "                adata,\n",
    "                layer=hvg_layer,\n",
    "                n_top_genes=n_hvg,\n",
    "                flavor=hvg_flavor,\n",
    "                batch_key=condition_key,\n",
    "                subset=False)\n",
    "\n",
    "            adata.var[\"gp_relevant\"] = (\n",
    "                adata.var.index.str.upper().isin(gp_relevant_genes))\n",
    "            adata.var[\"keep_gene\"] = (adata.var[\"gp_relevant\"] | \n",
    "                                                adata.var[\"highly_variable\"])\n",
    "            adata = (\n",
    "                adata[:, adata.var[\"keep_gene\"] == True])\n",
    "            print(f\"Keeping {len(adata.var_names)} highly variable or gene \"\n",
    "                  \"program relevant genes.\")\n",
    "            adata = (\n",
    "                adata[:, adata.var_names[\n",
    "                    adata.var_names.str.upper().isin(\n",
    "                        gp_dict_genes)].sort_values()])\n",
    "            print(f\"Keeping {len(adata.var_names)} genes after filtering \"\n",
    "                  \"genes not in gp dict.\")\n",
    "        \n",
    "        # Add the gene program dictionary as binary masks to the adata for model \n",
    "        # training\n",
    "        add_gps_from_gp_dict_to_adata(\n",
    "            gp_dict=combined_new_gp_dict,\n",
    "            adata=adata,\n",
    "            genes_uppercase=True,\n",
    "            gp_targets_mask_key=gp_targets_mask_key,\n",
    "            gp_sources_mask_key=gp_sources_mask_key,\n",
    "            gp_names_key=gp_names_key,\n",
    "            min_genes_per_gp=1,\n",
    "            min_source_genes_per_gp=0,\n",
    "            min_target_genes_per_gp=0,\n",
    "            max_genes_per_gp=None,\n",
    "            max_source_genes_per_gp=None,\n",
    "            max_target_genes_per_gp=None,\n",
    "            filter_genes_not_in_masks=False)\n",
    "\n",
    "        # Determine dimensionality of hidden encoder\n",
    "        n_hidden_encoder = len(adata.uns[f\"{model_name}_gp_names\"])\n",
    "        n_cond_embed = int(len(adata.var_names) / 2)\n",
    "\n",
    "        start_time = time.time()\n",
    "        \n",
    "        print(\"\\nTraining model...\")\n",
    "        # Initialize model\n",
    "        model = Autotalker(adata,\n",
    "                           counts_key=counts_key,\n",
    "                           adj_key=adj_key,\n",
    "                           condition_key=condition_key,\n",
    "                           cond_embed_injection=cond_embed_injection,\n",
    "                           n_cond_embed=n_cond_embed,\n",
    "                           gp_names_key=gp_names_key,\n",
    "                           active_gp_names_key=active_gp_names_key,\n",
    "                           gp_targets_mask_key=gp_targets_mask_key,\n",
    "                           gp_sources_mask_key=gp_sources_mask_key,\n",
    "                           latent_key=latent_key,\n",
    "                           active_gp_thresh_ratio=active_gp_thresh_ratio,\n",
    "                           gene_expr_recon_dist=gene_expr_recon_dist,\n",
    "                           n_layers_encoder=n_layers_encoder,\n",
    "                           conv_layer_encoder=conv_layer_encoder,\n",
    "                           n_hidden_encoder=n_hidden_encoder,\n",
    "                           log_variational=log_variational)\n",
    "\n",
    "        # Train model\n",
    "        model.train(n_epochs=n_epochs,\n",
    "                    n_epochs_all_gps=n_epochs_all_gps,\n",
    "                    lr=lr,\n",
    "                    lambda_edge_recon=lambda_edge_recon,\n",
    "                    lambda_gene_expr_recon=lambda_gene_expr_recon,\n",
    "                    lambda_cond_contrastive=lambda_cond_contrastive,\n",
    "                    cond_contrastive_thresh=cond_contrastive_thresh,\n",
    "                    lambda_group_lasso=lambda_group_lasso,\n",
    "                    lambda_l1_masked=lambda_l1_masked,\n",
    "                    edge_batch_size=edge_batch_size,\n",
    "                    node_batch_size=node_batch_size,\n",
    "                    seed=model_seeds[run_number-1],\n",
    "                    verbose=True)        \n",
    "        \n",
    "        # Measure time for model training\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        hours, rem = divmod(elapsed_time, 3600)\n",
    "        minutes, seconds = divmod(rem, 60)\n",
    "        print(f\"Duration of model training in run {run_number}: \"\n",
    "              f\"{int(hours)} hours, {int(minutes)} minutes and {int(seconds)} seconds.\")\n",
    "        adata_new.uns[f\"{model_name}_model_training_duration_run{run_number}\"] = (\n",
    "            elapsed_time)\n",
    "\n",
    "        if plot_latent_umaps:\n",
    "            # Configure figure folder path\n",
    "            dataset_figure_folder_path = f\"{figure_folder_path}/{dataset}/sample_integration_method_benchmarking/\" \\\n",
    "                                         f\"{model_name}/{current_timestamp}\"\n",
    "            os.makedirs(dataset_figure_folder_path, exist_ok=True)\n",
    "            \n",
    "            # Use Autotalker latent space for UMAP generation\n",
    "            sc.pp.neighbors(adata,\n",
    "                            use_rep=latent_key,\n",
    "                            n_neighbors=n_neighbors)\n",
    "            sc.tl.umap(adata)\n",
    "            fig = sc.pl.umap(adata,\n",
    "                             color=[cell_type_key],\n",
    "                             title=f\"Latent Space with Cell Types: {model_name.capitalize()}\",\n",
    "                             return_fig=True)\n",
    "            fig.savefig(f\"{dataset_figure_folder_path}/latent_{model_name}\"\n",
    "                        f\"_cell_types_run{run_number}.png\",\n",
    "                        bbox_inches=\"tight\")\n",
    "\n",
    "            # Compute latent Leiden clustering\n",
    "            sc.tl.leiden(adata=adata,\n",
    "                         resolution=leiden_resolution,\n",
    "                         random_state=random_seed,\n",
    "                         key_added=f\"latent_{model_name}_leiden_{str(leiden_resolution)}\")\n",
    "\n",
    "            # Create subplot of latent Leiden cluster annotations in physical and latent space\n",
    "            fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(6, 12))\n",
    "            title = fig.suptitle(t=\"Latent and Physical Space with Leiden Clusters: \"\n",
    "                                   f\"{model_name.capitalize()}\")\n",
    "            sc.pl.umap(adata=adata,\n",
    "                       color=[f\"latent_{model_name}_leiden_{str(leiden_resolution)}\"],\n",
    "                       title=f\"Latent Space with Leiden Clusters\",\n",
    "                       ax=axs[0],\n",
    "                       show=False)\n",
    "            sq.pl.spatial_scatter(adata=adata,\n",
    "                                  color=[f\"latent_{model_name}_leiden_{str(leiden_resolution)}\"],\n",
    "                                  title=f\"Physical Space with Leiden Clusters\",\n",
    "                                  shape=None,\n",
    "                                  ax=axs[1])\n",
    "\n",
    "            # Create and position shared legend\n",
    "            handles, labels = axs[0].get_legend_handles_labels()\n",
    "            lgd = fig.legend(handles, labels, bbox_to_anchor=(1.25, 0.9185))\n",
    "            axs[0].get_legend().remove()\n",
    "            axs[1].get_legend().remove()\n",
    "\n",
    "            # Adjust, save and display plot\n",
    "            plt.subplots_adjust(wspace=0, hspace=0.2)\n",
    "            fig.savefig(f\"{dataset_figure_folder_path}/latent_physical_comparison_\"\n",
    "                        f\"{model_name}_run{run_number}.png\",\n",
    "                        bbox_extra_artists=(lgd, title),\n",
    "                        bbox_inches=\"tight\")\n",
    "            plt.show()\n",
    "\n",
    "        # Store latent representation\n",
    "        adata_new.obsm[latent_key + f\"_run{run_number}\"] = adata.obsm[latent_key]\n",
    "        \n",
    "        # Use latent representation for UMAP generation\n",
    "        sc.pp.neighbors(adata_new,\n",
    "                        use_rep=f\"{latent_key}_run{run_number}\",\n",
    "                        key_added=f\"{latent_key}_run{run_number}\")\n",
    "        sc.tl.umap(adata_new,\n",
    "                   neighbors_key=f\"{latent_key}_run{run_number}\")\n",
    "        adata_new.obsm[f\"{latent_key}_run{run_number}_X_umap\"] = adata_new.obsm[\"X_umap\"]\n",
    "        del(adata_new.obsm[\"X_umap\"])\n",
    "\n",
    "        # Store intermediate adata to disk\n",
    "        adata_new.write(f\"{srt_data_gold_folder_path}/results/{dataset}_{model_name}_oneshot_integrated.h5ad\")\n",
    "        \n",
    "        # Free memory\n",
    "        del(adata)\n",
    "        del(model)\n",
    "        gc.collect()\n",
    "\n",
    "    # Store final adata to disk\n",
    "    adata_new.write(f\"{srt_data_gold_folder_path}/results/{dataset}_{model_name}_oneshot_integrated.h5ad\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5471d723-2807-44a9-aea2-4736131b614d",
   "metadata": {},
   "source": [
    "### 2.3 Train Models on Benchmarking Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3592bdd4-a763-4323-ae3a-8087f4c77af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Computing spatial neighborhood graph...\n",
      "\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Computing spatial neighborhood graph...\n",
      "\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Computing spatial neighborhood graph...\n",
      "\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Computing spatial neighborhood graph...\n",
      "\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Computing spatial neighborhood graph...\n",
      "\n",
      "Processing batch batch6...\n",
      "Loading data...\n",
      "Computing spatial neighborhood graph...\n",
      "\n",
      "\n",
      "Training model...\n",
      "--- INITIALIZING NEW NETWORK MODULE: VARIATIONAL GENE PROGRAM GRAPH AUTOENCODER ---\n",
      "LOSS -> include_edge_recon_loss: True, include_gene_expr_recon_loss: True, gene_expr_recon_dist: nb\n",
      "NODE LABEL METHOD -> one-hop-attention\n",
      "ACTIVE GP THRESHOLD RATIO -> 0.03\n",
      "LOG VARIATIONAL -> True\n",
      "CONDITIONAL EMBEDDING INJECTION -> gene_expr_decoder\n",
      "GRAPH ENCODER -> n_input: 351, n_cond_embed_input: 0, n_layers: 2, n_hidden: 489, n_latent: 489, n_addon_latent: 0, conv_layer: gcnconv, n_attention_heads: 0, dropout_rate: 0.0\n",
      "COSINE SIM GRAPH DECODER -> n_cond_embed_input: 0, n_output: 489, dropout_rate: 0.0\n",
      "MASKED GENE EXPRESSION DECODER -> n_input: 489, n_cond_embed_input: 175, n_addon_input: 0, n_output: 702\n",
      "\n",
      "--- INITIALIZING TRAINER ---\n",
      "Number of training nodes: 47311\n",
      "Number of validation nodes: 5257\n",
      "Number of training edges: 109836\n",
      "Number of validation edges: 12204\n",
      "\n",
      "--- MODEL TRAINING ---\n",
      "Epoch 1/40 |--------------------| 2.5% val_auroc_score: 0.9541; val_auprc_score: 0.9441; val_best_acc_score: 0.9036; val_best_f1_score: 0.9082; train_kl_reg_loss: 0.2718; train_edge_recon_loss: 162.3833; train_cond_contrastive_loss: 165.4194; train_gene_expr_recon_loss: 325.3390; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 653.4135; train_optim_loss: 653.4135; val_kl_reg_loss: 0.3156; val_edge_recon_loss: 158.3387; val_cond_contrastive_loss: 193.1329; val_gene_expr_recon_loss: 311.0742; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 662.8614; val_optim_loss: 662.8614\n",
      "Epoch 2/40 |â-------------------| 5.0% val_auroc_score: 0.9512; val_auprc_score: 0.9388; val_best_acc_score: 0.9125; val_best_f1_score: 0.9169; train_kl_reg_loss: 0.3423; train_edge_recon_loss: 152.8356; train_cond_contrastive_loss: 190.0683; train_gene_expr_recon_loss: 306.3626; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 649.6087; train_optim_loss: 649.6087; val_kl_reg_loss: 0.3433; val_edge_recon_loss: 154.0024; val_cond_contrastive_loss: 190.2557; val_gene_expr_recon_loss: 302.9348; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 647.5362; val_optim_loss: 647.5362\n",
      "Epoch 3/40 |â-------------------| 7.5% val_auroc_score: 0.9561; val_auprc_score: 0.9438; val_best_acc_score: 0.9216; val_best_f1_score: 0.9241; train_kl_reg_loss: 0.3857; train_edge_recon_loss: 152.1919; train_cond_contrastive_loss: 190.0262; train_gene_expr_recon_loss: 301.4746; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 644.0785; train_optim_loss: 644.0785; val_kl_reg_loss: 0.3500; val_edge_recon_loss: 154.7139; val_cond_contrastive_loss: 191.8849; val_gene_expr_recon_loss: 300.3771; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 647.3259; val_optim_loss: 647.3259\n",
      "Epoch 4/40 |ââ------------------| 10.0% val_auroc_score: 0.9449; val_auprc_score: 0.9248; val_best_acc_score: 0.9203; val_best_f1_score: 0.9234; train_kl_reg_loss: 0.4194; train_edge_recon_loss: 152.2690; train_cond_contrastive_loss: 189.5502; train_gene_expr_recon_loss: 296.7301; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 638.9687; train_optim_loss: 638.9687; val_kl_reg_loss: 0.4376; val_edge_recon_loss: 157.3046; val_cond_contrastive_loss: 189.9512; val_gene_expr_recon_loss: 293.3015; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 640.9950; val_optim_loss: 640.9950\n",
      "Epoch 5/40 |ââ------------------| 12.5% val_auroc_score: 0.9499; val_auprc_score: 0.9301; val_best_acc_score: 0.9261; val_best_f1_score: 0.9283; train_kl_reg_loss: 0.4726; train_edge_recon_loss: 154.0158; train_cond_contrastive_loss: 189.6938; train_gene_expr_recon_loss: 294.4818; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 638.6641; train_optim_loss: 638.6641; val_kl_reg_loss: 0.4692; val_edge_recon_loss: 155.3535; val_cond_contrastive_loss: 190.4697; val_gene_expr_recon_loss: 290.4333; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 636.7257; val_optim_loss: 636.7257\n",
      "Epoch 6/40 |âââ-----------------| 15.0% val_auroc_score: 0.9423; val_auprc_score: 0.9183; val_best_acc_score: 0.9232; val_best_f1_score: 0.9265; train_kl_reg_loss: 0.4975; train_edge_recon_loss: 153.0161; train_cond_contrastive_loss: 189.3836; train_gene_expr_recon_loss: 289.7143; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 632.6115; train_optim_loss: 632.6115; val_kl_reg_loss: 0.5766; val_edge_recon_loss: 157.2163; val_cond_contrastive_loss: 189.2015; val_gene_expr_recon_loss: 290.3201; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 637.3146; val_optim_loss: 637.3146\n",
      "Epoch 7/40 |âââ-----------------| 17.5% val_auroc_score: 0.9450; val_auprc_score: 0.9237; val_best_acc_score: 0.9263; val_best_f1_score: 0.9300; train_kl_reg_loss: 0.5519; train_edge_recon_loss: 152.1008; train_cond_contrastive_loss: 189.2487; train_gene_expr_recon_loss: 288.3065; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 630.2079; train_optim_loss: 630.2079; val_kl_reg_loss: 0.5217; val_edge_recon_loss: 154.8149; val_cond_contrastive_loss: 189.6242; val_gene_expr_recon_loss: 287.5213; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 632.4821; val_optim_loss: 632.4821\n",
      "Epoch 8/40 |ââââ----------------| 20.0% val_auroc_score: 0.9384; val_auprc_score: 0.9124; val_best_acc_score: 0.9249; val_best_f1_score: 0.9281; train_kl_reg_loss: 0.5382; train_edge_recon_loss: 153.9157; train_cond_contrastive_loss: 188.9755; train_gene_expr_recon_loss: 286.1785; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 629.6079; train_optim_loss: 629.6079; val_kl_reg_loss: 0.5871; val_edge_recon_loss: 155.4288; val_cond_contrastive_loss: 188.4636; val_gene_expr_recon_loss: 286.0934; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 630.5728; val_optim_loss: 630.5728\n",
      "Epoch 9/40 |ââââ----------------| 22.5% val_auroc_score: 0.9422; val_auprc_score: 0.9157; val_best_acc_score: 0.9297; val_best_f1_score: 0.9323; train_kl_reg_loss: 0.5681; train_edge_recon_loss: 153.0767; train_cond_contrastive_loss: 189.0242; train_gene_expr_recon_loss: 286.5179; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 629.1869; train_optim_loss: 629.1869; val_kl_reg_loss: 0.5935; val_edge_recon_loss: 158.4236; val_cond_contrastive_loss: 190.0564; val_gene_expr_recon_loss: 281.1416; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 630.2151; val_optim_loss: 630.2151\n",
      "Epoch 10/40 |âââââ---------------| 25.0% val_auroc_score: 0.9443; val_auprc_score: 0.9200; val_best_acc_score: 0.9302; val_best_f1_score: 0.9334; train_kl_reg_loss: 0.5779; train_edge_recon_loss: 153.0568; train_cond_contrastive_loss: 189.2357; train_gene_expr_recon_loss: 284.0403; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 626.9107; train_optim_loss: 626.9107; val_kl_reg_loss: 0.5955; val_edge_recon_loss: 152.5806; val_cond_contrastive_loss: 188.8913; val_gene_expr_recon_loss: 281.8257; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 623.8931; val_optim_loss: 623.8931\n",
      "Epoch 11/40 |âââââ---------------| 27.5% val_auroc_score: 0.9415; val_auprc_score: 0.9193; val_best_acc_score: 0.9291; val_best_f1_score: 0.9322; train_kl_reg_loss: 0.5812; train_edge_recon_loss: 152.9973; train_cond_contrastive_loss: 189.4924; train_gene_expr_recon_loss: 281.7451; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 624.8161; train_optim_loss: 624.8161; val_kl_reg_loss: 0.5265; val_edge_recon_loss: 157.2199; val_cond_contrastive_loss: 189.7977; val_gene_expr_recon_loss: 279.9823; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 627.5263; val_optim_loss: 627.5263\n",
      "Epoch 12/40 |ââââââ--------------| 30.0% val_auroc_score: 0.9458; val_auprc_score: 0.9219; val_best_acc_score: 0.9339; val_best_f1_score: 0.9358; train_kl_reg_loss: 0.5948; train_edge_recon_loss: 152.7902; train_cond_contrastive_loss: 189.6933; train_gene_expr_recon_loss: 280.4241; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 623.5024; train_optim_loss: 623.5024; val_kl_reg_loss: 0.5719; val_edge_recon_loss: 156.5413; val_cond_contrastive_loss: 190.0356; val_gene_expr_recon_loss: 279.8162; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 626.9649; val_optim_loss: 626.9649\n",
      "Epoch 13/40 |ââââââ--------------| 32.5% val_auroc_score: 0.9427; val_auprc_score: 0.9172; val_best_acc_score: 0.9339; val_best_f1_score: 0.9366; train_kl_reg_loss: 0.6041; train_edge_recon_loss: 151.6399; train_cond_contrastive_loss: 189.0443; train_gene_expr_recon_loss: 279.6020; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 620.8902; train_optim_loss: 620.8902; val_kl_reg_loss: 0.6286; val_edge_recon_loss: 154.6478; val_cond_contrastive_loss: 188.4211; val_gene_expr_recon_loss: 285.1659; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 628.8633; val_optim_loss: 628.8633\n",
      "\n",
      "Reducing learning rate: metric has not improved more than 0.0 in the last 3 epochs.\n",
      "New learning rate is 0.0001.\n",
      "\n",
      "Epoch 14/40 |âââââââ-------------| 35.0% val_auroc_score: 0.9438; val_auprc_score: 0.9181; val_best_acc_score: 0.9338; val_best_f1_score: 0.9357; train_kl_reg_loss: 0.6185; train_edge_recon_loss: 150.1872; train_cond_contrastive_loss: 188.4471; train_gene_expr_recon_loss: 275.9079; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 615.1606; train_optim_loss: 615.1606; val_kl_reg_loss: 0.5950; val_edge_recon_loss: 151.9325; val_cond_contrastive_loss: 188.8595; val_gene_expr_recon_loss: 274.6805; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 616.0676; val_optim_loss: 616.0676\n",
      "Epoch 15/40 |âââââââ-------------| 37.5% val_auroc_score: 0.9477; val_auprc_score: 0.9233; val_best_acc_score: 0.9367; val_best_f1_score: 0.9385; train_kl_reg_loss: 0.6338; train_edge_recon_loss: 153.5165; train_cond_contrastive_loss: 189.0600; train_gene_expr_recon_loss: 276.4022; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 619.6124; train_optim_loss: 619.6124; val_kl_reg_loss: 0.6025; val_edge_recon_loss: 156.2640; val_cond_contrastive_loss: 189.7380; val_gene_expr_recon_loss: 271.8876; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 618.4920; val_optim_loss: 618.4920\n",
      "Epoch 16/40 |ââââââââ------------| 40.0% val_auroc_score: 0.9431; val_auprc_score: 0.9167; val_best_acc_score: 0.9343; val_best_f1_score: 0.9366; train_kl_reg_loss: 0.6477; train_edge_recon_loss: 152.1303; train_cond_contrastive_loss: 188.4768; train_gene_expr_recon_loss: 276.0168; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 617.2716; train_optim_loss: 617.2716; val_kl_reg_loss: 0.6268; val_edge_recon_loss: 152.8853; val_cond_contrastive_loss: 189.2258; val_gene_expr_recon_loss: 279.4966; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 622.2345; val_optim_loss: 622.2345\n",
      "Epoch 17/40 |ââââââââ------------| 42.5% val_auroc_score: 0.9392; val_auprc_score: 0.9139; val_best_acc_score: 0.9295; val_best_f1_score: 0.9326; train_kl_reg_loss: 0.6398; train_edge_recon_loss: 152.5211; train_cond_contrastive_loss: 188.4228; train_gene_expr_recon_loss: 275.7471; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 617.3307; train_optim_loss: 617.3307; val_kl_reg_loss: 0.6065; val_edge_recon_loss: 160.3259; val_cond_contrastive_loss: 188.7688; val_gene_expr_recon_loss: 274.7511; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 624.4523; val_optim_loss: 624.4523\n",
      "\n",
      "Reducing learning rate: metric has not improved more than 0.0 in the last 3 epochs.\n",
      "New learning rate is 1e-05.\n",
      "\n",
      "Epoch 18/40 |âââââââââ-----------| 45.0% val_auroc_score: 0.9444; val_auprc_score: 0.9195; val_best_acc_score: 0.9342; val_best_f1_score: 0.9366; train_kl_reg_loss: 0.6221; train_edge_recon_loss: 152.4888; train_cond_contrastive_loss: 188.6194; train_gene_expr_recon_loss: 274.9136; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 616.6439; train_optim_loss: 616.6439; val_kl_reg_loss: 0.5946; val_edge_recon_loss: 150.9039; val_cond_contrastive_loss: 188.5018; val_gene_expr_recon_loss: 276.3009; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 616.3011; val_optim_loss: 616.3011\n",
      "Epoch 19/40 |âââââââââ-----------| 47.5% val_auroc_score: 0.9444; val_auprc_score: 0.9202; val_best_acc_score: 0.9352; val_best_f1_score: 0.9374; train_kl_reg_loss: 0.6134; train_edge_recon_loss: 152.4572; train_cond_contrastive_loss: 188.6780; train_gene_expr_recon_loss: 274.6887; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 616.4373; train_optim_loss: 616.4373; val_kl_reg_loss: 0.5969; val_edge_recon_loss: 151.8202; val_cond_contrastive_loss: 189.1303; val_gene_expr_recon_loss: 272.7054; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 614.2528; val_optim_loss: 614.2528\n",
      "Epoch 20/40 |ââââââââââ----------| 50.0% val_auroc_score: 0.9454; val_auprc_score: 0.9194; val_best_acc_score: 0.9348; val_best_f1_score: 0.9363; train_kl_reg_loss: 0.6109; train_edge_recon_loss: 152.2102; train_cond_contrastive_loss: 188.5300; train_gene_expr_recon_loss: 276.8865; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 618.2375; train_optim_loss: 618.2375; val_kl_reg_loss: 0.5894; val_edge_recon_loss: 154.4690; val_cond_contrastive_loss: 189.8870; val_gene_expr_recon_loss: 273.2461; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 618.1916; val_optim_loss: 618.1916\n",
      "Epoch 21/40 |ââââââââââ----------| 52.5% val_auroc_score: 0.9453; val_auprc_score: 0.9219; val_best_acc_score: 0.9337; val_best_f1_score: 0.9361; train_kl_reg_loss: 0.6240; train_edge_recon_loss: 151.4071; train_cond_contrastive_loss: 189.6785; train_gene_expr_recon_loss: 274.3326; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 616.0422; train_optim_loss: 616.0422; val_kl_reg_loss: 0.4586; val_edge_recon_loss: 156.7396; val_cond_contrastive_loss: 189.5398; val_gene_expr_recon_loss: 279.8299; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 626.5678; val_optim_loss: 626.5678\n",
      "Epoch 22/40 |âââââââââââ---------| 55.0% val_auroc_score: 0.9445; val_auprc_score: 0.9207; val_best_acc_score: 0.9343; val_best_f1_score: 0.9365; train_kl_reg_loss: 0.6243; train_edge_recon_loss: 153.4448; train_cond_contrastive_loss: 189.3077; train_gene_expr_recon_loss: 276.5140; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 619.8908; train_optim_loss: 619.8908; val_kl_reg_loss: 0.4562; val_edge_recon_loss: 155.4019; val_cond_contrastive_loss: 189.0573; val_gene_expr_recon_loss: 277.4333; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 622.3487; val_optim_loss: 622.3487\n",
      "\n",
      "Reducing learning rate: metric has not improved more than 0.0 in the last 3 epochs.\n",
      "New learning rate is 1.0000000000000002e-06.\n",
      "\n",
      "Epoch 23/40 |âââââââââââ---------| 57.5% val_auroc_score: 0.9434; val_auprc_score: 0.9189; val_best_acc_score: 0.9342; val_best_f1_score: 0.9369; train_kl_reg_loss: 0.6227; train_edge_recon_loss: 152.6492; train_cond_contrastive_loss: 189.9691; train_gene_expr_recon_loss: 275.4398; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 618.6808; train_optim_loss: 618.6808; val_kl_reg_loss: 0.4565; val_edge_recon_loss: 158.0890; val_cond_contrastive_loss: 189.2034; val_gene_expr_recon_loss: 274.2974; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 622.0463; val_optim_loss: 622.0463\n",
      "Epoch 24/40 |ââââââââââââ--------| 60.0% val_auroc_score: 0.9463; val_auprc_score: 0.9225; val_best_acc_score: 0.9360; val_best_f1_score: 0.9382; train_kl_reg_loss: 0.6298; train_edge_recon_loss: 152.1302; train_cond_contrastive_loss: 189.3101; train_gene_expr_recon_loss: 276.2731; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 618.3432; train_optim_loss: 618.3432; val_kl_reg_loss: 0.4567; val_edge_recon_loss: 157.6218; val_cond_contrastive_loss: 189.7903; val_gene_expr_recon_loss: 274.9425; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 622.8113; val_optim_loss: 622.8113\n",
      "Epoch 25/40 |ââââââââââââ--------| 62.5% val_auroc_score: 0.9478; val_auprc_score: 0.9260; val_best_acc_score: 0.9369; val_best_f1_score: 0.9392; train_kl_reg_loss: 0.6234; train_edge_recon_loss: 150.8726; train_cond_contrastive_loss: 189.2399; train_gene_expr_recon_loss: 274.8187; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 615.5546; train_optim_loss: 615.5546; val_kl_reg_loss: 0.4570; val_edge_recon_loss: 156.0510; val_cond_contrastive_loss: 189.8608; val_gene_expr_recon_loss: 279.2132; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 625.5819; val_optim_loss: 625.5819\n",
      "\n",
      "Stopping early: metric has not improved more than 0.0 in the last 6 epochs.\n",
      "If the early stopping criterion is too strong, please instantiate it with different parameters in the train method.\n",
      "Model training finished after 9 min 14 sec.\n",
      "Using best model state, which was in epoch 19.\n",
      "\n",
      "--- MODEL EVALUATION ---\n",
      "Val AUROC score: 0.9502\n",
      "Val AUPRC score: 0.9246\n",
      "Val best accuracy score: 0.9378\n",
      "Val best F1 score: 0.9399\n",
      "Val MSE score: 0.7606\n",
      "Duration of model training in run 1: 0 hours, 9 minutes and 31 seconds.\n"
     ]
    }
   ],
   "source": [
    "train_autotalker_models(dataset=\"seqfish_mouse_organogenesis\",\n",
    "                        reference_batches=[f\"batch{i}\" for i in range(1,7)],\n",
    "                        cell_type_key=\"celltype_mapped_refined\",\n",
    "                        adata_new=None,\n",
    "                        n_start_run=1,\n",
    "                        n_end_run=1,\n",
    "                        n_neighbor_list=[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43617a84-1c81-473e-b275-c6b15a1b9fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_autotalker_models(dataset=\"seqfish_mouse_organogenesis\",\n",
    "                        reference_batches=[f\"batch{i}\" for i in range(1,7)],\n",
    "                        cell_type_key=\"celltype_mapped_refined\",\n",
    "                        adata_new=None,\n",
    "                        n_start_run=1,\n",
    "                        n_end_run=10,\n",
    "                        n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16, 20, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38da8b32-f839-494f-a31a-a19f661c0290",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(\"../../datasets/srt_data/gold/results/seqfish_mouse_organogenesis_autotalker_oneshot_integrated.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b6c04b-e1e7-4825-a9ec-5ee46f66ca8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d92d6d-e323-4a04-ae08-26ee096a02e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")\n",
    "from color_utils import seqfish_mouse_organogenesis_cell_type_colors\n",
    "\n",
    "adata.obsm[\"X_umap\"] = adata.obsm[\"autotalker_latent_run1_X_umap\"]\n",
    "cell_type_key = \"cell_type\"\n",
    "\n",
    "# Plot UMAP with batch annotations\n",
    "fig = sc.pl.umap(adata,\n",
    "                 color=[condition_key],\n",
    "                 legend_fontsize=12,\n",
    "                 size=240000/len(adata),\n",
    "                 return_fig=True)\n",
    "fig.set_figheight(7)\n",
    "fig.set_figwidth(7)\n",
    "plt.title(f\"One-Shot Integration: {model_name} Latent Batch Annotations\", size=20, pad=15)\n",
    "\n",
    "# Plot UMAP with cell type annotations\n",
    "fig = sc.pl.umap(adata,\n",
    "                 color=[cell_type_key],\n",
    "                 palette=seqfish_mouse_organogenesis_cell_type_colors,\n",
    "                 legend_fontsize=12,\n",
    "                 size=240000/len(adata),\n",
    "                 return_fig=True)\n",
    "fig.set_figheight(7)\n",
    "fig.set_figwidth(7)\n",
    "plt.title(f\"One-Shot Integration: {model_name} Latent Cell Type Annotations\", size=20, pad=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee102dc-b9fe-47b8-9fb0-e47cae2bb759",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autotalker.benchmarking import compute_clisis, compute_cas\n",
    "import scib\n",
    "\n",
    "spatial_knng_key = \"autotalker_spatial_knng\"\n",
    "latent_knng_key = \"autotalker_latent_run1\"\n",
    "\n",
    "# Compute metrics\n",
    "metrics_dict = {}\n",
    "\n",
    "# Spatial conservation metrics\n",
    "metrics_dict[\"cas\"] = compute_cas(\n",
    "    adata=adata,\n",
    "    cell_type_key=cell_type_key,\n",
    "    condition_key=condition_key,\n",
    "    spatial_knng_key=spatial_knng_key,\n",
    "    latent_knng_key=latent_knng_key,\n",
    "    spatial_key=spatial_key,\n",
    "    latent_key=latent_key)\n",
    "metrics_dict[\"clisis\"] = compute_clisis(\n",
    "    adata=adata,\n",
    "    cell_type_key=cell_type_key,\n",
    "    condition_key=condition_key,\n",
    "    spatial_knng_key=spatial_knng_key,\n",
    "    latent_knng_key=latent_knng_key,\n",
    "    spatial_key=spatial_key,\n",
    "    latent_key=latent_key)\n",
    "\n",
    "# Batch correction metrics\n",
    "metrics_dict[\"asw\"] = scib.me.silhouette_batch(\n",
    "    adata=adata,\n",
    "    batch_key=condition_key,\n",
    "    label_key=cell_type_key,\n",
    "    embed=latent_key)\n",
    "metrics_dict[\"ilisi\"] = scib.me.ilisi_graph(\n",
    "    adata=adata,\n",
    "    batch_key=condition_key,\n",
    "    type_=\"embed\",\n",
    "    use_rep=latent_key)\n",
    "    #type_=\"knn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b528e64-9ee4-4cc8-9936-a225130b4b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147568e6-b055-4181-900f-d47d5984bf0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
