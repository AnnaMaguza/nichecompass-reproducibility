{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "364a9ebc-3e3c-4645-9049-a34bd084c8a8",
   "metadata": {},
   "source": [
    "# Autotalker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c55227-147e-417f-b0dd-bb0b7f322930",
   "metadata": {},
   "source": [
    "- **Creator**: Sebastian Birk (<sebastian.birk@helmholtz-munich.de>).\n",
    "- **Affiliation:** Helmholtz Munich, Institute of Computational Biology (ICB), Talavera-LÃ³pez Lab\n",
    "- **Date of Creation:** 13.01.2023\n",
    "- **Date of Last Modification:** 31.03.2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa669117-f347-4666-b112-8ea6669fd9e9",
   "metadata": {},
   "source": [
    "- The Autotalker source code is available at https://github.com/Talavera-Lopez-Lab/autotalker.\n",
    "- The workflow of this notebook follows the tutorial from https://github.com/sebastianbirk/autotalker/blob/main/notebooks/autotalker_tutorial.ipynb.\n",
    "- It is recommended to use raw counts as input to Autotalker. Therefore, we use raw counts (stored in adata.layers[\"counts\"])."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7529cde5-be12-403b-a94c-07561774b86c",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faad87bd-fef5-4429-a175-d714c491ae76",
   "metadata": {},
   "source": [
    "### 1.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "149b5fec-87ba-4bd5-a327-5a37065b6223",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9305ecb-5d4b-4cdd-8e92-f7155426b7f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../../autotalker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7f93960-c759-424f-8cb2-1d8698acae2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import gc\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "\n",
    "import anndata as ad\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import scipy.sparse as sp\n",
    "import seaborn as sns\n",
    "import squidpy as sq\n",
    "import torch\n",
    "from matplotlib.pyplot import rc_context\n",
    "\n",
    "from autotalker.models import Autotalker\n",
    "from autotalker.utils import (add_gps_from_gp_dict_to_adata,\n",
    "                              extract_gp_dict_from_mebocost_es_interactions,\n",
    "                              extract_gp_dict_from_nichenet_ligand_target_mx,\n",
    "                              extract_gp_dict_from_omnipath_lr_interactions,\n",
    "                              filter_and_combine_gp_dict_gps,\n",
    "                              get_unique_genes_from_gp_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b5efa5-2052-4986-8ae5-89cfab018515",
   "metadata": {},
   "source": [
    "### 1.2 Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5c8b48a-ed5e-48b5-8c5c-c1de11493aee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"autotalker\"\n",
    "latent_key = f\"{model_name}_latent\"\n",
    "mapping_entity_key = \"reference\"\n",
    "condition_key = \"batch\"\n",
    "counts_key = \"counts\"\n",
    "spatial_key = \"spatial\"\n",
    "adj_key = \"spatial_connectivities\"\n",
    "nichenet_keep_target_genes_ratio = 0.01\n",
    "nichenet_max_n_target_genes_per_gp = 25344\n",
    "include_mebocost_gps = True\n",
    "mebocost_species = \"mouse\"\n",
    "filter_genes = False\n",
    "gp_filter_mode = \"subset\"\n",
    "combine_overlap_gps = True\n",
    "overlap_thresh_source_genes = 0.9\n",
    "overlap_thresh_target_genes = 0.9\n",
    "overlap_thresh_genes = 0.9\n",
    "active_gp_names_key = \"autotalker_active_gp_names\"\n",
    "gp_targets_mask_key = \"autotalker_gp_targets_mask\"\n",
    "gp_sources_mask_key = \"autotalker_gp_sources_mask\"\n",
    "gp_names_key = \"autotalker_gp_names\"\n",
    "active_gp_thresh_ratio = 0.03\n",
    "gene_expr_recon_dist = \"nb\"\n",
    "cond_embed_injection = [\"gene_expr_decoder\"]\n",
    "log_variational = True\n",
    "n_layers_encoder = 1\n",
    "conv_layer_encoder = \"gcnconv\"\n",
    "n_epochs = 40\n",
    "n_epochs_all_gps = 20\n",
    "lr = 0.001\n",
    "lambda_edge_recon = 1000.\n",
    "lambda_gene_expr_recon = 1.\n",
    "lambda_cond_contrastive = 2000.\n",
    "contrastive_logits_ratio = 0.1\n",
    "lambda_group_lasso = 0.\n",
    "lambda_l1_masked = 0.\n",
    "edge_batch_size = 512\n",
    "node_batch_size = 64\n",
    "leiden_resolution = 0.01 # used for Leiden clustering of latent space; 0.1\n",
    "random_seed = 0 # used for Leiden clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28adc110-0f41-4a71-9838-dc7f0687809a",
   "metadata": {},
   "source": [
    "### 1.3 Run Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "334b87ca-3387-4ba9-8567-84bc4754ff0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sc.set_figure_params(figsize=(6, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ab6b302-1c0b-4937-8624-40629ada2e46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get time of notebook execution for timestamping saved artifacts\n",
    "now = datetime.now()\n",
    "current_timestamp = now.strftime(\"%d%m%Y_%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85538952-006b-4b0b-a50c-fe7445ce22e2",
   "metadata": {},
   "source": [
    "### 1.4 Configure Paths and Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ddcc49c-ba22-4155-acd5-05b5b810e091",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "srt_data_gold_folder_path = \"../../datasets/srt_data/gold\"\n",
    "figure_folder_path = f\"../../figures\"\n",
    "gp_data_folder_path = \"../../datasets/gp_data\" # gene program data\n",
    "nichenet_ligand_target_mx_file_path = gp_data_folder_path + \"/nichenet_ligand_target_matrix.csv\"\n",
    "omnipath_lr_interactions_file_path = gp_data_folder_path + \"/omnipath_lr_interactions.csv\"\n",
    "\n",
    "# Create required directories\n",
    "os.makedirs(gp_data_folder_path, exist_ok=True)\n",
    "os.makedirs(srt_data_gold_folder_path + \"/results\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d974cd00-eafa-4432-b172-fafc4058a619",
   "metadata": {},
   "source": [
    "## 2. Autotalker Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b908c99c-de2f-4239-8420-00bd1fd58baa",
   "metadata": {},
   "source": [
    "### 2.1 Prepare Gene Program Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06c510ab-e3b1-41e7-848d-e4b9513313cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the gene program mask...\n",
      "Number of gene programs before filtering and combining: 1725.\n",
      "Number of gene programs after filtering and combining: 1575.\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing the gene program mask...\")\n",
    "# OmniPath gene programs\n",
    "omnipath_gp_dict = extract_gp_dict_from_omnipath_lr_interactions(\n",
    "    min_curation_effort=0,\n",
    "    load_from_disk=True,\n",
    "    save_to_disk=False,\n",
    "    file_path=omnipath_lr_interactions_file_path,\n",
    "    plot_gp_gene_count_distributions=False)\n",
    "\n",
    "omnipath_genes = get_unique_genes_from_gp_dict(\n",
    "    gp_dict=omnipath_gp_dict,\n",
    "    retrieved_gene_entities=[\"sources\", \"targets\"])\n",
    "\n",
    "# NicheNet gene programs\n",
    "nichenet_gp_dict = extract_gp_dict_from_nichenet_ligand_target_mx(\n",
    "    keep_target_genes_ratio=nichenet_keep_target_genes_ratio,\n",
    "    max_n_target_genes_per_gp=nichenet_max_n_target_genes_per_gp,\n",
    "    load_from_disk=True,\n",
    "    save_to_disk=False,\n",
    "    file_path=nichenet_ligand_target_mx_file_path,\n",
    "    plot_gp_gene_count_distributions=False)\n",
    "\n",
    "nichenet_source_genes = get_unique_genes_from_gp_dict(\n",
    "    gp_dict=nichenet_gp_dict,\n",
    "    retrieved_gene_entities=[\"sources\"])\n",
    "\n",
    "# Combine gene programs into one dictionary\n",
    "combined_gp_dict = dict(omnipath_gp_dict)\n",
    "combined_gp_dict.update(nichenet_gp_dict)\n",
    "\n",
    "if filter_genes:\n",
    "    # Get gene program relevant genes\n",
    "    gp_relevant_genes = list(set(omnipath_genes + nichenet_source_genes))\n",
    "\n",
    "# Mebocost gene programs\n",
    "if include_mebocost_gps:\n",
    "    mebocost_gp_dict = extract_gp_dict_from_mebocost_es_interactions(\n",
    "    dir_path=f\"{gp_data_folder_path}/metabolite_enzyme_sensor_gps/\",\n",
    "    species=mebocost_species,\n",
    "    genes_uppercase=True,\n",
    "    plot_gp_gene_count_distributions=False)\n",
    "    \n",
    "    mebocost_genes = get_unique_genes_from_gp_dict(\n",
    "        gp_dict=mebocost_gp_dict,\n",
    "        retrieved_gene_entities=[\"sources\", \"targets\"])\n",
    "\n",
    "    combined_gp_dict.update(mebocost_gp_dict)\n",
    "    \n",
    "    if filter_genes:\n",
    "        # Update gene program relevant genes\n",
    "        gp_relevant_genes = list(set(gp_relevant_genes + mebocost_genes))\n",
    "    \n",
    "# Filter and combine gene programs\n",
    "combined_new_gp_dict = filter_and_combine_gp_dict_gps(\n",
    "    gp_dict=combined_gp_dict,\n",
    "    gp_filter_mode=gp_filter_mode,\n",
    "    combine_overlap_gps=combine_overlap_gps,\n",
    "    overlap_thresh_source_genes=overlap_thresh_source_genes,\n",
    "    overlap_thresh_target_genes=overlap_thresh_target_genes,\n",
    "    overlap_thresh_genes=overlap_thresh_genes,\n",
    "    verbose=False)\n",
    "\n",
    "print(\"Number of gene programs before filtering and combining: \"\n",
    "      f\"{len(combined_gp_dict)}.\")\n",
    "print(f\"Number of gene programs after filtering and combining: \"\n",
    "      f\"{len(combined_new_gp_dict)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d712fe8e-6438-4b1d-9ec8-6b6f4408627b",
   "metadata": {},
   "source": [
    "### 2.2 Define Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ea39b0f-9c9a-459a-ba2e-c843802a8e37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_autotalker_models(dataset,\n",
    "                            reference_batches,\n",
    "                            cell_type_key,\n",
    "                            adata_new=None,\n",
    "                            n_start_run=1,\n",
    "                            n_end_run=10,\n",
    "                            n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16, 20, 20],\n",
    "                            plot_latent_umaps: bool=False):\n",
    "    # Create new adata to store results from training runs in storage-efficient way\n",
    "    if adata_new is None:  \n",
    "        adata_batch_list = []\n",
    "        if reference_batches is not None:\n",
    "            for batch in reference_batches:\n",
    "                adata_batch = ad.read_h5ad(\n",
    "                    f\"{srt_data_gold_folder_path}/{dataset}_{batch}.h5ad\")\n",
    "                adata_batch.obs[mapping_entity_key] = \"reference\"\n",
    "                adata_batch_list.append(adata_batch)\n",
    "            adata_original = ad.concat(adata_batch_list, join=\"inner\")\n",
    "        else:\n",
    "            adata_original = ad.read_h5ad(f\"{srt_data_gold_folder_path}/{dataset}.h5ad\")\n",
    "\n",
    "        adata_new = sc.AnnData(sp.csr_matrix(\n",
    "            (adata_original.shape[0], adata_original.shape[1]),\n",
    "            dtype=np.float32))\n",
    "        adata_new.var_names = adata_original.var_names\n",
    "        adata_new.obs_names = adata_original.obs_names\n",
    "        adata_new.obs[\"cell_type\"] = adata_original.obs[cell_type_key].values\n",
    "        adata_new.obsm[\"spatial\"] = adata_original.obsm[\"spatial\"]\n",
    "        adata_new.obs[condition_key] = adata_original.obs[condition_key]\n",
    "        adata_new.obs[mapping_entity_key] = adata_original.obs[mapping_entity_key] \n",
    "        del(adata_original)\n",
    "    \n",
    "    model_seeds = list(range(10))\n",
    "    for run_number, n_neighbors in zip(np.arange(n_start_run, n_end_run+1), n_neighbor_list):\n",
    "        # Load data\n",
    "        adata_batch_list = []\n",
    "        if reference_batches is not None:\n",
    "            for batch in reference_batches:\n",
    "                print(f\"Processing batch {batch}...\")\n",
    "                print(\"Loading data...\")\n",
    "                adata_batch = ad.read_h5ad(\n",
    "                    f\"{srt_data_gold_folder_path}/{dataset}_{batch}.h5ad\")\n",
    "                adata_batch.obs[mapping_entity_key] = \"reference\"\n",
    "                print(\"Computing spatial neighborhood graph...\\n\")\n",
    "                # Compute (separate) spatial neighborhood graphs\n",
    "                sq.gr.spatial_neighbors(adata_batch,\n",
    "                                        coord_type=\"generic\",\n",
    "                                        spatial_key=spatial_key,\n",
    "                                        n_neighs=n_neighbors)\n",
    "                # Make adjacency matrix symmetric\n",
    "                adata_batch.obsp[adj_key] = (\n",
    "                    adata_batch.obsp[adj_key].maximum(\n",
    "                        adata_batch.obsp[adj_key].T))\n",
    "                adata_batch_list.append(adata_batch)\n",
    "            adata = ad.concat(adata_batch_list, join=\"inner\")\n",
    "\n",
    "            # Combine spatial neighborhood graphs as disconnected components\n",
    "            batch_connectivities = []\n",
    "            len_before_batch = 0\n",
    "            for i in range(len(adata_batch_list)):\n",
    "                if i == 0: # first batch\n",
    "                    after_batch_connectivities_extension = sp.csr_matrix(\n",
    "                        (adata_batch_list[0].shape[0],\n",
    "                        (adata.shape[0] -\n",
    "                        adata_batch_list[0].shape[0])))\n",
    "                    batch_connectivities.append(sp.hstack(\n",
    "                        (adata_batch_list[0].obsp[adj_key],\n",
    "                        after_batch_connectivities_extension)))\n",
    "                elif i == (len(adata_batch_list) - 1): # last batch\n",
    "                    before_batch_connectivities_extension = sp.csr_matrix(\n",
    "                        (adata_batch_list[i].shape[0],\n",
    "                        (adata.shape[0] -\n",
    "                        adata_batch_list[i].shape[0])))\n",
    "                    batch_connectivities.append(sp.hstack(\n",
    "                        (before_batch_connectivities_extension,\n",
    "                        adata_batch_list[i].obsp[adj_key])))\n",
    "                else: # middle batches\n",
    "                    before_batch_connectivities_extension = sp.csr_matrix(\n",
    "                        (adata_batch_list[i].shape[0], len_before_batch))\n",
    "                    after_batch_connectivities_extension = sp.csr_matrix(\n",
    "                        (adata_batch_list[i].shape[0],\n",
    "                        (adata.shape[0] -\n",
    "                        adata_batch_list[i].shape[0] -\n",
    "                        len_before_batch)))\n",
    "                    batch_connectivities.append(sp.hstack(\n",
    "                        (before_batch_connectivities_extension,\n",
    "                        adata_batch_list[i].obsp[adj_key],\n",
    "                        after_batch_connectivities_extension)))\n",
    "                len_before_batch += adata_batch_list[i].shape[0]\n",
    "            connectivities = sp.vstack(batch_connectivities)\n",
    "            adata.obsp[adj_key] = connectivities\n",
    "        else:\n",
    "            adata = ad.read_h5ad(f\"{srt_data_gold_folder_path}/{dataset}.h5ad\")\n",
    "            # Compute (separate) spatial neighborhood graphs\n",
    "            sq.gr.spatial_neighbors(adata,\n",
    "                                    coord_type=\"generic\",\n",
    "                                    spatial_key=spatial_key,\n",
    "                                    n_neighs=n_neighbors)\n",
    "            # Make adjacency matrix symmetric\n",
    "            adata.obsp[adj_key] = (\n",
    "                adata.obsp[adj_key].maximum(\n",
    "                    adata.obsp[adj_key].T))\n",
    "            \n",
    "        # Filter genes if specified\n",
    "        if filter_genes:\n",
    "            print(\"\\nFiltering genes...\")\n",
    "            # Filter genes and only keep ligand, receptor, metabolitye enzyme, \n",
    "            # metabolite sensor and the 'n_hvg' highly variable genes (potential target\n",
    "            # genes of nichenet)\n",
    "            gp_dict_genes = get_unique_genes_from_gp_dict(\n",
    "                gp_dict=combined_new_gp_dict,\n",
    "                retrieved_gene_entities=[\"sources\", \"targets\"])\n",
    "            print(f\"Starting with {len(adata.var_names)} genes.\")\n",
    "            sc.pp.filter_genes(adata,\n",
    "                               min_cells=0)\n",
    "            print(f\"Keeping {len(adata.var_names)} genes after filtering \"\n",
    "                  \"genes with expression in 0 cells.\")\n",
    "\n",
    "            if counts_key is not None:\n",
    "                hvg_layer = counts_key\n",
    "                if (adata.layers[counts_key].astype(int).sum() == \n",
    "                adata.layers[counts_key].sum()): # raw counts\n",
    "                    hvg_flavor = \"seurat_v3\"\n",
    "                else:\n",
    "                    hvg_flavor = \"seurat\" # log normalized counts\n",
    "            else:\n",
    "                hvg_layer = None\n",
    "                if adata.X.astype(int).sum() == adata.X.sum(): # raw counts\n",
    "                    hvg_flavor = \"seurat_v3\"\n",
    "                else: # log normalized counts\n",
    "                    hvg_flavor = \"seurat\"\n",
    "\n",
    "            sc.pp.highly_variable_genes(\n",
    "                adata,\n",
    "                layer=hvg_layer,\n",
    "                n_top_genes=n_hvg,\n",
    "                flavor=hvg_flavor,\n",
    "                batch_key=condition_key,\n",
    "                subset=False)\n",
    "\n",
    "            adata.var[\"gp_relevant\"] = (\n",
    "                adata.var.index.str.upper().isin(gp_relevant_genes))\n",
    "            adata.var[\"keep_gene\"] = (adata.var[\"gp_relevant\"] | \n",
    "                                                adata.var[\"highly_variable\"])\n",
    "            adata = (\n",
    "                adata[:, adata.var[\"keep_gene\"] == True])\n",
    "            print(f\"Keeping {len(adata.var_names)} highly variable or gene \"\n",
    "                  \"program relevant genes.\")\n",
    "            adata = (\n",
    "                adata[:, adata.var_names[\n",
    "                    adata.var_names.str.upper().isin(\n",
    "                        gp_dict_genes)].sort_values()])\n",
    "            print(f\"Keeping {len(adata.var_names)} genes after filtering \"\n",
    "                  \"genes not in gp dict.\")\n",
    "        \n",
    "        # Add the gene program dictionary as binary masks to the adata for model \n",
    "        # training\n",
    "        add_gps_from_gp_dict_to_adata(\n",
    "            gp_dict=combined_new_gp_dict,\n",
    "            adata=adata,\n",
    "            genes_uppercase=True,\n",
    "            gp_targets_mask_key=gp_targets_mask_key,\n",
    "            gp_sources_mask_key=gp_sources_mask_key,\n",
    "            gp_names_key=gp_names_key,\n",
    "            min_genes_per_gp=1,\n",
    "            min_source_genes_per_gp=0,\n",
    "            min_target_genes_per_gp=0,\n",
    "            max_genes_per_gp=None,\n",
    "            max_source_genes_per_gp=None,\n",
    "            max_target_genes_per_gp=None,\n",
    "            filter_genes_not_in_masks=False)\n",
    "\n",
    "        # Determine dimensionality of hidden encoder\n",
    "        n_hidden_encoder = len(adata.uns[f\"{model_name}_gp_names\"])\n",
    "        n_cond_embed = int(len(adata.var_names) / 2)\n",
    "\n",
    "        start_time = time.time()\n",
    "        \n",
    "        print(\"\\nTraining model...\")\n",
    "        # Initialize model\n",
    "        model = Autotalker(adata,\n",
    "                           counts_key=counts_key,\n",
    "                           adj_key=adj_key,\n",
    "                           condition_key=condition_key,\n",
    "                           cond_embed_injection=cond_embed_injection,\n",
    "                           n_cond_embed=n_cond_embed,\n",
    "                           gp_names_key=gp_names_key,\n",
    "                           active_gp_names_key=active_gp_names_key,\n",
    "                           gp_targets_mask_key=gp_targets_mask_key,\n",
    "                           gp_sources_mask_key=gp_sources_mask_key,\n",
    "                           latent_key=latent_key,\n",
    "                           active_gp_thresh_ratio=active_gp_thresh_ratio,\n",
    "                           gene_expr_recon_dist=gene_expr_recon_dist,\n",
    "                           n_layers_encoder=n_layers_encoder,\n",
    "                           conv_layer_encoder=conv_layer_encoder,\n",
    "                           n_hidden_encoder=n_hidden_encoder,\n",
    "                           log_variational=log_variational)\n",
    "\n",
    "        # Train model\n",
    "        model.train(n_epochs=n_epochs,\n",
    "                    n_epochs_all_gps=n_epochs_all_gps,\n",
    "                    lr=lr,\n",
    "                    lambda_edge_recon=lambda_edge_recon,\n",
    "                    lambda_gene_expr_recon=lambda_gene_expr_recon,\n",
    "                    lambda_cond_contrastive=lambda_cond_contrastive,\n",
    "                    contrastive_logits_ratio=contrastive_logits_ratio,\n",
    "                    lambda_group_lasso=lambda_group_lasso,\n",
    "                    lambda_l1_masked=lambda_l1_masked,\n",
    "                    edge_batch_size=edge_batch_size,\n",
    "                    node_batch_size=node_batch_size,\n",
    "                    seed=model_seeds[run_number-1],\n",
    "                    verbose=True)        \n",
    "        \n",
    "        # Measure time for model training\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        hours, rem = divmod(elapsed_time, 3600)\n",
    "        minutes, seconds = divmod(rem, 60)\n",
    "        print(f\"Duration of model training in run {run_number}: \"\n",
    "              f\"{int(hours)} hours, {int(minutes)} minutes and {int(seconds)} seconds.\")\n",
    "        adata_new.uns[f\"{model_name}_model_training_duration_run{run_number}\"] = (\n",
    "            elapsed_time)\n",
    "\n",
    "        if plot_latent_umaps:\n",
    "            # Configure figure folder path\n",
    "            dataset_figure_folder_path = f\"{figure_folder_path}/{dataset}/sample_integration_method_benchmarking/\" \\\n",
    "                                         f\"{model_name}/{current_timestamp}\"\n",
    "            os.makedirs(dataset_figure_folder_path, exist_ok=True)\n",
    "            \n",
    "            # Use Autotalker latent space for UMAP generation\n",
    "            sc.pp.neighbors(adata,\n",
    "                            use_rep=latent_key,\n",
    "                            n_neighbors=n_neighbors)\n",
    "            sc.tl.umap(adata)\n",
    "            fig = sc.pl.umap(adata,\n",
    "                             color=[cell_type_key],\n",
    "                             title=f\"Latent Space with Cell Types: {model_name.capitalize()}\",\n",
    "                             return_fig=True)\n",
    "            fig.savefig(f\"{dataset_figure_folder_path}/latent_{model_name}\"\n",
    "                        f\"_cell_types_run{run_number}.png\",\n",
    "                        bbox_inches=\"tight\")\n",
    "\n",
    "            # Compute latent Leiden clustering\n",
    "            sc.tl.leiden(adata=adata,\n",
    "                         resolution=leiden_resolution,\n",
    "                         random_state=random_seed,\n",
    "                         key_added=f\"latent_{model_name}_leiden_{str(leiden_resolution)}\")\n",
    "\n",
    "            # Create subplot of latent Leiden cluster annotations in physical and latent space\n",
    "            fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(6, 12))\n",
    "            title = fig.suptitle(t=\"Latent and Physical Space with Leiden Clusters: \"\n",
    "                                   f\"{model_name.capitalize()}\")\n",
    "            sc.pl.umap(adata=adata,\n",
    "                       color=[f\"latent_{model_name}_leiden_{str(leiden_resolution)}\"],\n",
    "                       title=f\"Latent Space with Leiden Clusters\",\n",
    "                       ax=axs[0],\n",
    "                       show=False)\n",
    "            sq.pl.spatial_scatter(adata=adata,\n",
    "                                  color=[f\"latent_{model_name}_leiden_{str(leiden_resolution)}\"],\n",
    "                                  title=f\"Physical Space with Leiden Clusters\",\n",
    "                                  shape=None,\n",
    "                                  ax=axs[1])\n",
    "\n",
    "            # Create and position shared legend\n",
    "            handles, labels = axs[0].get_legend_handles_labels()\n",
    "            lgd = fig.legend(handles, labels, bbox_to_anchor=(1.25, 0.9185))\n",
    "            axs[0].get_legend().remove()\n",
    "            axs[1].get_legend().remove()\n",
    "\n",
    "            # Adjust, save and display plot\n",
    "            plt.subplots_adjust(wspace=0, hspace=0.2)\n",
    "            fig.savefig(f\"{dataset_figure_folder_path}/latent_physical_comparison_\"\n",
    "                        f\"{model_name}_run{run_number}.png\",\n",
    "                        bbox_extra_artists=(lgd, title),\n",
    "                        bbox_inches=\"tight\")\n",
    "            plt.show()\n",
    "\n",
    "        # Store latent representation\n",
    "        adata_new.obsm[latent_key + f\"_run{run_number}\"] = adata.obsm[latent_key]\n",
    "        \n",
    "        # Use latent representation for UMAP generation\n",
    "        sc.pp.neighbors(adata_new,\n",
    "                        use_rep=f\"{latent_key}_run{run_number}\",\n",
    "                        key_added=f\"{latent_key}_run{run_number}\")\n",
    "        sc.tl.umap(adata_new,\n",
    "                   neighbors_key=f\"{latent_key}_run{run_number}\")\n",
    "        adata_new.obsm[f\"{latent_key}_run{run_number}_X_umap\"] = adata_new.obsm[\"X_umap\"]\n",
    "        del(adata_new.obsm[\"X_umap\"])\n",
    "\n",
    "        # Store intermediate adata to disk\n",
    "        adata_new.write(f\"{srt_data_gold_folder_path}/results/{dataset}_{model_name}_oneshot_integrated.h5ad\")\n",
    "        \n",
    "        # Free memory\n",
    "        del(adata)\n",
    "        del(model)\n",
    "        gc.collect()\n",
    "\n",
    "    # Store final adata to disk\n",
    "    adata_new.write(f\"{srt_data_gold_folder_path}/results/{dataset}_{model_name}_oneshot_integrated.h5ad\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5471d723-2807-44a9-aea2-4736131b614d",
   "metadata": {},
   "source": [
    "### 2.3 Train Models on Benchmarking Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3592bdd4-a763-4323-ae3a-8087f4c77af9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch batch1...\n",
      "Loading data...\n",
      "Computing spatial neighborhood graph...\n",
      "\n",
      "Processing batch batch2...\n",
      "Loading data...\n",
      "Computing spatial neighborhood graph...\n",
      "\n",
      "Processing batch batch3...\n",
      "Loading data...\n",
      "Computing spatial neighborhood graph...\n",
      "\n",
      "Processing batch batch4...\n",
      "Loading data...\n",
      "Computing spatial neighborhood graph...\n",
      "\n",
      "Processing batch batch5...\n",
      "Loading data...\n",
      "Computing spatial neighborhood graph...\n",
      "\n",
      "Processing batch batch6...\n",
      "Loading data...\n",
      "Computing spatial neighborhood graph...\n",
      "\n",
      "\n",
      "Training model...\n",
      "--- INITIALIZING NEW NETWORK MODULE: VARIATIONAL GENE PROGRAM GRAPH AUTOENCODER ---\n",
      "LOSS -> include_edge_recon_loss: True, include_gene_expr_recon_loss: True, gene_expr_recon_dist: nb\n",
      "NODE LABEL METHOD -> one-hop-attention\n",
      "ACTIVE GP THRESHOLD RATIO -> 0.03\n",
      "LOG VARIATIONAL -> True\n",
      "CONDITIONAL EMBEDDING INJECTION -> ['gene_expr_decoder']\n",
      "GRAPH ENCODER -> n_input: 351, n_cond_embed_input: 0, n_layers: 1, n_hidden: 489, n_latent: 489, n_addon_latent: 0, conv_layer: gcnconv, n_attention_heads: 0, dropout_rate: 0.0\n",
      "COSINE SIM GRAPH DECODER -> n_cond_embed_input: 0, n_output: 489, dropout_rate: 0.0\n",
      "MASKED GENE EXPRESSION DECODER -> n_input: 489, n_cond_embed_input: 175, n_addon_input: 0, n_output: 702\n",
      "\n",
      "--- INITIALIZING TRAINER ---\n",
      "Number of training nodes: 47311\n",
      "Number of validation nodes: 5257\n",
      "Number of training edges: 109836\n",
      "Number of validation edges: 12204\n",
      "\n",
      "--- MODEL TRAINING ---\n",
      "Epoch 1/40 |--------------------| 2.5% val_auroc_score: 0.9686; val_auprc_score: 0.9652; val_best_acc_score: 0.9132; val_best_f1_score: 0.9161; train_kl_reg_loss: 3.8747; train_edge_recon_loss: 215.1350; train_cond_contrastive_loss: 705.0349; train_gene_expr_recon_loss: 340.2019; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 559.2116; train_optim_loss: 1264.2465; val_kl_reg_loss: 3.0513; val_edge_recon_loss: 164.5800; val_cond_contrastive_loss: 914.7867; val_gene_expr_recon_loss: 321.5019; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 489.1331; val_optim_loss: 1403.9198\n",
      "Epoch 2/40 |â-------------------| 5.0% val_auroc_score: 0.9667; val_auprc_score: 0.9619; val_best_acc_score: 0.9099; val_best_f1_score: 0.9136; train_kl_reg_loss: 2.5403; train_edge_recon_loss: 210.0537; train_cond_contrastive_loss: 639.1267; train_gene_expr_recon_loss: 318.7821; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 531.3761; train_optim_loss: 1170.5028; val_kl_reg_loss: 2.4495; val_edge_recon_loss: 161.4187; val_cond_contrastive_loss: 888.2693; val_gene_expr_recon_loss: 310.4595; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 474.3276; val_optim_loss: 1362.5969\n",
      "Epoch 3/40 |â-------------------| 7.5% val_auroc_score: 0.9655; val_auprc_score: 0.9608; val_best_acc_score: 0.9119; val_best_f1_score: 0.9147; train_kl_reg_loss: 2.3778; train_edge_recon_loss: 208.8994; train_cond_contrastive_loss: 638.7098; train_gene_expr_recon_loss: 310.2970; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 521.5742; train_optim_loss: 1160.2839; val_kl_reg_loss: 2.4849; val_edge_recon_loss: 166.9519; val_cond_contrastive_loss: 876.3293; val_gene_expr_recon_loss: 304.0225; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 473.4593; val_optim_loss: 1349.7886\n",
      "Epoch 4/40 |ââ------------------| 10.0% val_auroc_score: 0.9567; val_auprc_score: 0.9477; val_best_acc_score: 0.9054; val_best_f1_score: 0.9090; train_kl_reg_loss: 2.4002; train_edge_recon_loss: 208.6967; train_cond_contrastive_loss: 638.5502; train_gene_expr_recon_loss: 306.0631; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 517.1600; train_optim_loss: 1155.7102; val_kl_reg_loss: 2.3373; val_edge_recon_loss: 161.1076; val_cond_contrastive_loss: 858.0238; val_gene_expr_recon_loss: 299.3891; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 462.8340; val_optim_loss: 1320.8578\n",
      "Epoch 5/40 |ââ------------------| 12.5% val_auroc_score: 0.9559; val_auprc_score: 0.9475; val_best_acc_score: 0.9049; val_best_f1_score: 0.9076; train_kl_reg_loss: 2.3342; train_edge_recon_loss: 206.4567; train_cond_contrastive_loss: 638.1582; train_gene_expr_recon_loss: 299.7480; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 508.5389; train_optim_loss: 1146.6972; val_kl_reg_loss: 2.6696; val_edge_recon_loss: 159.7124; val_cond_contrastive_loss: 852.5333; val_gene_expr_recon_loss: 296.4357; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 458.8178; val_optim_loss: 1311.3511\n",
      "Epoch 6/40 |âââ-----------------| 15.0% val_auroc_score: 0.9582; val_auprc_score: 0.9488; val_best_acc_score: 0.9099; val_best_f1_score: 0.9118; train_kl_reg_loss: 2.3386; train_edge_recon_loss: 204.7773; train_cond_contrastive_loss: 637.7736; train_gene_expr_recon_loss: 298.2334; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 505.3493; train_optim_loss: 1143.1229; val_kl_reg_loss: 2.4545; val_edge_recon_loss: 156.7197; val_cond_contrastive_loss: 848.9893; val_gene_expr_recon_loss: 292.9618; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 452.1360; val_optim_loss: 1301.1254\n",
      "Epoch 7/40 |âââ-----------------| 17.5% val_auroc_score: 0.9612; val_auprc_score: 0.9533; val_best_acc_score: 0.9159; val_best_f1_score: 0.9182; train_kl_reg_loss: 2.4409; train_edge_recon_loss: 204.1340; train_cond_contrastive_loss: 637.1711; train_gene_expr_recon_loss: 293.7162; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 500.2911; train_optim_loss: 1137.4622; val_kl_reg_loss: 2.6882; val_edge_recon_loss: 162.5354; val_cond_contrastive_loss: 878.5523; val_gene_expr_recon_loss: 293.4962; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 458.7197; val_optim_loss: 1337.2720\n",
      "Epoch 8/40 |ââââ----------------| 20.0% val_auroc_score: 0.9704; val_auprc_score: 0.9647; val_best_acc_score: 0.9248; val_best_f1_score: 0.9267; train_kl_reg_loss: 2.4735; train_edge_recon_loss: 201.8016; train_cond_contrastive_loss: 636.7713; train_gene_expr_recon_loss: 291.5779; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 495.8529; train_optim_loss: 1132.6242; val_kl_reg_loss: 2.4782; val_edge_recon_loss: 160.8258; val_cond_contrastive_loss: 902.2862; val_gene_expr_recon_loss: 289.4311; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 452.7351; val_optim_loss: 1355.0213\n",
      "Epoch 9/40 |ââââ----------------| 22.5% val_auroc_score: 0.9748; val_auprc_score: 0.9708; val_best_acc_score: 0.9332; val_best_f1_score: 0.9339; train_kl_reg_loss: 2.5344; train_edge_recon_loss: 199.6366; train_cond_contrastive_loss: 636.4029; train_gene_expr_recon_loss: 288.5131; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 490.6840; train_optim_loss: 1127.0869; val_kl_reg_loss: 2.7522; val_edge_recon_loss: 160.4013; val_cond_contrastive_loss: 948.1243; val_gene_expr_recon_loss: 285.1050; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 448.2585; val_optim_loss: 1396.3828\n",
      "Epoch 10/40 |âââââ---------------| 25.0% val_auroc_score: 0.9769; val_auprc_score: 0.9728; val_best_acc_score: 0.9373; val_best_f1_score: 0.9381; train_kl_reg_loss: 2.5551; train_edge_recon_loss: 202.2094; train_cond_contrastive_loss: 635.7665; train_gene_expr_recon_loss: 285.9336; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 490.6981; train_optim_loss: 1126.4646; val_kl_reg_loss: 2.2327; val_edge_recon_loss: 164.6037; val_cond_contrastive_loss: 965.0076; val_gene_expr_recon_loss: 288.0123; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 454.8487; val_optim_loss: 1419.8563\n",
      "Epoch 11/40 |âââââ---------------| 27.5% val_auroc_score: 0.9784; val_auprc_score: 0.9745; val_best_acc_score: 0.9375; val_best_f1_score: 0.9383; train_kl_reg_loss: 2.5401; train_edge_recon_loss: 199.6772; train_cond_contrastive_loss: 635.2703; train_gene_expr_recon_loss: 285.9367; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 488.1540; train_optim_loss: 1123.4243; val_kl_reg_loss: 2.7966; val_edge_recon_loss: 157.0131; val_cond_contrastive_loss: 964.5736; val_gene_expr_recon_loss: 285.5264; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 445.3361; val_optim_loss: 1409.9097\n",
      "Epoch 12/40 |ââââââ--------------| 30.0% val_auroc_score: 0.9793; val_auprc_score: 0.9747; val_best_acc_score: 0.9414; val_best_f1_score: 0.9414; train_kl_reg_loss: 2.4326; train_edge_recon_loss: 201.1016; train_cond_contrastive_loss: 634.9050; train_gene_expr_recon_loss: 284.3286; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 487.8628; train_optim_loss: 1122.7678; val_kl_reg_loss: 2.4439; val_edge_recon_loss: 158.8878; val_cond_contrastive_loss: 971.0608; val_gene_expr_recon_loss: 281.2020; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 442.5337; val_optim_loss: 1413.5946\n",
      "Epoch 13/40 |ââââââ--------------| 32.5% val_auroc_score: 0.9806; val_auprc_score: 0.9765; val_best_acc_score: 0.9442; val_best_f1_score: 0.9449; train_kl_reg_loss: 2.4443; train_edge_recon_loss: 200.4267; train_cond_contrastive_loss: 634.4800; train_gene_expr_recon_loss: 281.9079; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 484.7789; train_optim_loss: 1119.2589; val_kl_reg_loss: 2.5902; val_edge_recon_loss: 162.3214; val_cond_contrastive_loss: 982.4530; val_gene_expr_recon_loss: 279.8594; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 444.7709; val_optim_loss: 1427.2240\n",
      "Epoch 14/40 |âââââââ-------------| 35.0% val_auroc_score: 0.9800; val_auprc_score: 0.9753; val_best_acc_score: 0.9403; val_best_f1_score: 0.9407; train_kl_reg_loss: 2.3351; train_edge_recon_loss: 199.3336; train_cond_contrastive_loss: 634.2162; train_gene_expr_recon_loss: 280.1630; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 481.8317; train_optim_loss: 1116.0479; val_kl_reg_loss: 2.4376; val_edge_recon_loss: 167.1002; val_cond_contrastive_loss: 976.2244; val_gene_expr_recon_loss: 281.3032; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 450.8410; val_optim_loss: 1427.0653\n",
      "Epoch 15/40 |âââââââ-------------| 37.5% val_auroc_score: 0.9803; val_auprc_score: 0.9759; val_best_acc_score: 0.9421; val_best_f1_score: 0.9428; train_kl_reg_loss: 2.4325; train_edge_recon_loss: 199.6595; train_cond_contrastive_loss: 634.0958; train_gene_expr_recon_loss: 281.2140; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 483.3060; train_optim_loss: 1117.4018; val_kl_reg_loss: 2.4299; val_edge_recon_loss: 167.2204; val_cond_contrastive_loss: 984.8864; val_gene_expr_recon_loss: 279.7922; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 449.4425; val_optim_loss: 1434.3288\n",
      "\n",
      "Reducing learning rate: metric has not improved more than 0.0 in the last 3 epochs.\n",
      "New learning rate is 0.0001.\n",
      "\n",
      "Epoch 16/40 |ââââââââ------------| 40.0% val_auroc_score: 0.9783; val_auprc_score: 0.9728; val_best_acc_score: 0.9402; val_best_f1_score: 0.9411; train_kl_reg_loss: 2.2979; train_edge_recon_loss: 198.2649; train_cond_contrastive_loss: 633.7814; train_gene_expr_recon_loss: 276.2306; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 476.7933; train_optim_loss: 1110.5748; val_kl_reg_loss: 2.4301; val_edge_recon_loss: 162.9518; val_cond_contrastive_loss: 986.9010; val_gene_expr_recon_loss: 279.3489; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 444.7307; val_optim_loss: 1431.6317\n",
      "Epoch 17/40 |ââââââââ------------| 42.5% val_auroc_score: 0.9766; val_auprc_score: 0.9698; val_best_acc_score: 0.9384; val_best_f1_score: 0.9392; train_kl_reg_loss: 2.3303; train_edge_recon_loss: 198.7291; train_cond_contrastive_loss: 633.8103; train_gene_expr_recon_loss: 276.2302; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 477.2896; train_optim_loss: 1111.0998; val_kl_reg_loss: 2.3629; val_edge_recon_loss: 165.1458; val_cond_contrastive_loss: 980.7568; val_gene_expr_recon_loss: 276.8799; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 444.3887; val_optim_loss: 1425.1455\n",
      "Epoch 18/40 |âââââââââ-----------| 45.0% val_auroc_score: 0.9791; val_auprc_score: 0.9739; val_best_acc_score: 0.9386; val_best_f1_score: 0.9395; train_kl_reg_loss: 2.2300; train_edge_recon_loss: 198.3980; train_cond_contrastive_loss: 633.7455; train_gene_expr_recon_loss: 276.0934; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 476.7213; train_optim_loss: 1110.4668; val_kl_reg_loss: 2.4468; val_edge_recon_loss: 163.1297; val_cond_contrastive_loss: 981.8349; val_gene_expr_recon_loss: 273.7763; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 439.3528; val_optim_loss: 1421.1878\n",
      "Epoch 19/40 |âââââââââ-----------| 47.5% val_auroc_score: 0.9777; val_auprc_score: 0.9729; val_best_acc_score: 0.9384; val_best_f1_score: 0.9387; train_kl_reg_loss: 2.2600; train_edge_recon_loss: 200.2832; train_cond_contrastive_loss: 633.5961; train_gene_expr_recon_loss: 276.7744; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 479.3177; train_optim_loss: 1112.9137; val_kl_reg_loss: 2.2177; val_edge_recon_loss: 160.6818; val_cond_contrastive_loss: 983.5634; val_gene_expr_recon_loss: 276.1933; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 439.0928; val_optim_loss: 1422.6561\n",
      "Epoch 20/40 |ââââââââââ----------| 50.0% val_auroc_score: 0.9788; val_auprc_score: 0.9737; val_best_acc_score: 0.9412; val_best_f1_score: 0.9414; train_kl_reg_loss: 2.1980; train_edge_recon_loss: 197.8611; train_cond_contrastive_loss: 633.5734; train_gene_expr_recon_loss: 275.5932; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 475.6523; train_optim_loss: 1109.2256; val_kl_reg_loss: 2.2898; val_edge_recon_loss: 159.0963; val_cond_contrastive_loss: 985.1339; val_gene_expr_recon_loss: 281.0390; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 442.4250; val_optim_loss: 1427.5589\n",
      "Epoch 21/40 |ââââââââââ----------| 52.5% val_auroc_score: 0.9238; val_auprc_score: 0.9288; val_best_acc_score: 0.8440; val_best_f1_score: 0.8404; train_kl_reg_loss: 0.8400; train_edge_recon_loss: 186.0664; train_cond_contrastive_loss: 747.2768; train_gene_expr_recon_loss: 279.2799; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 466.1863; train_optim_loss: 1213.4631; val_kl_reg_loss: 0.4804; val_edge_recon_loss: 189.2126; val_cond_contrastive_loss: 687.4252; val_gene_expr_recon_loss: 275.6261; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 465.3190; val_optim_loss: 1152.7442\n",
      "Epoch 22/40 |âââââââââââ---------| 55.0% val_auroc_score: 0.9045; val_auprc_score: 0.9082; val_best_acc_score: 0.8151; val_best_f1_score: 0.8202; train_kl_reg_loss: 0.3994; train_edge_recon_loss: 186.4635; train_cond_contrastive_loss: 678.7811; train_gene_expr_recon_loss: 280.4093; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 467.2723; train_optim_loss: 1146.0533; val_kl_reg_loss: 0.3589; val_edge_recon_loss: 190.6301; val_cond_contrastive_loss: 667.6963; val_gene_expr_recon_loss: 285.6716; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 476.6607; val_optim_loss: 1144.3569\n",
      "\n",
      "Reducing learning rate: metric has not improved more than 0.0 in the last 3 epochs.\n",
      "New learning rate is 1e-05.\n",
      "\n",
      "Epoch 23/40 |âââââââââââ---------| 57.5% val_auroc_score: 0.9037; val_auprc_score: 0.9070; val_best_acc_score: 0.8134; val_best_f1_score: 0.8197; train_kl_reg_loss: 0.3518; train_edge_recon_loss: 187.6453; train_cond_contrastive_loss: 669.0831; train_gene_expr_recon_loss: 280.2462; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 468.2432; train_optim_loss: 1137.3263; val_kl_reg_loss: 0.3495; val_edge_recon_loss: 189.5981; val_cond_contrastive_loss: 667.0871; val_gene_expr_recon_loss: 280.8085; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 470.7561; val_optim_loss: 1137.8432\n",
      "Epoch 24/40 |ââââââââââââ--------| 60.0% val_auroc_score: 0.9001; val_auprc_score: 0.9031; val_best_acc_score: 0.8097; val_best_f1_score: 0.8175; train_kl_reg_loss: 0.3462; train_edge_recon_loss: 186.1485; train_cond_contrastive_loss: 667.6798; train_gene_expr_recon_loss: 278.8323; train_masked_gp_l1_reg_loss: 0.0000; train_group_lasso_reg_loss: 0.0000; train_global_loss: 465.3270; train_optim_loss: 1133.0068; val_kl_reg_loss: 0.3467; val_edge_recon_loss: 190.5608; val_cond_contrastive_loss: 667.2148; val_gene_expr_recon_loss: 281.5792; val_masked_gp_l1_reg_loss: 0.0000; val_group_lasso_reg_loss: 0.0000; val_global_loss: 472.4866; val_optim_loss: 1139.7014\n"
     ]
    }
   ],
   "source": [
    "train_autotalker_models(dataset=\"seqfish_mouse_organogenesis\",\n",
    "                        reference_batches=[f\"batch{i}\" for i in range(1,7)],\n",
    "                        cell_type_key=\"celltype_mapped_refined\",\n",
    "                        adata_new=None,\n",
    "                        n_start_run=1,\n",
    "                        n_end_run=1,\n",
    "                        n_neighbor_list=[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a6b839-f7ba-41b3-a6cd-b818de304344",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_autotalker_models(dataset=\"seqfish_mouse_organogenesis\",\n",
    "                        reference_batches=[f\"batch{i}\" for i in range(1,7)],\n",
    "                        cell_type_key=\"celltype_mapped_refined\",\n",
    "                        adata_new=None,\n",
    "                        n_start_run=1,\n",
    "                        n_end_run=1,\n",
    "                        n_neighbor_list=[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43617a84-1c81-473e-b275-c6b15a1b9fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_autotalker_models(dataset=\"seqfish_mouse_organogenesis\",\n",
    "                        reference_batches=[f\"batch{i}\" for i in range(1,7)],\n",
    "                        cell_type_key=\"celltype_mapped_refined\",\n",
    "                        adata_new=None,\n",
    "                        n_start_run=1,\n",
    "                        n_end_run=10,\n",
    "                        n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16, 20, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e2d199-174f-4e6e-aa67-e50149b4c4b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(\"../../datasets/srt_data/gold/seqfish_mouse_organogenesis.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38da8b32-f839-494f-a31a-a19f661c0290",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(\"../../datasets/srt_data/gold/results/seqfish_mouse_organogenesis_autotalker_oneshot_integrated.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b6c04b-e1e7-4825-a9ec-5ee46f66ca8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d92d6d-e323-4a04-ae08-26ee096a02e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")\n",
    "from color_utils import seqfish_mouse_organogenesis_cell_type_colors\n",
    "\n",
    "adata.obsm[\"X_umap\"] = adata.obsm[\"autotalker_latent_run1_X_umap\"]\n",
    "cell_type_key = \"cell_type\"\n",
    "\n",
    "# Plot UMAP with batch annotations\n",
    "fig = sc.pl.umap(adata,\n",
    "                 color=[condition_key],\n",
    "                 legend_fontsize=12,\n",
    "                 size=240000/len(adata),\n",
    "                 return_fig=True)\n",
    "fig.set_figheight(7)\n",
    "fig.set_figwidth(7)\n",
    "plt.title(f\"One-Shot Integration: {model_name} Latent Batch Annotations\", size=20, pad=15)\n",
    "\n",
    "# Plot UMAP with cell type annotations\n",
    "fig = sc.pl.umap(adata,\n",
    "                 color=[cell_type_key],\n",
    "                 palette=seqfish_mouse_organogenesis_cell_type_colors,\n",
    "                 legend_fontsize=12,\n",
    "                 size=240000/len(adata),\n",
    "                 return_fig=True)\n",
    "fig.set_figheight(7)\n",
    "fig.set_figwidth(7)\n",
    "plt.title(f\"One-Shot Integration: {model_name} Latent Cell Type Annotations\", size=20, pad=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee102dc-b9fe-47b8-9fb0-e47cae2bb759",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autotalker.benchmarking import compute_clisis, compute_cas\n",
    "import scib\n",
    "\n",
    "spatial_knng_key = \"autotalker_spatial_knng\"\n",
    "latent_knng_key = \"autotalker_latent_run1\"\n",
    "\n",
    "# Compute metrics\n",
    "metrics_dict = {}\n",
    "\n",
    "# Spatial conservation metrics\n",
    "metrics_dict[\"cas\"] = compute_cas(\n",
    "    adata=adata,\n",
    "    cell_type_key=cell_type_key,\n",
    "    condition_key=condition_key,\n",
    "    spatial_knng_key=spatial_knng_key,\n",
    "    latent_knng_key=latent_knng_key,\n",
    "    spatial_key=spatial_key,\n",
    "    latent_key=latent_key)\n",
    "metrics_dict[\"clisis\"] = compute_clisis(\n",
    "    adata=adata,\n",
    "    cell_type_key=cell_type_key,\n",
    "    condition_key=condition_key,\n",
    "    spatial_knng_key=spatial_knng_key,\n",
    "    latent_knng_key=latent_knng_key,\n",
    "    spatial_key=spatial_key,\n",
    "    latent_key=latent_key)\n",
    "\n",
    "# Batch correction metrics\n",
    "metrics_dict[\"asw\"] = scib.me.silhouette_batch(\n",
    "    adata=adata,\n",
    "    batch_key=condition_key,\n",
    "    label_key=cell_type_key,\n",
    "    embed=latent_key)\n",
    "metrics_dict[\"ilisi\"] = scib.me.ilisi_graph(\n",
    "    adata=adata,\n",
    "    batch_key=condition_key,\n",
    "    type_=\"embed\",\n",
    "    use_rep=latent_key)\n",
    "    #type_=\"knn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b528e64-9ee4-4cc8-9936-a225130b4b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147568e6-b055-4181-900f-d47d5984bf0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
