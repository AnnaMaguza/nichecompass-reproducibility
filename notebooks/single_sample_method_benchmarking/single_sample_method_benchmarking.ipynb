{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "364a9ebc-3e3c-4645-9049-a34bd084c8a8",
   "metadata": {},
   "source": [
    "# Single Sample Method Benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c55227-147e-417f-b0dd-bb0b7f322930",
   "metadata": {},
   "source": [
    "- **Creator**: Sebastian Birk (<sebastian.birk@helmholtz-munich.de>).\n",
    "- **Affiliation:** Helmholtz Munich, Institute of Computational Biology (ICB), Talavera-LÃ³pez Lab\n",
    "- **Date of Creation:** 06.01.2023\n",
    "- **Date of Last Modification:** 08.12.2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7529cde5-be12-403b-a94c-07561774b86c",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faad87bd-fef5-4429-a175-d714c491ae76",
   "metadata": {},
   "source": [
    "### 1.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9533f18-f082-4dcc-8e93-117b9759133e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e0bf12-90ee-403e-8970-0d1ac2f47540",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../../nichecompass-reproducibility/utils\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f93960-c759-424f-8cb2-1d8698acae2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import plottable\n",
    "import scanpy as sc\n",
    "import scib_metrics\n",
    "\n",
    "from nichecompass.utils import (add_gps_from_gp_dict_to_adata,\n",
    "                                create_new_color_dict,\n",
    "                                extract_gp_dict_from_mebocost_es_interactions,\n",
    "                                extract_gp_dict_from_nichenet_lrt_interactions,\n",
    "                                extract_gp_dict_from_omnipath_lr_interactions,\n",
    "                                filter_and_combine_gp_dict_gps)\n",
    "\n",
    "from benchmarking_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b5efa5-2052-4986-8ae5-89cfab018515",
   "metadata": {},
   "source": [
    "### 1.2 Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c513d2e5-7690-432e-a63f-c44bdbe0c11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_cols_single_sample = [\n",
    "    \"cas\", \"mlami\", # global spatial conservation\n",
    "    \"clisis\", \"gcs\", # local spatial conservation\n",
    "    \"nasw\", \"cnmi\", # niche coherence\n",
    "]\n",
    "metric_col_weights_single_sample = [ # separate for each category (later multiplied with category_col_weights)\n",
    "    (1/8), (1/8), # global spatial conservation\n",
    "    (1/8), (1/8), # local spatial conservation\n",
    "    (1/4), (1/4), # niche clustering performance\n",
    "]\n",
    "metric_col_titles_single_sample = [\n",
    "    \"CAS\", # \"Cell Type Affinity Similarity\",\n",
    "    \"MLAMI\", # \"Maximum Leiden Adjusted Mutual Info\",\n",
    "    \"CLISIS\", # \"Cell Type Local Inverse Simpson's Index Similarity\",\n",
    "    \"GCS\", # \"Graph Connectivity Similarity\",\n",
    "    \"NASW\", # \"Niche Average Silhouette Width\",\n",
    "    \"CNMI\", # \"Cell Type Normalized Mutual Info\",\n",
    "]\n",
    "\n",
    "category_cols_single_sample = [\n",
    "    \"Global Spatial Conservation Score\",\n",
    "    \"Local Spatial Conservation Score\",\n",
    "    \"Niche Coherence Score\"]\n",
    "category_col_weights_single_sample = [\n",
    "    0.25,\n",
    "    0.25,\n",
    "    0.5]\n",
    "category_col_titles_single_sample = [\n",
    "    \"Global Spatial Conservation Score\",\n",
    "    \"Local Spatial Conservation Score\",\n",
    "    \"Niche Coherence Score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28adc110-0f41-4a71-9838-dc7f0687809a",
   "metadata": {},
   "source": [
    "### 1.3 Run Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334b87ca-3387-4ba9-8567-84bc4754ff0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.set_figure_params(figsize=(6, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3944b0c4-023b-4fcb-9b61-9293f08939b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore future warnings and user warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=UserWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab6b302-1c0b-4937-8624-40629ada2e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get time of notebook execution for timestamping saved artifacts\n",
    "now = datetime.now()\n",
    "current_timestamp = now.strftime(\"%d%m%Y_%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc97645-e32e-4012-9907-8a575221b2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set mlflow tracking server (run it on the defined port)\n",
    "mlflow.set_tracking_uri(\"http://localhost:8889\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85538952-006b-4b0b-a50c-fe7445ce22e2",
   "metadata": {},
   "source": [
    "### 1.4 Configure Paths and Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddcc49c-ba22-4155-acd5-05b5b810e091",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder_path = \"../../datasets/srt_data/gold\"\n",
    "artifact_folder_path = f\"../../artifacts\"\n",
    "benchmarking_folder_path = f\"{artifact_folder_path}/single_sample_method_benchmarking\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1f3798-2b4a-49ed-892c-a85d167d8ff1",
   "metadata": {},
   "source": [
    "## 2. Method Benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed96ebf-922e-42c2-a8aa-778e59737bc0",
   "metadata": {},
   "source": [
    "- Run all model notebooks in the ```notebooks/single_sample_method_benchmarking``` directory before continuing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521e3095-f73f-446f-afed-c3d825cfbc2d",
   "metadata": {},
   "source": [
    "### 2.1 Retrieve NicheCompass Runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74899e5-1274-404f-8ec6-9ffef5e51b4e",
   "metadata": {},
   "source": [
    "#### 2.1.1 seqFISH Mouse Organogenesis"
   ]
  },
  {
   "cell_type": "raw",
   "id": "59257364-5393-49c9-82cd-ed933f83e379",
   "metadata": {},
   "source": [
    "# Store NicheCompass GCN encoder results in benchmarking folder\n",
    "task = \"single_sample_method_benchmarking\"\n",
    "conv_layer_encoder = \"gcnconv\"\n",
    "datasets = [\n",
    "    \"seqfish_mouse_organogenesis_embryo2\",\n",
    "    \"seqfish_mouse_organogenesis_subsample_50pct_embryo2\",\n",
    "    \"seqfish_mouse_organogenesis_subsample_25pct_embryo2\",\n",
    "    \"seqfish_mouse_organogenesis_subsample_10pct_embryo2\",\n",
    "    \"seqfish_mouse_organogenesis_subsample_5pct_embryo2\",\n",
    "    \"seqfish_mouse_organogenesis_subsample_1pct_embryo2\",\n",
    "]\n",
    "timestamps = [\n",
    "    \"17082023_113817_1\",\n",
    "    \"17082023_121306_1\",\n",
    "    \"17082023_121306_1\",\n",
    "    \"17082023_121309_1\",\n",
    "    \"17082023_121309_1\",\n",
    "    \"17082023_121309_1\",\n",
    "]\n",
    "\n",
    "for dataset, timestamp in zip(datasets, timestamps):\n",
    "    source_path = f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_{task}/{timestamp}/{dataset}_{conv_layer_encoder}_{task}.h5ad\"\n",
    "    destination_path = f\"{artifact_folder_path}/{task}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\"\n",
    "    shutil.copy(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f51939fa-a497-490b-8705-807b007c27f6",
   "metadata": {},
   "source": [
    "# Store NicheCompass GATv2 encoder results in benchmarking folder\n",
    "task = \"single_sample_method_benchmarking\"\n",
    "conv_layer_encoder = \"gatv2conv\"\n",
    "datasets = [\n",
    "    \"seqfish_mouse_organogenesis_embryo2\",\n",
    "    \"seqfish_mouse_organogenesis_subsample_50pct_embryo2\",\n",
    "    \"seqfish_mouse_organogenesis_subsample_25pct_embryo2\",\n",
    "    \"seqfish_mouse_organogenesis_subsample_10pct_embryo2\",\n",
    "    \"seqfish_mouse_organogenesis_subsample_5pct_embryo2\",\n",
    "    \"seqfish_mouse_organogenesis_subsample_1pct_embryo2\",\n",
    "]\n",
    "timestamps = [\n",
    "    \"16082023_153513_1\",\n",
    "    \"16082023_201308_1\",\n",
    "    \"16082023_201312_1\",\n",
    "    \"16082023_201320_1\",\n",
    "    \"16082023_201434_1\",\n",
    "    \"16082023_202321_1\",\n",
    "]\n",
    "\n",
    "for dataset, timestamp in zip(datasets, timestamps):\n",
    "    source_path = f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_{task}/{timestamp}/{dataset}_{conv_layer_encoder}_{task}.h5ad\"\n",
    "    destination_path = f\"{artifact_folder_path}/{task}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\"\n",
    "    shutil.copy(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18165ea-8b86-41d4-b4dc-09a2ac617f32",
   "metadata": {},
   "source": [
    "#### 2.1.2 nanoString CosMx SMI Human Non-Small-Cell Lung Cancer (NSCLC)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "30c0d336-b7a8-43e5-9a43-ee8eaede6334",
   "metadata": {},
   "source": [
    "# Store NicheCompass GCN encoder results in benchmarking folder\n",
    "task = \"single_sample_method_benchmarking\"\n",
    "conv_layer_encoder = \"gcnconv\"\n",
    "datasets = [\n",
    "    \"nanostring_cosmx_human_nsclc_batch5\",\n",
    "    \"nanostring_cosmx_human_nsclc_subsample_50pct_batch5\",\n",
    "    \"nanostring_cosmx_human_nsclc_subsample_25pct_batch5\",\n",
    "    \"nanostring_cosmx_human_nsclc_subsample_10pct_batch5\",\n",
    "    \"nanostring_cosmx_human_nsclc_subsample_5pct_batch5\",\n",
    "    \"nanostring_cosmx_human_nsclc_subsample_1pct_batch5\",\n",
    "]\n",
    "timestamps = [\n",
    "    \"16082023_174027_1\",\n",
    "    \"16082023_174028_1\",\n",
    "    \"16082023_174332_1\",\n",
    "    \"17082023_100851_1\",\n",
    "    \"17082023_101057_1\",\n",
    "    \"16082023_154030_1\",\n",
    "]\n",
    "\n",
    "for dataset, timestamp in zip(datasets, timestamps):\n",
    "    source_path = f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_{task}/{timestamp}/{dataset}_{conv_layer_encoder}_{task}.h5ad\"\n",
    "    destination_path = f\"{artifact_folder_path}/{task}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\"\n",
    "    shutil.copy(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "50c4f747-13a4-4f5c-909f-7c143f3868e3",
   "metadata": {},
   "source": [
    "# Store NicheCompass GATv2 encoder results in benchmarking folder\n",
    "task = \"single_sample_method_benchmarking\"\n",
    "conv_layer_encoder = \"gatv2conv\"\n",
    "datasets = [\n",
    "    \"nanostring_cosmx_human_nsclc_batch5\",\n",
    "    \"nanostring_cosmx_human_nsclc_subsample_50pct_batch5\",\n",
    "    \"nanostring_cosmx_human_nsclc_subsample_25pct_batch5\",\n",
    "    \"nanostring_cosmx_human_nsclc_subsample_10pct_batch5\",\n",
    "    \"nanostring_cosmx_human_nsclc_subsample_5pct_batch5\",\n",
    "    \"nanostring_cosmx_human_nsclc_subsample_1pct_batch5\",\n",
    "]\n",
    "timestamps = [\n",
    "    \"16082023_191755_1\", # only contains 4 runs due to 2 day limit\n",
    "    \"16082023_203456_1\",\n",
    "    \"18082023_100942_1\",\n",
    "    \"17082023_100713_1\",\n",
    "    \"16082023_203744_1\",\n",
    "    \"16082023_203926_1\",\n",
    "]\n",
    "\n",
    "for dataset, timestamp in zip(datasets, timestamps):\n",
    "    source_path = f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_{task}/{timestamp}/{dataset}_{conv_layer_encoder}_{task}.h5ad\"\n",
    "    destination_path = f\"{artifact_folder_path}/{task}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\"\n",
    "    shutil.copy(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "20f6539c-785d-4962-ab8f-9cf9d1b12a03",
   "metadata": {},
   "source": [
    "# Add missing runs for 'nanostring_cosmx_human_nsclc_batch5'\n",
    "dataset = \"nanostring_cosmx_human_nsclc_batch5\"\n",
    "conv_layer_encoder = \"gatv2conv\"\n",
    "timestamp = \"18082023_185135_1\"\n",
    "\n",
    "adata1 = sc.read_h5ad(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\")\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_single_sample_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_single_sample_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [1, 2, 3, 4]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "adata1.write(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b6d996-956a-4033-862e-bc29a4d3b110",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.1.4 Vizgen MERFISH Mouse Liver"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6df22e43-77b3-40eb-8586-f58e8c33df19",
   "metadata": {},
   "source": [
    "# Store NicheCompass GCN encoder results in benchmarking folder\n",
    "task = \"single_sample_method_benchmarking\"\n",
    "conv_layer_encoder = \"gcnconv\"\n",
    "datasets = [\n",
    "    \"vizgen_merfish_mouse_liver\",\n",
    "    \"vizgen_merfish_mouse_liver_subsample_50pct\",\n",
    "    \"vizgen_merfish_mouse_liver_subsample_25pct\",\n",
    "    \"vizgen_merfish_mouse_liver_subsample_10pct\",\n",
    "    \"vizgen_merfish_mouse_liver_subsample_5pct\",\n",
    "    \"vizgen_merfish_mouse_liver_subsample_1pct\",\n",
    "]\n",
    "timestamps = [\n",
    "    \"16082023_165031_1\",\n",
    "    \"16082023_165038_1\",\n",
    "    \"16082023_165031_1\",\n",
    "    \"16082023_165031_1\",\n",
    "    \"16082023_165031_1\",\n",
    "    \"16082023_170911_1\",\n",
    "]\n",
    "\n",
    "for dataset, timestamp in zip(datasets, timestamps):\n",
    "    source_path = f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_{task}/{timestamp}/{dataset}_{conv_layer_encoder}_{task}.h5ad\"\n",
    "    destination_path = f\"{artifact_folder_path}/{task}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\"\n",
    "    shutil.copy(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "073deaa7-352a-46e9-afd1-77feb3c8574a",
   "metadata": {},
   "source": [
    "# Add missing runs for 'vizgen_merfish_mouse_liver'\n",
    "dataset = \"vizgen_merfish_mouse_liver\"\n",
    "conv_layer_encoder = \"gcnconv\"\n",
    "timestamp = \"18082023_171011_2\"\n",
    "\n",
    "adata1 = sc.read_h5ad(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\")\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_single_sample_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_single_sample_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [1, 2, 3]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "adata1.write(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "73b35896-4efc-468a-9b89-45cd83a41240",
   "metadata": {},
   "source": [
    "# Store NicheCompass GATv2 encoder results in benchmarking folder\n",
    "task = \"single_sample_method_benchmarking\"\n",
    "conv_layer_encoder = \"gatv2conv\"\n",
    "datasets = [\n",
    "    \"vizgen_merfish_mouse_liver\",\n",
    "    \"vizgen_merfish_mouse_liver_subsample_50pct\",\n",
    "    \"vizgen_merfish_mouse_liver_subsample_25pct\",\n",
    "    \"vizgen_merfish_mouse_liver_subsample_10pct\",\n",
    "    \"vizgen_merfish_mouse_liver_subsample_5pct\",\n",
    "    \"vizgen_merfish_mouse_liver_subsample_1pct\",\n",
    "]\n",
    "timestamps = [\n",
    "    \"18082023_191958_4\",\n",
    "    \"18082023_192011_1\",\n",
    "    \"18082023_211554_1\",\n",
    "    \"19082023_141238_1\",\n",
    "    \"19082023_150452_1\",\n",
    "    \"18082023_193358_1\",\n",
    "]\n",
    "\n",
    "for dataset, timestamp in zip(datasets, timestamps):\n",
    "    source_path = f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_{task}/{timestamp}/{dataset}_{conv_layer_encoder}_{task}.h5ad\"\n",
    "    destination_path = f\"{artifact_folder_path}/{task}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\"\n",
    "    shutil.copy(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4b4b4b1b-6866-422c-a16b-da2d1e788299",
   "metadata": {},
   "source": [
    "# Add missing runs for 'vizgen_merfish_mouse_liver'\n",
    "dataset = \"vizgen_merfish_mouse_liver\"\n",
    "conv_layer_encoder = \"gatv2conv\"\n",
    "timestamp = \"18082023_191942_3\"\n",
    "\n",
    "adata1 = sc.read_h5ad(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\")\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_single_sample_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_single_sample_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [3, 4]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "\n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"21082023_131701_2\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_single_sample_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_single_sample_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [5, 6]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "\n",
    "del(adata2)\n",
    "gc.collect()\n",
    "    \n",
    "timestamp = \"21082023_125245_1\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_single_sample_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_single_sample_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [7]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "\n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"21082023_125034_1\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_single_sample_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_single_sample_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [8]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "adata1.write(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "119bd143-034b-49fb-a96b-7695a508e3ac",
   "metadata": {},
   "source": [
    "# Add missing runs for 'vizgen_merfish_mouse_liver_subsample_50pct'\n",
    "dataset = \"vizgen_merfish_mouse_liver_subsample_50pct\"\n",
    "conv_layer_encoder = \"gatv2conv\"\n",
    "timestamp = \"21082023_163421_1\"\n",
    "\n",
    "adata1 = sc.read_h5ad(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\")\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_single_sample_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_single_sample_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [5]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "\n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"21082023_131701_1\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_single_sample_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_single_sample_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [6]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "    \n",
    "timestamp = \"18082023_192011_1\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_single_sample_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_single_sample_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [7, 8]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "adata1.write(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5b8cbf71-a0e3-46e4-aa63-2866aaf3ab8b",
   "metadata": {},
   "source": [
    "# Add missing runs for 'vizgen_merfish_mouse_liver_subsample_25pct'\n",
    "dataset = \"vizgen_merfish_mouse_liver_subsample_25pct\"\n",
    "conv_layer_encoder = \"gatv2conv\"\n",
    "timestamp = \"21082023_132619_1\"\n",
    "\n",
    "adata1 = sc.read_h5ad(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\")\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_single_sample_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_single_sample_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [1, 2]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "adata1.write(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68b309e-653e-479f-8932-fbe0b8d9bc3d",
   "metadata": {},
   "source": [
    "#### 2.1.5 Slide-seqV2 Mouse Hippocampus"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e5f18179-4be7-4f2c-a6b8-6e27c47b5da3",
   "metadata": {},
   "source": [
    "# Store NicheCompass GCN encoder results in benchmarking folder\n",
    "task = \"single_sample_method_benchmarking\"\n",
    "conv_layer_encoder = \"gcnconv\"\n",
    "datasets = [\n",
    "    \"slideseqv2_mouse_hippocampus\",\n",
    "    \"slideseqv2_mouse_hippocampus_subsample_50pct\",\n",
    "    \"slideseqv2_mouse_hippocampus_subsample_25pct\",\n",
    "    \"slideseqv2_mouse_hippocampus_subsample_10pct\",\n",
    "    \"slideseqv2_mouse_hippocampus_subsample_5pct\",\n",
    "    \"slideseqv2_mouse_hippocampus_subsample_1pct\",\n",
    "]\n",
    "timestamps = [\n",
    "    \"16082023_205838_1\",\n",
    "    \"16082023_210004_1\",\n",
    "    \"16082023_210005_1\",\n",
    "    \"16082023_210304_1\",\n",
    "    \"16082023_211128_1\",\n",
    "    \"16082023_211128_1\",\n",
    "]\n",
    "\n",
    "for dataset, timestamp in zip(datasets, timestamps):\n",
    "    source_path = f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_{task}/{timestamp}/{dataset}_{conv_layer_encoder}_{task}.h5ad\"\n",
    "    destination_path = f\"{artifact_folder_path}/{task}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\"\n",
    "    shutil.copy(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0da6aa9d-b5c6-4b70-a60c-af776ab35468",
   "metadata": {},
   "source": [
    "# Store NicheCompass GATv2 encoder results in benchmarking folder\n",
    "task = \"single_sample_method_benchmarking\"\n",
    "conv_layer_encoder = \"gatv2conv\"\n",
    "datasets = [\n",
    "    \"slideseqv2_mouse_hippocampus\",\n",
    "    \"slideseqv2_mouse_hippocampus_subsample_50pct\",\n",
    "    \"slideseqv2_mouse_hippocampus_subsample_25pct\",\n",
    "    \"slideseqv2_mouse_hippocampus_subsample_10pct\",\n",
    "    \"slideseqv2_mouse_hippocampus_subsample_5pct\",\n",
    "    \"slideseqv2_mouse_hippocampus_subsample_1pct\",\n",
    "]\n",
    "timestamps = [\n",
    "    \"17082023_104409_1\",\n",
    "    \"18082023_095235_1\",\n",
    "    \"17082023_110554_1\",\n",
    "    \"16082023_212040_1\",\n",
    "    \"16082023_212145_1\",\n",
    "    \"16082023_212338_1\",\n",
    "]\n",
    "\n",
    "for dataset, timestamp in zip(datasets, timestamps):\n",
    "    source_path = f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_{task}/{timestamp}/{dataset}_{conv_layer_encoder}_{task}.h5ad\"\n",
    "    destination_path = f\"{artifact_folder_path}/{task}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\"\n",
    "    shutil.copy(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ff99c4-ab55-4b85-90e9-d73eaa88f282",
   "metadata": {},
   "source": [
    "### 2.1 Create Benchmarking Metrics Plots & Run Time Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc9cd49-0005-42d9-9c9c-c9e019bcf1c2",
   "metadata": {},
   "source": [
    "#### 2.1.1 Slide-seqV2 Mouse Hippocampus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b98ef0e-8395-4780-9c57-93a67111a3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Supplementary figure: spatial clusters ###\n",
    "adata = sc.read_h5ad(f\"../../datasets/srt_data/gold/slideseqv2_mouse_hippocampus.h5ad\")\n",
    "adata.obs[\"sample\"] = \"sample1\"\n",
    "\n",
    "leiden_resolution = 0.1\n",
    "\n",
    "print(\"\\nComputing neighbor graph...\")\n",
    "# Use latent representation for UMAP generation\n",
    "sc.pp.neighbors(adata,\n",
    "                use_rep=\"spatial\",\n",
    "                key_added=\"spatial_knn\")\n",
    "\n",
    "print(\"\\nComputing UMAP embedding...\")\n",
    "sc.tl.umap(adata,\n",
    "           neighbors_key=\"spatial_knn\")\n",
    "\n",
    "print(\"\\nComputing Leiden clustering...\")\n",
    "sc.tl.leiden(adata=adata,\n",
    "             resolution=leiden_resolution,\n",
    "             key_added=f\"spatial_leiden_{leiden_resolution}\",\n",
    "             neighbors_key=\"spatial_knn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f4ef72-0b9a-4c38-bdb3-3446e671e3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_cluster_colors = create_new_color_dict(\n",
    "    adata=adata,\n",
    "    cat_key=f\"spatial_leiden_{leiden_resolution}\")\n",
    "\n",
    "plot_category_in_latent_and_physical_space(\n",
    "        adata=adata,\n",
    "        #figsize=(10, 20), for latent UMAP\n",
    "        plot_label=\"Spatial Clusters\",\n",
    "        model_label=None,\n",
    "        cat_key=f\"spatial_leiden_{leiden_resolution}\",\n",
    "        groups=None,\n",
    "        sample_key=\"sample\",\n",
    "        samples=[\"sample1\"], # =None for latent UMAP\n",
    "        cat_colors=spatial_cluster_colors,\n",
    "        size=(720000 / len(adata)),\n",
    "        spot_size=30,\n",
    "        save_fig=True,\n",
    "        file_path=f\"{benchmarking_folder_path}/spatial_clusters.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c753fe-441a-447c-98ce-20a2379bf97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Main figure: full dataset metrics ###\n",
    "datasets = [\"slideseqv2_mouse_hippocampus\"]\n",
    "models = [#\"nichecompass_gcnconv\",\n",
    "          \"nichecompass_gatv2conv\",\n",
    "          #\"staci\", # did not run\n",
    "          \"graphst\",\n",
    "          \"deeplinc\",\n",
    "          \"sagenet\",\n",
    "          #\"scvi\",\n",
    "          #\"expimap\"\n",
    "]\n",
    "\n",
    "summary_df = pd.DataFrame()\n",
    "for dataset in datasets:\n",
    "    dataset_df = pd.DataFrame()\n",
    "    for model in models:\n",
    "        try:\n",
    "            benchmark_df = pd.read_csv(f\"{benchmarking_folder_path}/{dataset}_{model}_metrics.csv\")\n",
    "            #adata = sc.read_h5ad(f\"../../artifacts/single_sample_method_benchmarking/{dataset}_{model}.h5ad\")\n",
    "            #training_durations = []\n",
    "            #for run_number in [1, 2, 3, 4, 5, 6, 7, 8]:\n",
    "            #    training_durations.append(adata.uns[f\"{model.split('_')[0]}_model_training_duration_run{run_number}\"])\n",
    "            #benchmark_df[\"run_time\"] = training_durations\n",
    "            #benchmark_df = benchmark_df[[\"dataset\", \"run_number\", \"run_time\", \"gcs\", \"mlami\", \"cas\", \"clisis\", \"nasw\", \"cnmi\", \"cari\", \"casw\", \"clisi\"]]\n",
    "            #benchmark_df.to_csv(f\"{benchmarking_folder_path}/{dataset}_{model}_metrics.csv\", index=False)\n",
    "            benchmark_df[\"model\"] = model\n",
    "            dataset_df = pd.concat([dataset_df, benchmark_df], ignore_index=True)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Did not find file {benchmarking_folder_path}/{dataset}_{model}_metrics.csv. Continuing...\")\n",
    "            missing_run_data = {\n",
    "                \"dataset\": [dataset] * 8,\n",
    "                \"model\": [model] * 8,\n",
    "                \"run_number\": [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "                \"run_time\": [np.nan] * 8\n",
    "            }\n",
    "            missing_run_df = pd.DataFrame(missing_run_data)\n",
    "            dataset_df = dataset_df.append(missing_run_df, ignore_index=True)\n",
    "            \n",
    "    # Apply min-max scaling to metric columns\n",
    "    for i in range(len(metric_cols_single_sample)):\n",
    "        min_val = dataset_df[metric_cols_single_sample[i]].min()\n",
    "        max_val = dataset_df[metric_cols_single_sample[i]].max()\n",
    "        dataset_df[metric_cols_single_sample[i] + \"_scaled\"] = ((\n",
    "            dataset_df[metric_cols_single_sample[i]] - min_val) / (max_val - min_val))\n",
    "\n",
    "    summary_df = pd.concat([summary_df, dataset_df], ignore_index=True)\n",
    "    continue\n",
    "    \n",
    "cat_0_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_single_sample[0:2]]\n",
    "cat_1_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_single_sample[2:4]]\n",
    "cat_2_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_single_sample[4:6]]\n",
    "    \n",
    "summary_df[category_cols_single_sample[0]] = np.average(summary_df[cat_0_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_single_sample[0:2],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_single_sample[1]] = np.average(summary_df[cat_1_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_single_sample[2:4],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_single_sample[2]] = np.average(summary_df[cat_2_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_single_sample[4:6],\n",
    "                                                        axis=1)\n",
    "summary_df[\"Overall Score\"] = np.average(summary_df[category_cols_single_sample[:3]],\n",
    "                                         weights=category_col_weights_single_sample[:3],\n",
    "                                         axis=1)\n",
    " \n",
    "# Reformat for plot\n",
    "summary_df.replace({\"nichecompass_gatv2conv\": \"NicheCompass\",\n",
    "                    \"nichecompass_gcnconv\": \"NicheCompass Light\",\n",
    "                    \"staci\": \"STACI\",\n",
    "                    \"deeplinc\": \"DeepLinc\",\n",
    "                    \"expimap\": \"expiMap\",\n",
    "                    \"graphst\": \"GraphST\",\n",
    "                    \"sagenet\": \"SageNet\",\n",
    "                    \"scvi\": \"scVI\"}, inplace=True)\n",
    "\n",
    "# Filter for just second run\n",
    "summary_df = summary_df[summary_df[\"run_number\"] == 2]\n",
    "\n",
    "# Plot over all loss weights combinations\n",
    "# Prepare metrics table plot\n",
    "group_cols = [\"dataset\", \"model\"]\n",
    "aggregate_df = summary_df.groupby(group_cols).mean(\"Overall Score\").sort_values(\"Overall Score\", ascending=False)[\n",
    "    metric_cols_single_sample + [\"Overall Score\"]].reset_index()\n",
    "\n",
    "unrolled_df = pd.melt(aggregate_df, \n",
    "   id_vars=group_cols,\n",
    "   value_vars=metric_cols_single_sample + [\"Overall Score\"],\n",
    "   var_name=\"score_type\", \n",
    "   value_name=\"score\")\n",
    "\n",
    "# Create spatial indicator column\n",
    "def is_spatially_aware_model(row):\n",
    "    if row[\"model\"] in [\"NicheCompass\", \"STACI\", \"DeepLinc\", \"GraphST\", \"SageNet\"]:\n",
    "        return True\n",
    "    return False\n",
    "unrolled_df[\"spatially_aware\"] = unrolled_df.apply(lambda row: is_spatially_aware_model(row), axis=1)\n",
    "unrolled_df = unrolled_df[[\"dataset\", \"spatially_aware\", \"model\", \"score_type\", \"score\"]]\n",
    "\n",
    "# Order datasets\n",
    "unrolled_df[\"dataset\"] = pd.Categorical(unrolled_df[\"dataset\"], categories=datasets, ordered=True)\n",
    "unrolled_df = unrolled_df.sort_values(by=\"dataset\")\n",
    "\n",
    "unrolled_df[\"model\"] = unrolled_df[\"model\"].replace(\"NicheCompass GATv2\", \"NicheCompass\")\n",
    "#unrolled_df[\"model\"] = unrolled_df[\"model\"].replace(\"NicheCompass GCN\", \"Mini NicheCompass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4113fc-e45b-4ffc-aae4-0ed7ba0caf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot table\n",
    "plot_simple_metrics_table(\n",
    "    df=unrolled_df,\n",
    "    model_col=\"model\",\n",
    "    model_col_width=1.6,\n",
    "    group_col=\"dataset\",\n",
    "    metric_cols=metric_cols_single_sample, # metric_cols_single_sample, category_cols_single_sample\n",
    "    metric_col_weights=metric_col_weights_single_sample, # metric_col_weights_single_sample, category_col_weights_single_sample\n",
    "    metric_col_titles=[col.replace(\" \", \"\\n\") for col in metric_col_titles_single_sample], # category_col_titles_single_sample\n",
    "    metric_col_width=0.8, # 0.8,\n",
    "    aggregate_col_width=1.2,\n",
    "    plot_width=8.5, # 32,\n",
    "    plot_height=8,\n",
    "    show=True,\n",
    "    save_dir=benchmarking_folder_path,\n",
    "    save_name=f\"benchmarking_metrics_slideseqv2_mouse_hippocampus_run2.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d029f55e-527f-403c-9bef-202a13b81e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Supplementary figure: 25% subsample metrics ###\n",
    "datasets = [\"slideseqv2_mouse_hippocampus_subsample_25pct\"]\n",
    "models = [#\"nichecompass_gcnconv\",\n",
    "          \"nichecompass_gatv2conv\",\n",
    "          \"staci\",\n",
    "          \"graphst\",\n",
    "          \"deeplinc\",\n",
    "          #\"sagenet\", # did not run\n",
    "          #\"scvi\",\n",
    "          #\"expimap\"\n",
    "]\n",
    "\n",
    "summary_df = pd.DataFrame()\n",
    "for dataset in datasets:\n",
    "    dataset_df = pd.DataFrame()\n",
    "    for model in models:\n",
    "        try:\n",
    "            benchmark_df = pd.read_csv(f\"{benchmarking_folder_path}/{dataset}_{model}_metrics.csv\")\n",
    "            #adata = sc.read_h5ad(f\"../../artifacts/single_sample_method_benchmarking/{dataset}_{model}.h5ad\")\n",
    "            #training_durations = []\n",
    "            #for run_number in [1, 2, 3, 4, 5, 6, 7, 8]:\n",
    "            #    training_durations.append(adata.uns[f\"{model.split('_')[0]}_model_training_duration_run{run_number}\"])\n",
    "            #benchmark_df[\"run_time\"] = training_durations\n",
    "            #benchmark_df = benchmark_df[[\"dataset\", \"run_number\", \"run_time\", \"gcs\", \"mlami\", \"cas\", \"clisis\", \"nasw\", \"cnmi\", \"cari\", \"casw\", \"clisi\"]]\n",
    "            #benchmark_df.to_csv(f\"{benchmarking_folder_path}/{dataset}_{model}_metrics.csv\", index=False)\n",
    "            benchmark_df[\"model\"] = model\n",
    "            dataset_df = pd.concat([dataset_df, benchmark_df], ignore_index=True)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Did not find file {benchmarking_folder_path}/{dataset}_{model}_metrics.csv. Continuing...\")\n",
    "            missing_run_data = {\n",
    "                \"dataset\": [dataset] * 8,\n",
    "                \"model\": [model] * 8,\n",
    "                \"run_number\": [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "                \"run_time\": [np.nan] * 8\n",
    "            }\n",
    "            missing_run_df = pd.DataFrame(missing_run_data)\n",
    "            dataset_df = dataset_df.append(missing_run_df, ignore_index=True)\n",
    "            \n",
    "    # Apply min-max scaling to metric columns\n",
    "    for i in range(len(metric_cols_single_sample)):\n",
    "        min_val = dataset_df[metric_cols_single_sample[i]].min()\n",
    "        max_val = dataset_df[metric_cols_single_sample[i]].max()\n",
    "        dataset_df[metric_cols_single_sample[i] + \"_scaled\"] = ((\n",
    "            dataset_df[metric_cols_single_sample[i]] - min_val) / (max_val - min_val))\n",
    "\n",
    "    summary_df = pd.concat([summary_df, dataset_df], ignore_index=True)\n",
    "    continue\n",
    "    \n",
    "cat_0_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_single_sample[0:2]]\n",
    "cat_1_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_single_sample[2:4]]\n",
    "cat_2_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_single_sample[4:6]]\n",
    "    \n",
    "summary_df[category_cols_single_sample[0]] = np.average(summary_df[cat_0_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_single_sample[0:2],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_single_sample[1]] = np.average(summary_df[cat_1_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_single_sample[2:4],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_single_sample[2]] = np.average(summary_df[cat_2_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_single_sample[4:6],\n",
    "                                                        axis=1)\n",
    "summary_df[\"Overall Score\"] = np.average(summary_df[category_cols_single_sample[:3]],\n",
    "                                         weights=category_col_weights_single_sample[:3],\n",
    "                                         axis=1)\n",
    " \n",
    "# Reformat for plot\n",
    "summary_df.replace({\"nichecompass_gatv2conv\": \"NicheCompass\",\n",
    "                    \"nichecompass_gcnconv\": \"NicheCompass Light\",\n",
    "                    \"staci\": \"STACI\",\n",
    "                    \"deeplinc\": \"DeepLinc\",\n",
    "                    \"expimap\": \"expiMap\",\n",
    "                    \"graphst\": \"GraphST\",\n",
    "                    \"sagenet\": \"SageNet\",\n",
    "                    \"scvi\": \"scVI\"}, inplace=True)\n",
    "\n",
    "# Filter for just second run\n",
    "summary_df = summary_df[summary_df[\"run_number\"] == 2]\n",
    "\n",
    "# Plot over all loss weights combinations\n",
    "# Prepare metrics table plot\n",
    "group_cols = [\"dataset\", \"model\"]\n",
    "aggregate_df = summary_df.groupby(group_cols).mean(\"Overall Score\").sort_values(\"Overall Score\", ascending=False)[\n",
    "    metric_cols_single_sample + [\"Overall Score\"]].reset_index()\n",
    "\n",
    "unrolled_df = pd.melt(aggregate_df, \n",
    "   id_vars=group_cols,\n",
    "   value_vars=metric_cols_single_sample + [\"Overall Score\"],\n",
    "   var_name=\"score_type\", \n",
    "   value_name=\"score\")\n",
    "\n",
    "# Create spatial indicator column\n",
    "def is_spatially_aware_model(row):\n",
    "    if row[\"model\"] in [\"NicheCompass\", \"STACI\", \"DeepLinc\", \"GraphST\", \"SageNet\"]:\n",
    "        return True\n",
    "    return False\n",
    "unrolled_df[\"spatially_aware\"] = unrolled_df.apply(lambda row: is_spatially_aware_model(row), axis=1)\n",
    "unrolled_df = unrolled_df[[\"dataset\", \"spatially_aware\", \"model\", \"score_type\", \"score\"]]\n",
    "\n",
    "# Order datasets\n",
    "unrolled_df[\"dataset\"] = pd.Categorical(unrolled_df[\"dataset\"], categories=datasets, ordered=True)\n",
    "unrolled_df = unrolled_df.sort_values(by=\"dataset\")\n",
    "\n",
    "unrolled_df[\"model\"] = unrolled_df[\"model\"].replace(\"NicheCompass GATv2\", \"NicheCompass\")\n",
    "#unrolled_df[\"model\"] = unrolled_df[\"model\"].replace(\"NicheCompass GCN\", \"Mini NicheCompass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff127f2c-1848-4b93-abf7-17d2d36c4cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot table\n",
    "plot_simple_metrics_table(\n",
    "    df=unrolled_df,\n",
    "    model_col=\"model\",\n",
    "    model_col_width=1.6,\n",
    "    group_col=\"dataset\",\n",
    "    metric_cols=metric_cols_single_sample, # metric_cols_single_sample, category_cols_single_sample\n",
    "    metric_col_weights=metric_col_weights_single_sample, # metric_col_weights_single_sample, category_col_weights_single_sample\n",
    "    metric_col_titles=[col.replace(\" \", \"\\n\") for col in metric_col_titles_single_sample], # category_col_titles_single_sample\n",
    "    metric_col_width=0.8, # 0.8,\n",
    "    aggregate_col_width=1.2,\n",
    "    plot_width=8.5, # 32,\n",
    "    plot_height=8,\n",
    "    show=True,\n",
    "    save_dir=benchmarking_folder_path,\n",
    "    save_name=f\"benchmarking_metrics_slideseqv2_mouse_hippocampus_subsample_25pct_run2.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2bf327-fe14-4050-99dc-75962eee3122",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Main figure: full dataset niches ###\n",
    "dataset = \"slideseqv2_mouse_hippocampus\"\n",
    "models = [\"nichecompass_gatv2conv\"]\n",
    "run_number = 2\n",
    "leiden_resolutions = [0.35]\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    adata = sc.read_h5ad(f\"../../artifacts/single_sample_method_benchmarking/{dataset}_{model}.h5ad\")\n",
    "    model = model.replace(\"_gcnconv\", \"\").replace(\"_gatv2conv\", \"\")\n",
    "    adata.obs[\"sample\"] = \"sample1\"\n",
    "    \n",
    "    print(\"\\nComputing neighbor graph...\")\n",
    "    # Use latent representation for UMAP generation\n",
    "    sc.pp.neighbors(adata,\n",
    "                    use_rep=f\"{model}_latent_run{run_number}\",\n",
    "                    key_added=f\"{model}_latent_run{run_number}\")\n",
    "\n",
    "    print(\"\\nComputing UMAP embedding...\")\n",
    "    sc.tl.umap(adata,\n",
    "               neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "        \n",
    "    print(\"\\nComputing Leiden clustering...\")\n",
    "    sc.tl.leiden(adata=adata,\n",
    "                 resolution=leiden_resolutions[i],\n",
    "                 key_added=f\"run{run_number}_leiden_{leiden_resolutions[i]}\",\n",
    "                 neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "    \n",
    "    niche_annotations = {\n",
    "        \"0\": \"Stratum\",\n",
    "        \"1\": \"Thalamus LD\",\n",
    "        \"2\": \"Cortical layer 6a\",\n",
    "        \"3\": \"Cortical layer 6b\",\n",
    "        \"4\": \"Thalamus LP\",\n",
    "        \"5\": \"Corpus callosum\",\n",
    "        \"6\": \"CA1\",\n",
    "        \"7\": \"Cortical layer 5\",\n",
    "        \"8\": \"CA2 & CA3\",\n",
    "        \"9\": \"Dentate gyrus\",\n",
    "        \"10\": \"Medial habenula (MH)\",\n",
    "        \"11\": \"Lateral habenula (LH)\",\n",
    "        \"12\": \"Cortical layer 2/3\",\n",
    "        \"13\": \"Third Ventricle (V3)\"}\n",
    "\n",
    "    adata.obs[\"niche\"] = adata.obs[\"run2_leiden_0.35\"].map(niche_annotations)\n",
    "\n",
    "    latent_cluster_colors = create_new_color_dict(\n",
    "        adata=adata,\n",
    "        cat_key=f\"run{run_number}_leiden_{leiden_resolutions[i]}\")\n",
    "    \n",
    "    niche_colors = {niche: latent_cluster_colors[cluster] for cluster, niche in niche_annotations.items()}\n",
    "    \n",
    "    plot_category_in_latent_and_physical_space(\n",
    "            adata=adata,\n",
    "            #figsize=(10, 20), for latent UMAP\n",
    "            plot_label=\"Latent Clusters\",\n",
    "            model_label={model},\n",
    "            cat_key=f\"niche\",\n",
    "            groups=None,\n",
    "            sample_key=\"sample\",\n",
    "            samples=[\"sample1\"], # =None for latent UMAP\n",
    "            cat_colors=niche_colors,\n",
    "            size=(720000 / len(adata)),\n",
    "            spot_size=30,\n",
    "            save_fig=True,\n",
    "            file_path=f\"{benchmarking_folder_path}/latent_clusters_{model}.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfea977-b4c9-4bf6-b142-9cc384f7d1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.dendrogram(adata=adata,\n",
    "                 use_rep=\"nichecompass_latent_run2\",\n",
    "                 linkage_method=\"ward\",\n",
    "                 groupby=\"niche\")\n",
    "\n",
    "fig, (ax) = plt.subplots(1, 1, figsize=(2, 5))\n",
    "sc.pl.dendrogram(\n",
    "    adata=adata,\n",
    "    groupby=\"niche\",\n",
    "    orientation=\"left\",\n",
    "    show=False,\n",
    "    save=f\"_{dataset}_nichecompass_run2\",\n",
    "    ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052eb68d-99d1-4d18-bae9-eeaf16adceb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_type_colors = create_new_color_dict(\n",
    "    adata=adata,\n",
    "    color_palette=\"cell_type_30\",\n",
    "    cat_key=\"cell_type\")\n",
    "\n",
    "tmp = pd.crosstab(adata.obs[\"niche\"], adata.obs[\"cell_type\"], normalize='index')\n",
    "tmp = tmp.reindex(adata.uns[\"dendrogram_niche\"][\"categories_ordered\"][::])\n",
    "ax = tmp.plot.barh(color=cell_type_colors, stacked=True, figsize=(6, 10)).legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "plt.yticks(fontsize=16)\n",
    "plt.xlabel(\"Cell Type Proportions\", fontsize=16)\n",
    "plt.savefig(f\"{benchmarking_folder_path}/niche_cell_type_proportions.svg\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea09eed-3b79-4364-a805-7bebb6fc0e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"slideseqv2_mouse_hippocampus\"\n",
    "models = [\"graphst\"]\n",
    "run_number = 2\n",
    "leiden_resolutions = [0.93]\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    adata = sc.read_h5ad(f\"../../artifacts/single_sample_method_benchmarking/{dataset}_{model}.h5ad\")\n",
    "    model = model.replace(\"_gcnconv\", \"\").replace(\"_gatv2conv\", \"\")\n",
    "    adata.obs[\"sample\"] = \"sample1\"\n",
    "    \n",
    "    print(\"\\nComputing neighbor graph...\")\n",
    "    # Use latent representation for UMAP generation\n",
    "    sc.pp.neighbors(adata,\n",
    "                    use_rep=f\"{model}_latent_run{run_number}\",\n",
    "                    key_added=f\"{model}_latent_run{run_number}\")\n",
    "\n",
    "    print(\"\\nComputing UMAP embedding...\")\n",
    "    sc.tl.umap(adata,\n",
    "               neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "        \n",
    "    print(\"\\nComputing Leiden clustering...\")\n",
    "    sc.tl.leiden(adata=adata,\n",
    "                 resolution=leiden_resolutions[i],\n",
    "                 key_added=f\"run{run_number}_leiden_{leiden_resolutions[i]}\",\n",
    "                 neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "\n",
    "    niche_annotations = {\n",
    "        \"0\": \"Cortical Layer 6a\",\n",
    "        \"1\": \"Stratum\",\n",
    "        \"2\": \"Thalamus LD\",\n",
    "        \"3\": \"Corpus callosum\",\n",
    "        \"4\": \"Thalamus LP\",\n",
    "        \"5\": \"Cortical Layer 6b\",\n",
    "        \"6\": \"CA1\",\n",
    "        \"7\": \"CA2 & CA3\",\n",
    "        \"8\": \"Dentate gyrus\",\n",
    "        \"9\": \"Artifact 1\",\n",
    "        \"10\": \"Third Ventricle (V3)\",\n",
    "        \"11\": \"Medial habenula (MH)\",\n",
    "        \"12\": \"Lateral habenula (LH)\",\n",
    "        \"13\": \"Artifact 2\"}\n",
    "\n",
    "    adata.obs[\"niche\"] = adata.obs[\"run2_leiden_0.93\"].map(niche_annotations)\n",
    "\n",
    "    niche_colors = {\n",
    "     'Stratum': '#8BE0A4',\n",
    "     'Thalamus LD': '#F6CF71',\n",
    "     'Cortical Layer 6b': '#B497E7',\n",
    "     'Thalamus LP': '#87C55F',\n",
    "     'Corpus callosum': '#DAB6C4',\n",
    "     'CA1': '#FE88B1',\n",
    "     'CA2 & CA3': '#DCB0F2',\n",
    "     'Dentate gyrus': '#D3B484',\n",
    "     'Medial habenula (MH)': '#F89C74',\n",
    "     'Lateral habenula (LH)': '#C9DB74',\n",
    "     'Third Ventricle (V3)': '#B3B3B3',\n",
    "     'Cortical Layer 6a': \"#66C5CC\",\n",
    "     'Artifact 1': \"#FF4D4D\",\n",
    "     'Artifact 2': \"#D2691E\"}\n",
    "    \n",
    "    plot_category_in_latent_and_physical_space(\n",
    "            adata=adata,\n",
    "            figsize=(10, 20), #for latent UMAP\n",
    "            plot_label=\"Latent Clusters\",\n",
    "            model_label={model},\n",
    "            cat_key=f\"niche\",\n",
    "            groups=None,\n",
    "            sample_key=\"sample\",\n",
    "            samples=None, #samples=None #for latent UMAP #samples=[\"sample1\"] for spatial plot\n",
    "            cat_colors=niche_colors,\n",
    "            size=(720000 / len(adata)),\n",
    "            spot_size=30,\n",
    "            save_fig=True,\n",
    "            file_path=f\"{benchmarking_folder_path}/latent_clusters_{model}.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d3e014-6b0e-4e54-a1cc-09b9d02cfa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.dendrogram(adata=adata,\n",
    "                 use_rep=\"graphst_latent_run2\",\n",
    "                 linkage_method=\"ward\",\n",
    "                 groupby=\"niche\")\n",
    "\n",
    "fig, (ax) = plt.subplots(1, 1, figsize=(2, 5))\n",
    "sc.pl.dendrogram(\n",
    "    adata=adata,\n",
    "    groupby=\"niche\",\n",
    "    orientation=\"left\",\n",
    "    show=False,\n",
    "    save=f\"_{dataset}_graphst_run2\",\n",
    "    ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16160b61-4cc2-42e7-ab7f-bfcb27dfabc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_type_colors = create_new_color_dict(\n",
    "    adata=adata,\n",
    "    color_palette=\"cell_type_30\",\n",
    "    cat_key=\"cell_type\")\n",
    "\n",
    "tmp = pd.crosstab(adata.obs[\"niche\"], adata.obs[\"cell_type\"], normalize='index')\n",
    "tmp = tmp.reindex(adata.uns[\"dendrogram_niche\"][\"categories_ordered\"][::])\n",
    "ax = tmp.plot.barh(color=cell_type_colors, stacked=True, figsize=(6, 10)).legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "plt.yticks(fontsize=16)\n",
    "plt.xlabel(\"Cell Type Proportions\", fontsize=16)\n",
    "plt.savefig(f\"{benchmarking_folder_path}/niche_cell_type_proportions_graphst.svg\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a54c3b1-901f-4f04-89b8-addafbdd8e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"slideseqv2_mouse_hippocampus\"\n",
    "models = [\"sagenet\"]\n",
    "run_number = 2\n",
    "leiden_resolutions = [0.0775]\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    adata = sc.read_h5ad(f\"../../artifacts/single_sample_method_benchmarking/{dataset}_{model}.h5ad\")\n",
    "    model = model.replace(\"_gcnconv\", \"\").replace(\"_gatv2conv\", \"\")\n",
    "    adata.obs[\"sample\"] = \"sample1\"\n",
    "    \n",
    "    print(\"\\nComputing neighbor graph...\")\n",
    "    # Use latent representation for UMAP generation\n",
    "    sc.pp.neighbors(adata,\n",
    "                    use_rep=f\"{model}_latent_run{run_number}\",\n",
    "                    key_added=f\"{model}_latent_run{run_number}\")\n",
    "\n",
    "    print(\"\\nComputing UMAP embedding...\")\n",
    "    sc.tl.umap(adata,\n",
    "               neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "        \n",
    "    print(\"\\nComputing Leiden clustering...\")\n",
    "    sc.tl.leiden(adata=adata,\n",
    "                 resolution=leiden_resolutions[i],\n",
    "                 key_added=f\"run{run_number}_leiden_{leiden_resolutions[i]}\",\n",
    "                 neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "    \n",
    "    latent_cluster_colors = {\n",
    "        \"0\": \"#9EB9F3\",\n",
    "        \"1\": \"#DAB6C4\",\n",
    "        \"2\": \"#87C55F\",\n",
    "        \"3\": \"#F6CF71\",\n",
    "        \"4\": \"#9B4DCA\",\n",
    "        \"5\": \"#276A8C\",\n",
    "        \"6\": \"#8BE0A4\",\n",
    "        \"7\": \"#DCB0F2\",\n",
    "        \"8\": \"#FF9CDA\",\n",
    "        \"9\": \"#F89C74\",\n",
    "        \"10\": \"#FE88B1\",\n",
    "        \"11\": \"#66C5CC\",\n",
    "        \"12\": \"#D3B484\",\n",
    "        \"13\": \"#B3B3B3\"}\n",
    "    \n",
    "    niche_annotations = {\n",
    "        \"0\": \"Cortical layer 5\",\n",
    "        \"1\": \"Corpus callosum\",\n",
    "        \"2\": \"Thalamus LP\",\n",
    "        \"3\": \"Thalamus LD\",\n",
    "        \"4\": \"Artifact 1\",\n",
    "        \"5\": \"Cortical layer 2/3\",\n",
    "        \"6\": \"Stratum\",\n",
    "        \"7\": \"CA2 & CA3\",\n",
    "        \"8\": \"Artifact 2\",\n",
    "        \"9\": \"Medial habenula (MH)\",\n",
    "        \"10\": \"CA1\",\n",
    "        \"11\": \"Cortical Layer 6a\",\n",
    "        \"12\": \"Dentate gyrus\",\n",
    "        \"13\": \"Third Ventricle (V3)\"}\n",
    "\n",
    "    adata.obs[\"niche\"] = adata.obs[\"run2_leiden_0.0775\"].map(niche_annotations)\n",
    "    \n",
    "    niche_colors = {\n",
    "         'Stratum': '#8BE0A4',\n",
    "         'Thalamus LD': '#F6CF71',\n",
    "         'Cortical Layer 6b': '#B497E7',\n",
    "         'Cortical layer 5': '#9EB9F3',\n",
    "         'Thalamus LP': '#87C55F',\n",
    "         'Corpus callosum': '#DAB6C4',\n",
    "         'CA1': '#FE88B1',\n",
    "         'CA2 & CA3': '#DCB0F2',\n",
    "         'Dentate gyrus': '#D3B484',\n",
    "         'Medial habenula (MH)': '#F89C74',\n",
    "         'Lateral habenula (LH)': '#C9DB74',\n",
    "         'Third Ventricle (V3)': '#B3B3B3',\n",
    "         'Cortical layer 2/3': '#276A8C',\n",
    "         'Cortical Layer 6a': \"#66C5CC\",\n",
    "         'Artifact 1': \"#FF4D4D\",\n",
    "         'Artifact 2': \"#D2691E\"}\n",
    "    \n",
    "    plot_category_in_latent_and_physical_space(\n",
    "            adata=adata,\n",
    "            figsize=(10, 20), #for latent UMAP\n",
    "            plot_label=\"Latent Clusters\",\n",
    "            model_label={model},\n",
    "            cat_key=\"niche\",\n",
    "            groups=None,\n",
    "            sample_key=\"sample\",\n",
    "            samples=None, #samples=None #for latent UMAP #samples=[\"sample1\"] for spatial plot\n",
    "            cat_colors=niche_colors,\n",
    "            size=(720000 / len(adata)),\n",
    "            spot_size=30,\n",
    "            save_fig=True,\n",
    "            file_path=f\"{benchmarking_folder_path}/latent_clusters_{model}.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef41771b-3684-4193-b169-851d2f5da57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.dendrogram(adata=adata,\n",
    "                 use_rep=\"sagenet_latent_run2\",\n",
    "                 linkage_method=\"ward\",\n",
    "                 groupby=\"niche\")\n",
    "\n",
    "fig, (ax) = plt.subplots(1, 1, figsize=(2, 5))\n",
    "sc.pl.dendrogram(\n",
    "    adata=adata,\n",
    "    groupby=\"niche\",\n",
    "    orientation=\"left\",\n",
    "    show=False,\n",
    "    save=f\"_{dataset}_sagenet_run2\",\n",
    "    ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a62b19-a86f-452a-a4ba-d94eef3e784b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_type_colors = create_new_color_dict(\n",
    "    adata=adata,\n",
    "    color_palette=\"cell_type_30\",\n",
    "    cat_key=\"cell_type\")\n",
    "\n",
    "tmp = pd.crosstab(adata.obs[\"niche\"], adata.obs[\"cell_type\"], normalize='index')\n",
    "tmp = tmp.reindex(adata.uns[\"dendrogram_niche\"][\"categories_ordered\"][::])\n",
    "ax = tmp.plot.barh(color=cell_type_colors, stacked=True, figsize=(6, 10)).legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "plt.yticks(fontsize=16)\n",
    "plt.xlabel(\"Cell Type Proportions\", fontsize=16)\n",
    "plt.savefig(f\"{benchmarking_folder_path}/niche_cell_type_proportions_sagenet.svg\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc33d7d-e9dd-40b1-80e0-453071ffd25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"slideseqv2_mouse_hippocampus\"\n",
    "models = [\"deeplinc\"]\n",
    "run_number = 2\n",
    "leiden_resolutions = [1.1]\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    adata = sc.read_h5ad(f\"../../artifacts/single_sample_method_benchmarking/{dataset}_{model}.h5ad\")\n",
    "    model = model.replace(\"_gcnconv\", \"\").replace(\"_gatv2conv\", \"\")\n",
    "    adata.obs[\"sample\"] = \"sample1\"\n",
    "    \n",
    "    print(\"\\nComputing neighbor graph...\")\n",
    "    # Use latent representation for UMAP generation\n",
    "    sc.pp.neighbors(adata,\n",
    "                    use_rep=f\"{model}_latent_run{run_number}\",\n",
    "                    key_added=f\"{model}_latent_run{run_number}\")\n",
    "\n",
    "    print(\"\\nComputing UMAP embedding...\")\n",
    "    sc.tl.umap(adata,\n",
    "               neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "        \n",
    "    print(\"\\nComputing Leiden clustering...\")\n",
    "    sc.tl.leiden(adata=adata,\n",
    "                 resolution=leiden_resolutions[i],\n",
    "                 key_added=f\"run{run_number}_leiden_{leiden_resolutions[i]}\",\n",
    "                 neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "    \n",
    "    latent_cluster_colors = {\n",
    "        \"0\": \"#66C5CC\",\n",
    "        \"1\": \"#F6CF71\",\n",
    "        \"2\": \"#B497E7\",\n",
    "        \"3\": \"#87C55F\",\n",
    "        \"4\": \"#DAB6C4\",\n",
    "        \"5\": \"#FE88B1\",\n",
    "        \"6\": \"#8BE0A4\",\n",
    "        \"7\": \"#D3B484\",\n",
    "        \"8\": \"#F89C74\",\n",
    "        \"9\": \"#DCB0F2\",\n",
    "        \"10\": \"#276A8C\",\n",
    "        \"11\": \"#FF4D4D\",\n",
    "        \"12\": \"#B3B3B3\",\n",
    "        \"13\": \"#FF00FF\"}\n",
    "    \n",
    "    niche_annotations = {\n",
    "        \"0\": \"Cortical Layer 6a\",\n",
    "        \"1\": \"Thalamus LD\",\n",
    "        \"2\": \"Cortical Layer 6b\",\n",
    "        \"3\": \"Thalamus LP\",\n",
    "        \"4\": \"Corpus callosum\",\n",
    "        \"5\": \"CA1\",\n",
    "        \"6\": \"Stratum\",\n",
    "        \"7\": \"Dentate gyrus\",\n",
    "        \"8\": \"Medial habenula (MH)\",\n",
    "        \"9\": \"CA2 & CA3\",\n",
    "        \"10\": \"Cortical layer 2/3\",\n",
    "        \"11\": \"Artifact 1\",\n",
    "        \"12\": \"Third Ventricle (V3)\",\n",
    "        \"13\": \"Fasciola cinerea\"}\n",
    "\n",
    "    adata.obs[\"niche\"] = adata.obs[\"run2_leiden_1.1\"].map(niche_annotations)\n",
    "    \n",
    "    niche_colors = {\n",
    "         'Stratum': '#8BE0A4',\n",
    "         'Thalamus LD': '#F6CF71',\n",
    "         'Cortical Layer 6b': '#B497E7',\n",
    "         'Cortical layer 5': '#9EB9F3',\n",
    "         'Thalamus LP': '#87C55F',\n",
    "         'Corpus callosum': '#DAB6C4',\n",
    "         'CA1': '#FE88B1',\n",
    "         'CA2 & CA3': '#DCB0F2',\n",
    "         'Dentate gyrus': '#D3B484',\n",
    "         'Medial habenula (MH)': '#F89C74',\n",
    "         'Lateral habenula (LH)': '#C9DB74',\n",
    "         'Third Ventricle (V3)': '#B3B3B3',\n",
    "         'Cortical layer 2/3': '#276A8C',\n",
    "         'Cortical Layer 6a': \"#66C5CC\",\n",
    "         'Artifact 1': \"#FF4D4D\",\n",
    "         'Fasciola cinerea': \"#FF00FF\"}\n",
    "    \n",
    "    plot_category_in_latent_and_physical_space(\n",
    "            adata=adata,\n",
    "            figsize=(10, 20), #for latent UMAP\n",
    "            plot_label=\"Latent Clusters\",\n",
    "            model_label={model},\n",
    "            cat_key=\"niche\",\n",
    "            groups=None,\n",
    "            sample_key=\"sample\",\n",
    "            samples=None, #samples=None #for latent UMAP #samples=[\"sample1\"] for spatial plot\n",
    "            cat_colors=niche_colors,\n",
    "            size=(720000 / len(adata)),\n",
    "            spot_size=30,\n",
    "            save_fig=True,\n",
    "            file_path=f\"{benchmarking_folder_path}/latent_clusters_{model}.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e8aa8e-34bb-4535-8727-6ac5ed7404fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.dendrogram(adata=adata,\n",
    "                 use_rep=\"deeplinc_latent_run2\",\n",
    "                 linkage_method=\"ward\",\n",
    "                 groupby=\"niche\")\n",
    "\n",
    "fig, (ax) = plt.subplots(1, 1, figsize=(2, 5))\n",
    "sc.pl.dendrogram(\n",
    "    adata=adata,\n",
    "    groupby=\"niche\",\n",
    "    orientation=\"left\",\n",
    "    show=False,\n",
    "    save=f\"_{dataset}_deeplinc_run2\",\n",
    "    ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af69299a-9546-4236-a91e-bbd9d7b73e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_type_colors = create_new_color_dict(\n",
    "    adata=adata,\n",
    "    color_palette=\"cell_type_30\",\n",
    "    cat_key=\"cell_type\")\n",
    "\n",
    "tmp = pd.crosstab(adata.obs[\"niche\"], adata.obs[\"cell_type\"], normalize='index')\n",
    "tmp = tmp.reindex(adata.uns[\"dendrogram_niche\"][\"categories_ordered\"][::])\n",
    "ax = tmp.plot.barh(color=cell_type_colors, stacked=True, figsize=(6, 10)).legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "plt.yticks(fontsize=16)\n",
    "plt.xlabel(\"Cell Type Proportions\", fontsize=16)\n",
    "plt.savefig(f\"{benchmarking_folder_path}/niche_cell_type_proportions_deeplinc.svg\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5752ea02-a188-437c-99e9-2c88c670a60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_category_in_latent_and_physical_space(\n",
    "        adata=adata,\n",
    "        #figsize=(10, 20), for latent UMAP\n",
    "        plot_label=\"Cell Types\",\n",
    "        model_label=None,\n",
    "        cat_key=f\"cell_type\",\n",
    "        groups=None,\n",
    "        sample_key=\"sample\",\n",
    "        samples=[\"sample1\"], # =None for latent UMAP\n",
    "        cat_colors=cell_type_colors,\n",
    "        size=(720000 / len(adata)),\n",
    "        spot_size=30,\n",
    "        save_fig=True,\n",
    "        file_path=f\"{benchmarking_folder_path}/cell_types.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e206d09-de9a-46d5-8f4b-54daafb9902e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"slideseqv2_mouse_hippocampus\"\n",
    "models = [\"scvi\"]\n",
    "run_number = 2\n",
    "leiden_resolutions = [0.875]\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    adata = sc.read_h5ad(f\"../../artifacts/single_sample_method_benchmarking/{dataset}_{model}.h5ad\")\n",
    "    model = model.replace(\"_gcnconv\", \"\").replace(\"_gatv2conv\", \"\")\n",
    "    adata.obs[\"sample\"] = \"sample1\"\n",
    "    \n",
    "    print(\"\\nComputing neighbor graph...\")\n",
    "    # Use latent representation for UMAP generation\n",
    "    sc.pp.neighbors(adata,\n",
    "                    use_rep=f\"{model}_latent_run{run_number}\",\n",
    "                    key_added=f\"{model}_latent_run{run_number}\")\n",
    "\n",
    "    print(\"\\nComputing UMAP embedding...\")\n",
    "    sc.tl.umap(adata,\n",
    "               neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "        \n",
    "    print(\"\\nComputing Leiden clustering...\")\n",
    "    sc.tl.leiden(adata=adata,\n",
    "                 resolution=leiden_resolutions[i],\n",
    "                 key_added=f\"run{run_number}_leiden_{leiden_resolutions[i]}\",\n",
    "                 neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "    \n",
    "    latent_cluster_colors = {\n",
    "        \"0\": \"#66C5CC\",\n",
    "        \"1\": \"#8BE0A4\",\n",
    "        \"2\": \"#DAB6C4\",\n",
    "        \"3\": \"#F6CF71\",\n",
    "        \"4\": \"#87C55F\",\n",
    "        \"5\": \"#9D88A2\",\n",
    "        \"6\": \"#F89C74\",\n",
    "        \"7\": \"#BA55D3\",\n",
    "        \"8\": \"#B3B3B3\",\n",
    "        \"9\": \"#D3B484\",\n",
    "        \"10\": \"#8A2BE2\",\n",
    "        \"11\": \"#FE88B1\",\n",
    "        \"12\": \"#DCB0F2\",\n",
    "        \"13\": \"#276A8C\"}\n",
    "    \n",
    "    plot_category_in_latent_and_physical_space(\n",
    "            adata=adata,\n",
    "            plot_label=\"Latent Clusters\",\n",
    "            model_label={model},\n",
    "            cat_key=f\"run{run_number}_leiden_{leiden_resolutions[i]}\",\n",
    "            groups=None,\n",
    "            sample_key=\"sample\",\n",
    "            samples=[\"sample1\"],\n",
    "            cat_colors=latent_cluster_colors,\n",
    "            size=(720000 / len(adata)),\n",
    "            spot_size=30,\n",
    "            save_fig=True,\n",
    "            file_path=f\"{benchmarking_folder_path}/latent_clusters_{model}.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a49489-460b-4524-9d0c-7e22d5d74105",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"slideseqv2_mouse_hippocampus\"\n",
    "models = [\"expimap\"]\n",
    "run_number = 2\n",
    "leiden_resolutions = [1.5]\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    adata = sc.read_h5ad(f\"../../artifacts/single_sample_method_benchmarking/{dataset}_{model}.h5ad\")\n",
    "    model = model.replace(\"_gcnconv\", \"\").replace(\"_gatv2conv\", \"\")\n",
    "    adata.obs[\"sample\"] = \"sample1\"\n",
    "    \n",
    "    print(\"\\nComputing neighbor graph...\")\n",
    "    # Use latent representation for UMAP generation\n",
    "    sc.pp.neighbors(adata,\n",
    "                    use_rep=f\"{model}_latent_run{run_number}\",\n",
    "                    key_added=f\"{model}_latent_run{run_number}\")\n",
    "\n",
    "    print(\"\\nComputing UMAP embedding...\")\n",
    "    sc.tl.umap(adata,\n",
    "               neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "        \n",
    "    print(\"\\nComputing Leiden clustering...\")\n",
    "    sc.tl.leiden(adata=adata,\n",
    "                 resolution=leiden_resolutions[i],\n",
    "                 key_added=f\"run{run_number}_leiden_{leiden_resolutions[i]}\",\n",
    "                 neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "    \n",
    "    latent_cluster_colors = {\n",
    "        \"0\": \"#66C5CC\",\n",
    "        \"1\": \"#F6CF71\",\n",
    "        \"2\": \"#DAB6C4\",\n",
    "        \"3\": \"#8BE0A4\",\n",
    "        \"4\": \"#9D88A2\",\n",
    "        \"5\": \"#FE88B1\",\n",
    "        \"6\": \"#F89C74\",\n",
    "        \"7\": \"#D3B484\",\n",
    "        \"8\": \"#8A2BE2\",\n",
    "        \"9\": \"#FF00FF\",\n",
    "        \"10\": \"#48D1CC\",\n",
    "        \"11\": \"#B3B3B3\",\n",
    "        \"12\": \"#B497E7\",\n",
    "        \"13\": \"#9B4DCA\"}\n",
    "    \n",
    "    plot_category_in_latent_and_physical_space(\n",
    "            adata=adata,\n",
    "            plot_label=\"Latent Clusters\",\n",
    "            model_label={model},\n",
    "            cat_key=f\"run{run_number}_leiden_{leiden_resolutions[i]}\",\n",
    "            groups=None,\n",
    "            sample_key=\"sample\",\n",
    "            samples=[\"sample1\"],\n",
    "            cat_colors=latent_cluster_colors,\n",
    "            size=(720000 / len(adata)),\n",
    "            spot_size=30,\n",
    "            save_fig=True,\n",
    "            file_path=f\"{benchmarking_folder_path}/latent_clusters_{model}.svg\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "017430de-5863-4af7-a74d-cc9f4c8c4907",
   "metadata": {},
   "source": [
    "dataset = \"slideseqv2_mouse_hippocampus\"\n",
    "models = [\"nichecompass_gcnconv\"]\n",
    "run_number = 2\n",
    "leiden_resolutions = [0.35]\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    adata = sc.read_h5ad(f\"../../artifacts/single_sample_method_benchmarking/{dataset}_{model}.h5ad\")\n",
    "    model = model.replace(\"_gcnconv\", \"\").replace(\"_gatv2conv\", \"\")\n",
    "    adata.obs[\"sample\"] = \"sample1\"\n",
    "    \n",
    "    print(\"\\nComputing neighbor graph...\")\n",
    "    # Use latent representation for UMAP generation\n",
    "    sc.pp.neighbors(adata,\n",
    "                    use_rep=f\"{model}_latent_run{run_number}\",\n",
    "                    key_added=f\"{model}_latent_run{run_number}\")\n",
    "\n",
    "    print(\"\\nComputing UMAP embedding...\")\n",
    "    sc.tl.umap(adata,\n",
    "               neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "        \n",
    "    print(\"\\nComputing Leiden clustering...\")\n",
    "    sc.tl.leiden(adata=adata,\n",
    "                 resolution=leiden_resolutions[i],\n",
    "                 key_added=f\"run{run_number}_leiden_{leiden_resolutions[i]}\",\n",
    "                 neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "    \n",
    "    latent_cluster_colors = {\n",
    "        \"0\": \"#66C5CC\",\n",
    "        \"1\": \"#F6CF71\",\n",
    "        \"2\": \"#DAB6C4\",\n",
    "        \"3\": \"#8BE0A4\",\n",
    "        \"4\": \"#9D88A2\",\n",
    "        \"5\": \"#FE88B1\",\n",
    "        \"6\": \"#F89C74\",\n",
    "        \"7\": \"#D3B484\",\n",
    "        \"8\": \"#8A2BE2\",\n",
    "        \"9\": \"#FF00FF\",\n",
    "        \"10\": \"#48D1CC\",\n",
    "        \"11\": \"#B3B3B3\",\n",
    "        \"12\": \"#B497E7\",\n",
    "        \"13\": \"#9B4DCA\"}\n",
    "\n",
    "    plot_category_in_latent_and_physical_space(\n",
    "            adata=adata,\n",
    "            plot_label=\"Latent Clusters\",\n",
    "            model_label={model},\n",
    "            cat_key=f\"run{run_number}_leiden_{leiden_resolutions[i]}\",\n",
    "            groups=None,\n",
    "            sample_key=\"sample\",\n",
    "            samples=[\"sample1\"],\n",
    "            cat_colors=latent_cluster_colors,\n",
    "            size=(720000 / len(adata)),\n",
    "            spot_size=30,\n",
    "            save_fig=True,\n",
    "            file_path=f\"{benchmarking_folder_path}/latent_clusters_{model}.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5785c046-b8bf-4f55-b61b-06c2b43c2990",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Supplementary figure: 25% subsample niches ###\n",
    "dataset = \"slideseqv2_mouse_hippocampus_subsample_25pct\"\n",
    "models = [\"nichecompass_gatv2conv\"]\n",
    "\n",
    "run_number = 2\n",
    "leiden_resolutions = [0.1]\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    adata = sc.read_h5ad(f\"../../artifacts/single_sample_method_benchmarking/{dataset}_{model}.h5ad\")\n",
    "    model = model.replace(\"_gcnconv\", \"\").replace(\"_gatv2conv\", \"\")\n",
    "    adata.obs[\"sample\"] = \"sample1\"\n",
    "    \n",
    "    print(\"\\nComputing neighbor graph...\")\n",
    "    # Use latent representation for UMAP generation\n",
    "    sc.pp.neighbors(adata,\n",
    "                    use_rep=f\"{model}_latent_run{run_number}\",\n",
    "                    key_added=f\"{model}_latent_run{run_number}\")\n",
    "\n",
    "    print(\"\\nComputing UMAP embedding...\")\n",
    "    sc.tl.umap(adata,\n",
    "               neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "        \n",
    "    print(\"\\nComputing Leiden clustering...\")\n",
    "    sc.tl.leiden(adata=adata,\n",
    "                 resolution=leiden_resolutions[i],\n",
    "                 key_added=f\"run{run_number}_leiden_{leiden_resolutions[i]}\",\n",
    "                 neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "    \n",
    "    latent_cluster_colors = {\n",
    "        \"0\": \"#8BE0A4\",\n",
    "        \"1\": \"#DCB0F2\",\n",
    "        \"2\": \"#66C5CC\",\n",
    "        \"3\": \"#F6CF71\",\n",
    "        \"4\": \"#DAB6C4\",\n",
    "        \"5\": \"#D3B484\",\n",
    "        \"6\": \"#FE88B1\"}\n",
    "    \n",
    "    plot_category_in_latent_and_physical_space(\n",
    "            adata=adata,\n",
    "            figsize=(10,20),\n",
    "            plot_label=\"Latent Clusters\",\n",
    "            model_label={model},\n",
    "            cat_key=f\"run{run_number}_leiden_{leiden_resolutions[i]}\",\n",
    "            groups=None,\n",
    "            sample_key=\"sample\",\n",
    "            samples=[\"sample1\"], #samples=None #for latent UMAP #samples=[\"sample1\"] for spatial plot\n",
    "            cat_colors=latent_cluster_colors,\n",
    "            size=(720000 / len(adata)),\n",
    "            spot_size=30,\n",
    "            save_fig=True,\n",
    "            file_path=f\"{benchmarking_folder_path}/latent_clusters_{model}.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120325bb-f8de-478d-89d0-2a6d6da3e9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"slideseqv2_mouse_hippocampus_subsample_25pct\"\n",
    "models = [\"staci\"]\n",
    "\n",
    "run_number = 2\n",
    "leiden_resolutions = [0.1]\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    adata = sc.read_h5ad(f\"../../artifacts/single_sample_method_benchmarking/{dataset}_{model}.h5ad\")\n",
    "    adata.obs[\"sample\"] = \"sample1\"\n",
    "    \n",
    "    print(\"\\nComputing neighbor graph...\")\n",
    "    # Use latent representation for UMAP generation\n",
    "    sc.pp.neighbors(adata,\n",
    "                    use_rep=f\"{model}_latent_run{run_number}\",\n",
    "                    key_added=f\"{model}_latent_run{run_number}\")\n",
    "\n",
    "    print(\"\\nComputing UMAP embedding...\")\n",
    "    sc.tl.umap(adata,\n",
    "               neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "        \n",
    "    print(\"\\nComputing Leiden clustering...\")\n",
    "    sc.tl.leiden(adata=adata,\n",
    "                 resolution=leiden_resolutions[i],\n",
    "                 key_added=f\"run{run_number}_leiden_{leiden_resolutions[i]}\",\n",
    "                 neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "    \n",
    "    latent_cluster_colors = {\n",
    "        \"0\": \"#8BE0A4\",\n",
    "        \"1\": \"#66C5CC\",\n",
    "        \"2\": \"#D3B484\",\n",
    "        \"3\": \"#F6CF71\",\n",
    "        \"4\": \"#DCB0F2\",\n",
    "        \"5\": \"#FE88B1\",\n",
    "        \"6\": \"#DAB6C4\"}\n",
    "    \n",
    "    plot_category_in_latent_and_physical_space(\n",
    "            adata=adata,\n",
    "            figsize=(10,20),\n",
    "            plot_label=\"Latent Clusters\",\n",
    "            model_label={model},\n",
    "            cat_key=f\"run{run_number}_leiden_{leiden_resolutions[i]}\",\n",
    "            groups=None,\n",
    "            sample_key=\"sample\",\n",
    "            samples=[\"sample1\"], #samples=None #for latent UMAP #samples=[\"sample1\"] for spatial plot\n",
    "            cat_colors=latent_cluster_colors,\n",
    "            size=(720000 / len(adata)),\n",
    "            spot_size=30,\n",
    "            save_fig=True,\n",
    "            file_path=f\"{benchmarking_folder_path}/latent_clusters_{model}.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2338c1-7eff-40a7-9864-44c09babfd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"slideseqv2_mouse_hippocampus_subsample_25pct\"\n",
    "models = [\"graphst\"]\n",
    "\n",
    "run_number = 2\n",
    "leiden_resolutions = [0.15]\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    adata = sc.read_h5ad(f\"../../artifacts/single_sample_method_benchmarking/{dataset}_{model}.h5ad\")\n",
    "    adata.obs[\"sample\"] = \"sample1\"\n",
    "    \n",
    "    print(\"\\nComputing neighbor graph...\")\n",
    "    # Use latent representation for UMAP generation\n",
    "    sc.pp.neighbors(adata,\n",
    "                    use_rep=f\"{model}_latent_run{run_number}\",\n",
    "                    key_added=f\"{model}_latent_run{run_number}\")\n",
    "\n",
    "    print(\"\\nComputing UMAP embedding...\")\n",
    "    sc.tl.umap(adata,\n",
    "               neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "        \n",
    "    print(\"\\nComputing Leiden clustering...\")\n",
    "    sc.tl.leiden(adata=adata,\n",
    "                 resolution=leiden_resolutions[i],\n",
    "                 key_added=f\"run{run_number}_leiden_{leiden_resolutions[i]}\",\n",
    "                 neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "    \n",
    "    latent_cluster_colors = {\n",
    "        \"0\": \"#8BE0A4\",\n",
    "        \"1\": \"#DAB6C4\",\n",
    "        \"2\": \"#F6CF71\",\n",
    "        \"3\": \"#DCB0F2\",\n",
    "        \"4\": \"#66C5CC\",\n",
    "        \"5\": \"#D3B484\",\n",
    "        \"6\": \"#FE88B1\"}\n",
    "    \n",
    "    plot_category_in_latent_and_physical_space(\n",
    "            adata=adata,\n",
    "            figsize=(10,20),\n",
    "            plot_label=\"Latent Clusters\",\n",
    "            model_label={model},\n",
    "            cat_key=f\"run{run_number}_leiden_{leiden_resolutions[i]}\",\n",
    "            groups=None,\n",
    "            sample_key=\"sample\",\n",
    "            samples=[\"sample1\"], #samples=None #for latent UMAP #samples=[\"sample1\"] for spatial plot\n",
    "            cat_colors=latent_cluster_colors,\n",
    "            size=(720000 / len(adata)),\n",
    "            spot_size=30,\n",
    "            save_fig=True,\n",
    "            file_path=f\"{benchmarking_folder_path}/latent_clusters_{model}.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cadad4-b3f1-412a-aa75-c4f80f40f4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"slideseqv2_mouse_hippocampus_subsample_25pct\"\n",
    "models = [\"deeplinc\"]\n",
    "\n",
    "run_number = 2\n",
    "leiden_resolutions = [0.2]\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    adata = sc.read_h5ad(f\"../../artifacts/single_sample_method_benchmarking/{dataset}_{model}.h5ad\")\n",
    "    adata.obs[\"sample\"] = \"sample1\"\n",
    "    \n",
    "    print(\"\\nComputing neighbor graph...\")\n",
    "    # Use latent representation for UMAP generation\n",
    "    sc.pp.neighbors(adata,\n",
    "                    use_rep=f\"{model}_latent_run{run_number}\",\n",
    "                    key_added=f\"{model}_latent_run{run_number}\")\n",
    "\n",
    "    print(\"\\nComputing UMAP embedding...\")\n",
    "    sc.tl.umap(adata,\n",
    "               neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "        \n",
    "    print(\"\\nComputing Leiden clustering...\")\n",
    "    sc.tl.leiden(adata=adata,\n",
    "                 resolution=leiden_resolutions[i],\n",
    "                 key_added=f\"run{run_number}_leiden_{leiden_resolutions[i]}\",\n",
    "                 neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "    \n",
    "    latent_cluster_colors = {\n",
    "        \"0\": \"#8BE0A4\",\n",
    "        \"1\": \"#D3B484\",\n",
    "        \"2\": \"#DCB0F2\",\n",
    "        \"3\": \"#66C5CC\",\n",
    "        \"4\": \"#F6CF71\",\n",
    "        \"5\": \"#DAB6C4\",\n",
    "        \"6\": \"#FE88B1\"}\n",
    "    \n",
    "    plot_category_in_latent_and_physical_space(\n",
    "            adata=adata,\n",
    "            figsize=(10,20),\n",
    "            plot_label=\"Latent Clusters\",\n",
    "            model_label={model},\n",
    "            cat_key=f\"run{run_number}_leiden_{leiden_resolutions[i]}\",\n",
    "            groups=None,\n",
    "            sample_key=\"sample\",\n",
    "            samples=[\"sample1\"], #samples=None #for latent UMAP #samples=[\"sample1\"] for spatial plot\n",
    "            cat_colors=latent_cluster_colors,\n",
    "            size=(720000 / len(adata)),\n",
    "            spot_size=30,\n",
    "            save_fig=True,\n",
    "            file_path=f\"{benchmarking_folder_path}/latent_clusters_{model}.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2feb93-2187-40ad-bc67-6a5f04d2a6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"slideseqv2_mouse_hippocampus\",\n",
    "            \"slideseqv2_mouse_hippocampus_subsample_50pct\",\n",
    "            \"slideseqv2_mouse_hippocampus_subsample_25pct\",\n",
    "            \"slideseqv2_mouse_hippocampus_subsample_10pct\",\n",
    "            \"slideseqv2_mouse_hippocampus_subsample_5pct\",\n",
    "            \"slideseqv2_mouse_hippocampus_subsample_1pct\"]\n",
    "models = [\"nichecompass_gcnconv\",\n",
    "          \"nichecompass_gatv2conv\",\n",
    "          \"staci\",\n",
    "          \"deeplinc\",\n",
    "          \"graphst\",\n",
    "          \"sagenet\",\n",
    "          #\"scvi\",\n",
    "          #\"expimap\"\n",
    "         ]\n",
    "\n",
    "summary_df = pd.DataFrame()\n",
    "for dataset in datasets:\n",
    "    dataset_df = pd.DataFrame()\n",
    "    for model in models:\n",
    "        try:\n",
    "            benchmark_df = pd.read_csv(f\"{benchmarking_folder_path}/{dataset}_{model}_metrics.csv\")\n",
    "            #adata = sc.read_h5ad(f\"../../artifacts/single_sample_method_benchmarking/{dataset}_{model}.h5ad\")\n",
    "            #training_durations = []\n",
    "            #for run_number in [1, 2, 3, 4, 5, 6, 7, 8]:\n",
    "            #    training_durations.append(adata.uns[f\"{model.split('_')[0]}_model_training_duration_run{run_number}\"])\n",
    "            #benchmark_df[\"run_time\"] = training_durations\n",
    "            #benchmark_df = benchmark_df[[\"dataset\", \"run_number\", \"run_time\", \"gcs\", \"mlami\", \"cas\", \"clisis\", \"nasw\", \"cnmi\", \"cari\", \"casw\", \"clisi\"]]\n",
    "            #benchmark_df.to_csv(f\"{benchmarking_folder_path}/{dataset}_{model}_metrics.csv\", index=False)\n",
    "            benchmark_df[\"model\"] = model\n",
    "            dataset_df = pd.concat([dataset_df, benchmark_df], ignore_index=True)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Did not find file {benchmarking_folder_path}/{dataset}_{model}_metrics.csv. Continuing...\")\n",
    "            missing_run_data = {\n",
    "                \"dataset\": [dataset] * 8,\n",
    "                \"model\": [model] * 8,\n",
    "                \"run_number\": [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "                \"run_time\": [np.nan] * 8\n",
    "            }\n",
    "            missing_run_df = pd.DataFrame(missing_run_data)\n",
    "            dataset_df = dataset_df.append(missing_run_df, ignore_index=True)\n",
    "            \n",
    "    # Apply min-max scaling to metric columns\n",
    "    for i in range(len(metric_cols_single_sample)):\n",
    "        min_val = dataset_df[metric_cols_single_sample[i]].min()\n",
    "        max_val = dataset_df[metric_cols_single_sample[i]].max()\n",
    "        dataset_df[metric_cols_single_sample[i] + \"_scaled\"] = ((\n",
    "            dataset_df[metric_cols_single_sample[i]] - min_val) / (max_val - min_val))\n",
    "\n",
    "    summary_df = pd.concat([summary_df, dataset_df], ignore_index=True)\n",
    "    continue\n",
    "    \n",
    "cat_0_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_single_sample[0:2]]\n",
    "cat_1_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_single_sample[2:4]]\n",
    "cat_2_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_single_sample[4:6]]\n",
    "    \n",
    "summary_df[category_cols_single_sample[0]] = np.average(summary_df[cat_0_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_single_sample[0:2],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_single_sample[1]] = np.average(summary_df[cat_1_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_single_sample[2:4],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_single_sample[2]] = np.average(summary_df[cat_2_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_single_sample[4:6],\n",
    "                                                        axis=1)\n",
    "summary_df[\"Overall Score\"] = np.average(summary_df[category_cols_single_sample[:3]],\n",
    "                                         weights=category_col_weights_single_sample[:3],\n",
    "                                         axis=1)\n",
    " \n",
    "# Reformat for plot\n",
    "summary_df.replace({\"nichecompass_gatv2conv\": \"NicheCompass\",\n",
    "                    \"nichecompass_gcnconv\": \"NicheCompass Light\",\n",
    "                    \"staci\": \"STACI\",\n",
    "                    \"deeplinc\": \"DeepLinc\",\n",
    "                    \"expimap\": \"expiMap\",\n",
    "                    \"graphst\": \"GraphST\",\n",
    "                    \"sagenet\": \"SageNet\",\n",
    "                    \"scvi\": \"scVI\"}, inplace=True)\n",
    "\n",
    "# Plot over all loss weights combinations\n",
    "# Prepare metrics table plot\n",
    "group_cols = [\"dataset\", \"model\"]\n",
    "aggregate_df = summary_df.groupby(group_cols).mean(\"Overall Score\").sort_values(\"Overall Score\", ascending=False)[\n",
    "    metric_cols_single_sample + [\"Overall Score\"]].reset_index()\n",
    "\n",
    "unrolled_df = pd.melt(\n",
    "    aggregate_df, \n",
    "    id_vars=group_cols,\n",
    "    value_vars=metric_cols_single_sample + [\"Overall Score\"],\n",
    "    var_name=\"score_type\", \n",
    "    value_name=\"score\")\n",
    "\n",
    "# Create spatial indicator column\n",
    "def is_spatially_aware_model(row):\n",
    "    if row[\"model\"] in [\"NicheCompass GCN\", \"NicheCompass GATv2\", \"DeepLinc\", \"GraphST\", \"SageNet\"]:\n",
    "        return True\n",
    "    return False\n",
    "unrolled_df[\"spatially_aware\"] = unrolled_df.apply(lambda row: is_spatially_aware_model(row), axis=1)\n",
    "unrolled_df = unrolled_df[[\"dataset\", \"spatially_aware\", \"model\", \"score_type\", \"score\"]]\n",
    "\n",
    "# Order datasets\n",
    "unrolled_df[\"dataset\"] = pd.Categorical(unrolled_df[\"dataset\"], categories=datasets, ordered=True)\n",
    "unrolled_df = unrolled_df.sort_values(by=\"dataset\")\n",
    "\n",
    "#print(summary_df[\"model\"].value_counts())\n",
    "#print(summary_df[summary_df.isna().any(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40bd054-dc77-45c5-9c12-7ea78f6829a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_palette = {\"NicheCompass\": \"#8C96C6\",\n",
    "                 \"NicheCompass Light\": \"#42B6C7\",\n",
    "                 \"STACI\": \"#FFD700\",\n",
    "                 \"DeepLinc\": \"#0E1C4A\",\n",
    "                 \"GraphST\": \"#D78FF8\",\n",
    "                 \"SageNet\": \"#F46AA2\",\n",
    "                 \"scVI\": \"#FE8B3B\",\n",
    "                 \"expiMap\": \"#7E0028\",\n",
    "                 }\n",
    "\n",
    "run_time_mean_df = summary_df.groupby([\"dataset\", \"model\"])[[\"run_time\"]].mean().reset_index()\n",
    "run_time_mean_df[\"run_time\"] = run_time_mean_df[\"run_time\"] / 60\n",
    "\n",
    "def create_dataset_share_col(row):\n",
    "    if row[\"dataset\"] == \"slideseqv2_mouse_hippocampus\":\n",
    "        return 100\n",
    "    elif row[\"dataset\"] == \"slideseqv2_mouse_hippocampus_subsample_50pct\":    \n",
    "        return 50\n",
    "    elif row[\"dataset\"] == \"slideseqv2_mouse_hippocampus_subsample_25pct\":    \n",
    "        return 25\n",
    "    elif row[\"dataset\"] == \"slideseqv2_mouse_hippocampus_subsample_10pct\":    \n",
    "        return 10\n",
    "    elif row[\"dataset\"] == \"slideseqv2_mouse_hippocampus_subsample_5pct\":    \n",
    "        return 5\n",
    "    elif row[\"dataset\"] == \"slideseqv2_mouse_hippocampus_subsample_1pct\":    \n",
    "        return 1\n",
    "    \n",
    "run_time_mean_df[\"dataset_share\"] = run_time_mean_df.apply(lambda row: create_dataset_share_col(row), axis=1)\n",
    "    \n",
    "ax = sns.lineplot(data=run_time_mean_df,\n",
    "                  x=\"dataset_share\",\n",
    "                  y=\"run_time\",\n",
    "                  hue=\"model\",\n",
    "                  marker='o',\n",
    "                  palette=model_palette)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.title(\"SlideSeqV2 Mouse Hippocampus\\n(41,786 Cells; 4,000 Genes)\")\n",
    "plt.ylabel(\"Run Time (Minutes)\")\n",
    "plt.xlabel(\"Dataset Size (%)\")\n",
    "custom_y_ticks = [1, 10, 60, 180, 360, 720, 1440]  # Adjust the tick positions as needed\n",
    "plt.yscale(\"log\")\n",
    "plt.yticks(custom_y_ticks, custom_y_ticks)\n",
    "legend = plt.gca().get_legend()\n",
    "for handle in legend.legendHandles:\n",
    "    handle.set_linewidth(4.0)  # Adjust the size as needed\n",
    "handles, labels = legend.legendHandles, [text.get_text() for text in legend.get_texts()]\n",
    "order = [3, 2, 4, 1, 0]\n",
    "ordered_handles = [handles[i] for i in order]\n",
    "ordered_labels = [labels[i] for i in order]\n",
    "plt.legend(ordered_handles, ordered_labels)\n",
    "ax = plt.gca()\n",
    "ax.legend().set_visible(False)\n",
    "plt.savefig(benchmarking_folder_path + \"/benchmarking_runtimes_slideseqv2_mouse_hippocampus.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55de09bf-3e2d-41a2-913e-f8e8d6a4817e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot table\n",
    "plot_metrics_table(\n",
    "    df=unrolled_df,\n",
    "    model_col=\"model\",\n",
    "    model_col_width=1.9,\n",
    "    group_col=\"dataset\",\n",
    "    metric_cols=metric_cols_single_sample, # metric_cols_single_sample, category_cols_single_sample\n",
    "    metric_col_weights=metric_col_weights_single_sample, # metric_col_weights_single_sample, category_col_weights_single_sample\n",
    "    metric_col_titles=[col.replace(\" \", \"\\n\") for col in metric_col_titles_single_sample], # category_col_titles_single_sample\n",
    "    metric_col_width=0.7, # 0.8,\n",
    "    aggregate_col_width=1.,\n",
    "    plot_width=42, # 32,\n",
    "    plot_height=8,\n",
    "    show=True,\n",
    "    save_dir=benchmarking_folder_path,\n",
    "    save_name=f\"benchmarking_metrics_slideseqv2_mouse_hippocampus.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69c3cca-3c7d-4c5e-ac5f-ca9b1af82102",
   "metadata": {},
   "source": [
    "#### 2.1.2 seqFISH Mouse Organogenesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb819481-1e40-4cac-8ee0-413416345239",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"seqfish_mouse_organogenesis_embryo2\",\n",
    "            \"seqfish_mouse_organogenesis_subsample_50pct_embryo2\",\n",
    "            \"seqfish_mouse_organogenesis_subsample_25pct_embryo2\",\n",
    "            \"seqfish_mouse_organogenesis_subsample_10pct_embryo2\",\n",
    "            \"seqfish_mouse_organogenesis_subsample_5pct_embryo2\",\n",
    "            \"seqfish_mouse_organogenesis_subsample_1pct_embryo2\"]\n",
    "models = [\"nichecompass_gatv2conv\",\n",
    "          \"nichecompass_gcnconv\",\n",
    "          \"staci\",\n",
    "          \"deeplinc\",\n",
    "          \"graphst\",\n",
    "          \"sagenet\",\n",
    "          #\"scvi\",\n",
    "          #\"expimap\"\n",
    "         ]\n",
    "\n",
    "summary_df = pd.DataFrame()\n",
    "for dataset in datasets:\n",
    "    dataset_df = pd.DataFrame()\n",
    "    for model in models:\n",
    "        try:\n",
    "            benchmark_df = pd.read_csv(f\"{benchmarking_folder_path}/{dataset}_{model}_metrics.csv\")\n",
    "            #adata = sc.read_h5ad(f\"../../artifacts/single_sample_method_benchmarking/{dataset}_{model}.h5ad\")\n",
    "            #training_durations = []\n",
    "            #for run_number in [1, 2, 3, 4, 5, 6, 7, 8]:\n",
    "            #    training_durations.append(adata.uns[f\"{model.split('_')[0]}_model_training_duration_run{run_number}\"])\n",
    "            #benchmark_df[\"run_time\"] = training_durations\n",
    "            #benchmark_df = benchmark_df[[\"dataset\", \"run_number\", \"run_time\", \"gcs\", \"mlami\", \"cas\", \"clisis\", \"nasw\", \"cnmi\", \"cari\", \"casw\", \"clisi\"]]\n",
    "            #benchmark_df.to_csv(f\"{benchmarking_folder_path}/{dataset}_{model}_metrics.csv\", index=False)\n",
    "            benchmark_df[\"model\"] = model\n",
    "            dataset_df = pd.concat([dataset_df, benchmark_df], ignore_index=True)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Did not find file {benchmarking_folder_path}/{dataset}_{model}_metrics.csv. Continuing...\")\n",
    "            missing_run_data = {\n",
    "                \"dataset\": [dataset] * 8,\n",
    "                \"model\": [model] * 8,\n",
    "                \"run_number\": [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "                \"run_time\": [np.nan] * 8\n",
    "            }\n",
    "            missing_run_df = pd.DataFrame(missing_run_data)\n",
    "            dataset_df = dataset_df.append(missing_run_df, ignore_index=True)\n",
    "            \n",
    "    # Apply min-max scaling to metric columns\n",
    "    for i in range(len(metric_cols_single_sample)):\n",
    "        min_val = dataset_df[metric_cols_single_sample[i]].min()\n",
    "        max_val = dataset_df[metric_cols_single_sample[i]].max()\n",
    "        dataset_df[metric_cols_single_sample[i] + \"_scaled\"] = ((\n",
    "            dataset_df[metric_cols_single_sample[i]] - min_val) / (max_val - min_val))\n",
    "\n",
    "    summary_df = pd.concat([summary_df, dataset_df], ignore_index=True)\n",
    "    continue\n",
    "    \n",
    "cat_0_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_single_sample[0:2]]\n",
    "cat_1_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_single_sample[2:4]]\n",
    "cat_2_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_single_sample[4:6]]\n",
    "    \n",
    "summary_df[category_cols_single_sample[0]] = np.average(summary_df[cat_0_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_single_sample[0:2],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_single_sample[1]] = np.average(summary_df[cat_1_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_single_sample[2:4],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_single_sample[2]] = np.average(summary_df[cat_2_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_single_sample[4:6],\n",
    "                                                        axis=1)\n",
    "summary_df[\"Overall Score\"] = np.average(summary_df[category_cols_single_sample[:3]],\n",
    "                                         weights=category_col_weights_single_sample[:3],\n",
    "                                         axis=1)\n",
    " \n",
    "# Reformat for plot\n",
    "summary_df.replace({\"nichecompass_gatv2conv\": \"NicheCompass\",\n",
    "                    \"nichecompass_gcnconv\": \"NicheCompass Light\",\n",
    "                    \"staci\": \"STACI\",\n",
    "                    \"deeplinc\": \"DeepLinc\",\n",
    "                    \"expimap\": \"expiMap\",\n",
    "                    \"graphst\": \"GraphST\",\n",
    "                    \"sagenet\": \"SageNet\",\n",
    "                    \"scvi\": \"scVI\"}, inplace=True)\n",
    "\n",
    "# Plot over all loss weights combinations\n",
    "# Prepare metrics table plot\n",
    "group_cols = [\"dataset\", \"model\"]\n",
    "aggregate_df = summary_df.groupby(group_cols).mean(\"Overall Score\").sort_values(\"Overall Score\", ascending=False)[\n",
    "    metric_cols_single_sample + [\"Overall Score\"]].reset_index()\n",
    "\n",
    "unrolled_df = pd.melt(\n",
    "    aggregate_df, \n",
    "    id_vars=group_cols,\n",
    "    value_vars=metric_cols_single_sample + [\"Overall Score\"],\n",
    "    var_name=\"score_type\", \n",
    "    value_name=\"score\")\n",
    "\n",
    "# Create spatial indicator column\n",
    "def is_spatially_aware_model(row):\n",
    "    if row[\"model\"] in [\"NicheCompass GCN\", \"NicheCompass GATv2\", \"DeepLinc\", \"GraphST\", \"SageNet\"]:\n",
    "        return True\n",
    "    return False\n",
    "unrolled_df[\"spatially_aware\"] = unrolled_df.apply(lambda row: is_spatially_aware_model(row), axis=1)\n",
    "unrolled_df = unrolled_df[[\"dataset\", \"spatially_aware\", \"model\", \"score_type\", \"score\"]]\n",
    "\n",
    "# Order datasets\n",
    "unrolled_df[\"dataset\"] = pd.Categorical(unrolled_df[\"dataset\"], categories=datasets, ordered=True)\n",
    "unrolled_df = unrolled_df.sort_values(by=\"dataset\")\n",
    "\n",
    "#print(summary_df[\"model\"].value_counts())\n",
    "#print(summary_df[summary_df.isna().any(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1afa8d8-c3da-4e82-a5d3-870e045faab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_palette = {\"NicheCompass\": \"#8C96C6\",\n",
    "                 \"NicheCompass Light\": \"#42B6C7\",\n",
    "                 \"STACI\": \"#FFD700\",\n",
    "                 \"DeepLinc\": \"#0E1C4A\",\n",
    "                 \"GraphST\": \"#D78FF8\",\n",
    "                 \"SageNet\": \"#F46AA2\",\n",
    "                 \"scVI\": \"#FE8B3B\",\n",
    "                 \"expiMap\": \"#7E0028\",\n",
    "                 }\n",
    "\n",
    "run_time_mean_df = summary_df.groupby([\"dataset\", \"model\"])[[\"run_time\"]].mean().reset_index()\n",
    "run_time_mean_df[\"run_time\"] = run_time_mean_df[\"run_time\"] / 60\n",
    "\n",
    "def create_dataset_share_col(row):\n",
    "    if row[\"dataset\"] == \"seqfish_mouse_organogenesis_embryo2\":\n",
    "        return 100\n",
    "    elif row[\"dataset\"] == \"seqfish_mouse_organogenesis_subsample_50pct_embryo2\":    \n",
    "        return 50\n",
    "    elif row[\"dataset\"] == \"seqfish_mouse_organogenesis_subsample_25pct_embryo2\":    \n",
    "        return 25\n",
    "    elif row[\"dataset\"] == \"seqfish_mouse_organogenesis_subsample_10pct_embryo2\":    \n",
    "        return 10\n",
    "    elif row[\"dataset\"] == \"seqfish_mouse_organogenesis_subsample_5pct_embryo2\":    \n",
    "        return 5\n",
    "    elif row[\"dataset\"] == \"seqfish_mouse_organogenesis_subsample_1pct_embryo2\":    \n",
    "        return 1\n",
    "    \n",
    "run_time_mean_df[\"dataset_share\"] = run_time_mean_df.apply(lambda row: create_dataset_share_col(row), axis=1)\n",
    "    \n",
    "ax = sns.lineplot(data=run_time_mean_df,\n",
    "                  x=\"dataset_share\",\n",
    "                  y=\"run_time\",\n",
    "                  hue=\"model\",\n",
    "                  marker='o',\n",
    "                  palette=model_palette)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "plt.title(\"seqFISH Mouse Organogenesis\\n(14,891 Cells; 351 Genes)\")\n",
    "plt.ylabel(\"Run Time (Minutes)\")\n",
    "plt.xlabel(\"Dataset Size (%)\")\n",
    "custom_y_ticks = [1, 10, 60, 180, 360, 720, 1440]  # Adjust the tick positions as needed\n",
    "plt.yscale(\"log\")\n",
    "plt.yticks(custom_y_ticks, None)\n",
    "legend = plt.gca().get_legend()\n",
    "for handle in legend.legendHandles:\n",
    "    handle.set_linewidth(4.0)  # Adjust the size as needed\n",
    "handles, labels = legend.legendHandles, [text.get_text() for text in legend.get_texts()]\n",
    "order = [3, 2, 4, 1, 0]\n",
    "ordered_handles = [handles[i] for i in order]\n",
    "ordered_labels = [labels[i] for i in order]\n",
    "plt.legend(ordered_handles, ordered_labels)\n",
    "ax = plt.gca()\n",
    "ax.legend().set_visible(False)\n",
    "plt.savefig(benchmarking_folder_path + \"/benchmarking_runtimes_seqfish_mouse_organogenesis.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b78079-ec91-4168-a38f-0ff3530e8d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot table\n",
    "plot_metrics_table(\n",
    "    df=unrolled_df,\n",
    "    model_col=\"model\",\n",
    "    model_col_width=1.9,\n",
    "    group_col=\"dataset\",\n",
    "    metric_cols=metric_cols_single_sample, # metric_cols_single_sample, category_cols_single_sample\n",
    "    metric_col_weights=metric_col_weights_single_sample, # metric_col_weights_single_sample, category_col_weights_single_sample\n",
    "    metric_col_titles=[col.replace(\" \", \"\\n\") for col in metric_col_titles_single_sample], # category_col_titles_single_sample\n",
    "    metric_col_width=0.7, # 0.8,\n",
    "    aggregate_col_width=1.,\n",
    "    plot_width=42, # 32,\n",
    "    plot_height=8,\n",
    "    show=True,\n",
    "    save_dir=benchmarking_folder_path,\n",
    "    save_name=f\"benchmarking_metrics_seqfish_mouse_organogenesis.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6150e3-3aa9-4c55-bb20-2e0efe236ffc",
   "metadata": {},
   "source": [
    "#### 2.1.3 nanoString CosMx SMI Human Non-Small-Cell Lung Cancer (NSCLC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6422aa-660c-4474-9fea-3f9868b34146",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"nanostring_cosmx_human_nsclc_batch5\",\n",
    "            \"nanostring_cosmx_human_nsclc_subsample_50pct_batch5\",\n",
    "            \"nanostring_cosmx_human_nsclc_subsample_25pct_batch5\",\n",
    "            \"nanostring_cosmx_human_nsclc_subsample_10pct_batch5\",\n",
    "            \"nanostring_cosmx_human_nsclc_subsample_5pct_batch5\",\n",
    "            \"nanostring_cosmx_human_nsclc_subsample_1pct_batch5\"]\n",
    "models = [\"nichecompass_gcnconv\",\n",
    "          \"nichecompass_gatv2conv\",\n",
    "          \"staci\",\n",
    "          \"deeplinc\",\n",
    "          \"graphst\",\n",
    "          \"sagenet\",\n",
    "          #\"scvi\",\n",
    "          #\"expimap\"\n",
    "         ]\n",
    "\n",
    "summary_df = pd.DataFrame()\n",
    "for dataset in datasets:\n",
    "    dataset_df = pd.DataFrame()\n",
    "    for model in models:\n",
    "        try:\n",
    "            benchmark_df = pd.read_csv(f\"{benchmarking_folder_path}/{dataset}_{model}_metrics.csv\")\n",
    "            #adata = sc.read_h5ad(f\"../../artifacts/single_sample_method_benchmarking/{dataset}_{model}.h5ad\")\n",
    "            #training_durations = []\n",
    "            #for run_number in [1, 2, 3, 4, 5, 6, 7, 8]:\n",
    "            #    training_durations.append(adata.uns[f\"{model.split('_')[0]}_model_training_duration_run{run_number}\"])\n",
    "            #benchmark_df[\"run_time\"] = training_durations\n",
    "            #benchmark_df = benchmark_df[[\"dataset\", \"run_number\", \"run_time\", \"gcs\", \"mlami\", \"cas\", \"clisis\", \"nasw\", \"cnmi\", \"cari\", \"casw\", \"clisi\"]]\n",
    "            #benchmark_df.to_csv(f\"{benchmarking_folder_path}/{dataset}_{model}_metrics.csv\", index=False)\n",
    "            benchmark_df[\"model\"] = model\n",
    "            dataset_df = pd.concat([dataset_df, benchmark_df], ignore_index=True)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Did not find file {benchmarking_folder_path}/{dataset}_{model}_metrics.csv. Continuing...\")\n",
    "            missing_run_data = {\n",
    "                \"dataset\": [dataset] * 8,\n",
    "                \"model\": [model] * 8,\n",
    "                \"run_number\": [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "                \"run_time\": [np.nan] * 8\n",
    "            }\n",
    "            missing_run_df = pd.DataFrame(missing_run_data)\n",
    "            dataset_df = dataset_df.append(missing_run_df, ignore_index=True)\n",
    "            \n",
    "    # Apply min-max scaling to metric columns\n",
    "    for i in range(len(metric_cols_single_sample)):\n",
    "        min_val = dataset_df[metric_cols_single_sample[i]].min()\n",
    "        max_val = dataset_df[metric_cols_single_sample[i]].max()\n",
    "        dataset_df[metric_cols_single_sample[i] + \"_scaled\"] = ((\n",
    "            dataset_df[metric_cols_single_sample[i]] - min_val) / (max_val - min_val))\n",
    "\n",
    "    summary_df = pd.concat([summary_df, dataset_df], ignore_index=True)\n",
    "    continue\n",
    "    \n",
    "cat_0_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_single_sample[0:2]]\n",
    "cat_1_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_single_sample[2:4]]\n",
    "cat_2_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_single_sample[4:6]]\n",
    "    \n",
    "summary_df[category_cols_single_sample[0]] = np.average(summary_df[cat_0_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_single_sample[0:2],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_single_sample[1]] = np.average(summary_df[cat_1_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_single_sample[2:4],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_single_sample[2]] = np.average(summary_df[cat_2_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_single_sample[4:6],\n",
    "                                                        axis=1)\n",
    "summary_df[\"Overall Score\"] = np.average(summary_df[category_cols_single_sample[:3]],\n",
    "                                         weights=category_col_weights_single_sample[:3],\n",
    "                                         axis=1)\n",
    " \n",
    "# Reformat for plot\n",
    "summary_df.replace({\"nichecompass_gatv2conv\": \"NicheCompass\",\n",
    "                    \"nichecompass_gcnconv\": \"NicheCompass Light\",\n",
    "                    \"staci\": \"STACI\",\n",
    "                    \"deeplinc\": \"DeepLinc\",\n",
    "                    \"expimap\": \"expiMap\",\n",
    "                    \"graphst\": \"GraphST\",\n",
    "                    \"sagenet\": \"SageNet\",\n",
    "                    \"scvi\": \"scVI\"}, inplace=True)\n",
    "\n",
    "# Plot over all loss weights combinations\n",
    "# Prepare metrics table plot\n",
    "group_cols = [\"dataset\", \"model\"]\n",
    "aggregate_df = summary_df.groupby(group_cols).mean(\"Overall Score\").sort_values(\"Overall Score\", ascending=False)[\n",
    "    metric_cols_single_sample + [\"Overall Score\"]].reset_index()\n",
    "\n",
    "unrolled_df = pd.melt(\n",
    "    aggregate_df, \n",
    "    id_vars=group_cols,\n",
    "    value_vars=metric_cols_single_sample + [\"Overall Score\"],\n",
    "    var_name=\"score_type\", \n",
    "    value_name=\"score\")\n",
    "\n",
    "# Create spatial indicator column\n",
    "def is_spatially_aware_model(row):\n",
    "    if row[\"model\"] in [\"NicheCompass GCN\", \"NicheCompass GATv2\", \"DeepLinc\", \"GraphST\", \"SageNet\"]:\n",
    "        return True\n",
    "    return False\n",
    "unrolled_df[\"spatially_aware\"] = unrolled_df.apply(lambda row: is_spatially_aware_model(row), axis=1)\n",
    "unrolled_df = unrolled_df[[\"dataset\", \"spatially_aware\", \"model\", \"score_type\", \"score\"]]\n",
    "\n",
    "# Order datasets\n",
    "unrolled_df[\"dataset\"] = pd.Categorical(unrolled_df[\"dataset\"], categories=datasets, ordered=True)\n",
    "unrolled_df = unrolled_df.sort_values(by=\"dataset\")\n",
    "\n",
    "#print(summary_df[\"model\"].value_counts())\n",
    "#print(summary_df[summary_df.isna().any(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7539ec7-8687-44b6-8aec-11f594a5c1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_palette = {\"NicheCompass\": \"#8C96C6\",\n",
    "                 \"NicheCompass Light\": \"#42B6C7\",\n",
    "                 \"STACI\": \"#FFD700\",\n",
    "                 \"DeepLinc\": \"#0E1C4A\",\n",
    "                 \"GraphST\": \"#D78FF8\",\n",
    "                 \"SageNet\": \"#F46AA2\",\n",
    "                 \"scVI\": \"#FE8B3B\",\n",
    "                 \"expiMap\": \"#7E0028\",\n",
    "                 }\n",
    "\n",
    "run_time_mean_df = summary_df.groupby([\"dataset\", \"model\"])[[\"run_time\"]].mean().reset_index()\n",
    "run_time_mean_df[\"run_time\"] = run_time_mean_df[\"run_time\"] / 60\n",
    "\n",
    "def create_dataset_share_col(row):\n",
    "    if row[\"dataset\"] == \"nanostring_cosmx_human_nsclc_batch5\":\n",
    "        return 100\n",
    "    elif row[\"dataset\"] == \"nanostring_cosmx_human_nsclc_subsample_50pct_batch5\":    \n",
    "        return 50\n",
    "    elif row[\"dataset\"] == \"nanostring_cosmx_human_nsclc_subsample_25pct_batch5\":    \n",
    "        return 25\n",
    "    elif row[\"dataset\"] == \"nanostring_cosmx_human_nsclc_subsample_10pct_batch5\":    \n",
    "        return 10\n",
    "    elif row[\"dataset\"] == \"nanostring_cosmx_human_nsclc_subsample_5pct_batch5\":    \n",
    "        return 5\n",
    "    elif row[\"dataset\"] == \"nanostring_cosmx_human_nsclc_subsample_1pct_batch5\":    \n",
    "        return 1\n",
    "    \n",
    "run_time_mean_df[\"dataset_share\"] = run_time_mean_df.apply(lambda row: create_dataset_share_col(row), axis=1)\n",
    "    \n",
    "ax = sns.lineplot(data=run_time_mean_df,\n",
    "                  x=\"dataset_share\",\n",
    "                  y=\"run_time\",\n",
    "                  hue=\"model\",\n",
    "                  marker='o',\n",
    "                  palette=model_palette)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "plt.title(\"nanoString CosMx Human NSCLC\\n(77,391 Cells; 883 Genes)\")\n",
    "plt.ylabel(\"Run Time (Minutes)\")\n",
    "plt.xlabel(\"Dataset Size (%)\")\n",
    "custom_y_ticks = [1, 10, 60, 180, 360, 720, 1440]  # Adjust the tick positions as needed\n",
    "plt.yscale(\"log\")\n",
    "plt.yticks(custom_y_ticks, None)\n",
    "legend = plt.gca().get_legend()\n",
    "for handle in legend.legendHandles:\n",
    "    handle.set_linewidth(4.0)  # Adjust the size as needed\n",
    "handles, labels = legend.legendHandles, [text.get_text() for text in legend.get_texts()]\n",
    "order = [3, 2, 4, 1, 0, 5]\n",
    "ordered_handles = [handles[i] for i in order]\n",
    "ordered_labels = [labels[i] for i in order]\n",
    "lgd = plt.legend(ordered_handles, ordered_labels, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax = plt.gca()\n",
    "#ax.legend().set_visible(False)\n",
    "plt.savefig(benchmarking_folder_path + \"/benchmarking_runtimes_nanostring_cosmx_human_nsclc.svg\", bbox_inches=\"tight\", bbox_extra_artists=[lgd])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3872fa-6a37-4871-83ac-3400e6ca25f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot table\n",
    "plot_metrics_table(\n",
    "    df=unrolled_df,\n",
    "    model_col=\"model\",\n",
    "    model_col_width=1.9,\n",
    "    group_col=\"dataset\",\n",
    "    metric_cols=metric_cols_single_sample, # metric_cols_single_sample, category_cols_single_sample\n",
    "    metric_col_weights=metric_col_weights_single_sample, # metric_col_weights_single_sample, category_col_weights_single_sample\n",
    "    metric_col_titles=[col.replace(\" \", \"\\n\") for col in metric_col_titles_single_sample],\n",
    "    metric_col_width=0.7, # 0.8,\n",
    "    aggregate_col_width=1.,\n",
    "    plot_width=42, # 32,\n",
    "    plot_height=8,\n",
    "    show=True,\n",
    "    save_dir=benchmarking_folder_path,\n",
    "    save_name=f\"benchmarking_metrics_nanostring_cosmx_human_nsclc.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e7829f-acdc-40df-a608-14b05afbd55d",
   "metadata": {},
   "source": [
    "#### 2.1.4 Vizgen MERFISH Mouse Liver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db20e1a2-841b-4202-b1eb-7752b4a8d252",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"vizgen_merfish_mouse_liver\",\n",
    "            \"vizgen_merfish_mouse_liver_subsample_50pct\",\n",
    "            \"vizgen_merfish_mouse_liver_subsample_25pct\",\n",
    "            \"vizgen_merfish_mouse_liver_subsample_10pct\",\n",
    "            \"vizgen_merfish_mouse_liver_subsample_5pct\",\n",
    "            \"vizgen_merfish_mouse_liver_subsample_1pct\"]\n",
    "models = [\"nichecompass_gcnconv\",\n",
    "          \"nichecompass_gatv2conv\",\n",
    "          \"staci\",\n",
    "          \"deeplinc\",\n",
    "          \"graphst\",\n",
    "          \"sagenet\",\n",
    "          #\"scvi\",\n",
    "          #\"expimap\"\n",
    "         ]\n",
    "\n",
    "summary_df = pd.DataFrame()\n",
    "for dataset in datasets:\n",
    "    dataset_df = pd.DataFrame()\n",
    "    for model in models:\n",
    "        try:\n",
    "            benchmark_df = pd.read_csv(f\"{benchmarking_folder_path}/{dataset}_{model}_metrics.csv\")\n",
    "            #adata = sc.read_h5ad(f\"../../artifacts/single_sample_method_benchmarking/{dataset}_{model}.h5ad\")\n",
    "            #training_durations = []\n",
    "            #for run_number in [1, 2, 3, 4, 5, 6, 7, 8]:\n",
    "            #    training_durations.append(adata.uns[f\"{model.split('_')[0]}_model_training_duration_run{run_number}\"])\n",
    "            #benchmark_df[\"run_time\"] = training_durations\n",
    "            #benchmark_df = benchmark_df[[\"dataset\", \"run_number\", \"run_time\", \"gcs\", \"mlami\", \"cas\", \"clisis\", \"nasw\", \"cnmi\", \"cari\", \"casw\", \"clisi\"]]\n",
    "            #benchmark_df.to_csv(f\"{benchmarking_folder_path}/{dataset}_{model}_metrics.csv\", index=False)\n",
    "            benchmark_df[\"model\"] = model\n",
    "            dataset_df = pd.concat([dataset_df, benchmark_df], ignore_index=True)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Did not find file {benchmarking_folder_path}/{dataset}_{model}_metrics.csv. Continuing...\")\n",
    "            missing_run_data = {\n",
    "                \"dataset\": [dataset] * 8,\n",
    "                \"model\": [model] * 8,\n",
    "                \"run_number\": [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "                \"run_time\": [np.nan] * 8\n",
    "            }\n",
    "            missing_run_df = pd.DataFrame(missing_run_data)\n",
    "            dataset_df = dataset_df.append(missing_run_df, ignore_index=True)\n",
    "            \n",
    "    # Apply min-max scaling to metric columns\n",
    "    for i in range(len(metric_cols_single_sample)):\n",
    "        min_val = dataset_df[metric_cols_single_sample[i]].min()\n",
    "        max_val = dataset_df[metric_cols_single_sample[i]].max()\n",
    "        dataset_df[metric_cols_single_sample[i] + \"_scaled\"] = ((\n",
    "            dataset_df[metric_cols_single_sample[i]] - min_val) / (max_val - min_val))\n",
    "\n",
    "    summary_df = pd.concat([summary_df, dataset_df], ignore_index=True)\n",
    "    continue\n",
    "    \n",
    "cat_0_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_single_sample[0:2]]\n",
    "cat_1_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_single_sample[2:4]]\n",
    "cat_2_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_single_sample[4:6]]\n",
    "    \n",
    "summary_df[category_cols_single_sample[0]] = np.average(summary_df[cat_0_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_single_sample[0:2],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_single_sample[1]] = np.average(summary_df[cat_1_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_single_sample[2:4],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_single_sample[2]] = np.average(summary_df[cat_2_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_single_sample[4:6],\n",
    "                                                        axis=1)\n",
    "summary_df[\"Overall Score\"] = np.average(summary_df[category_cols_single_sample[:3]],\n",
    "                                         weights=category_col_weights_single_sample[:3],\n",
    "                                         axis=1)\n",
    " \n",
    "# Reformat for plot\n",
    "summary_df.replace({\"nichecompass_gatv2conv\": \"NicheCompass\",\n",
    "                    \"nichecompass_gcnconv\": \"NicheCompass Light\",\n",
    "                    \"staci\": \"STACI\",\n",
    "                    \"deeplinc\": \"DeepLinc\",\n",
    "                    \"expimap\": \"expiMap\",\n",
    "                    \"graphst\": \"GraphST\",\n",
    "                    \"sagenet\": \"SageNet\",\n",
    "                    \"scvi\": \"scVI\"}, inplace=True)\n",
    "\n",
    "# Plot over all loss weights combinations\n",
    "# Prepare metrics table plot\n",
    "group_cols = [\"dataset\", \"model\"]\n",
    "aggregate_df = summary_df.groupby(group_cols).mean(\"Overall Score\").sort_values(\"Overall Score\", ascending=False)[\n",
    "    metric_cols_single_sample + [\"Overall Score\"]].reset_index()\n",
    "\n",
    "unrolled_df = pd.melt(\n",
    "    aggregate_df, \n",
    "    id_vars=group_cols,\n",
    "    value_vars=metric_cols_single_sample + [\"Overall Score\"],\n",
    "    var_name=\"score_type\", \n",
    "    value_name=\"score\")\n",
    "\n",
    "# Create spatial indicator column\n",
    "def is_spatially_aware_model(row):\n",
    "    if row[\"model\"] in [\"NicheCompass GCN\", \"NicheCompass GATv2\", \"DeepLinc\", \"GraphST\", \"SageNet\"]:\n",
    "        return True\n",
    "    return False\n",
    "unrolled_df[\"spatially_aware\"] = unrolled_df.apply(lambda row: is_spatially_aware_model(row), axis=1)\n",
    "unrolled_df = unrolled_df[[\"dataset\", \"spatially_aware\", \"model\", \"score_type\", \"score\"]]\n",
    "\n",
    "# Order datasets\n",
    "unrolled_df[\"dataset\"] = pd.Categorical(unrolled_df[\"dataset\"], categories=datasets, ordered=True)\n",
    "unrolled_df = unrolled_df.sort_values(by=\"dataset\")\n",
    "\n",
    "#print(summary_df[\"model\"].value_counts())\n",
    "#print(summary_df[summary_df.isna().any(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c60a27-c03e-4975-b0f2-42b780b162f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_palette = {\"NicheCompass\": \"#8C96C6\",\n",
    "                 \"NicheCompass Light\": \"#42B6C7\",\n",
    "                 \"STACI\": \"#FFD700\",\n",
    "                 \"DeepLinc\": \"#0E1C4A\",\n",
    "                 \"GraphST\": \"#D78FF8\",\n",
    "                 \"SageNet\": \"#F46AA2\",\n",
    "                 \"scVI\": \"#FE8B3B\",\n",
    "                 \"expiMap\": \"#7E0028\",\n",
    "                 }\n",
    "\n",
    "run_time_mean_df = summary_df.groupby([\"dataset\", \"model\"])[[\"run_time\"]].mean().reset_index()\n",
    "run_time_mean_df[\"run_time\"] = run_time_mean_df[\"run_time\"] / 60\n",
    "\n",
    "def create_dataset_share_col(row):\n",
    "    if row[\"dataset\"] == \"vizgen_merfish_mouse_liver\":\n",
    "        return 100\n",
    "    elif row[\"dataset\"] == \"vizgen_merfish_mouse_liver_subsample_50pct\":    \n",
    "        return 50\n",
    "    elif row[\"dataset\"] == \"vizgen_merfish_mouse_liver_subsample_25pct\":    \n",
    "        return 25\n",
    "    elif row[\"dataset\"] == \"vizgen_merfish_mouse_liver_subsample_10pct\":    \n",
    "        return 10\n",
    "    elif row[\"dataset\"] == \"vizgen_merfish_mouse_liver_subsample_5pct\":    \n",
    "        return 5\n",
    "    elif row[\"dataset\"] == \"vizgen_merfish_mouse_liver_subsample_1pct\":    \n",
    "        return 1\n",
    "    \n",
    "run_time_mean_df[\"dataset_share\"] = run_time_mean_df.apply(lambda row: create_dataset_share_col(row), axis=1)\n",
    "    \n",
    "ax = sns.lineplot(data=run_time_mean_df,\n",
    "                  x=\"dataset_share\",\n",
    "                  y=\"run_time\",\n",
    "                  hue=\"model\",\n",
    "                  marker='o',\n",
    "                  palette=model_palette)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "plt.title(\"MERFISH Mouse Liver\\n(367,335 Cells; 347 Genes)\")\n",
    "plt.ylabel(\"Run Time (Minutes)\")\n",
    "plt.xlabel(\"Dataset Size (%)\")\n",
    "custom_y_ticks = [1, 10, 60, 180, 360, 720, 1440]  # Adjust the tick positions as needed\n",
    "plt.yscale(\"log\")\n",
    "plt.yticks(custom_y_ticks, None)\n",
    "legend = plt.gca().get_legend()\n",
    "for handle in legend.legendHandles:\n",
    "    handle.set_linewidth(4.0)  # Adjust the size as needed\n",
    "handles, labels = legend.legendHandles, [text.get_text() for text in legend.get_texts()]\n",
    "order = [3, 2, 4, 1, 0]\n",
    "ordered_handles = [handles[i] for i in order]\n",
    "ordered_labels = [labels[i] for i in order]\n",
    "plt.legend(ordered_handles, ordered_labels)\n",
    "ax = plt.gca()\n",
    "ax.legend().set_visible(False)\n",
    "plt.savefig(benchmarking_folder_path + \"/benchmarking_runtimes_vizgen_merfish_mouse_liver.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a04483-34f3-4147-9282-041bfe9a21bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot table\n",
    "plot_metrics_table(\n",
    "    df=unrolled_df,\n",
    "    model_col=\"model\",\n",
    "    model_col_width=1.9,\n",
    "    group_col=\"dataset\",\n",
    "    metric_cols=metric_cols_single_sample, # metric_cols_single_sample, category_cols_single_sample\n",
    "    metric_col_weights=metric_col_weights_single_sample, # metric_col_weights_single_sample, category_col_weights_single_sample\n",
    "    metric_col_titles=[col.replace(\" \", \"\\n\") for col in metric_col_titles_single_sample], # category_col_titles_single_sample\n",
    "    metric_col_width=0.7, # 0.8,\n",
    "    aggregate_col_width=1.,\n",
    "    plot_width=42, # 32,\n",
    "    plot_height=8,\n",
    "    show=True,\n",
    "    save_dir=benchmarking_folder_path,\n",
    "    save_name=f\"benchmarking_metrics_vizgen_merfish_mouse_liver.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894d488a-bd39-4948-8288-8fb26ea35dc5",
   "metadata": {},
   "source": [
    "#### 2.1.5 All Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3583ccc4-f0e9-4894-b3ea-5f2de4fc2f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define params for plot formatting\n",
    "fig_width_10_ticks = 8.2\n",
    "fig_width_9_ticks = 7.8\n",
    "fig_width_8_ticks = 7.4\n",
    "fig_width_7_ticks = 7.0\n",
    "fig_width_6_ticks = 6.6\n",
    "fig_width_5_ticks = 6.2\n",
    "fig_width_2_ticks = 5.1\n",
    "fig_width_3_ticks = 5.5\n",
    "fig_height = 5\n",
    "fontsize = 14\n",
    "row_fontsize = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1f66e5-16cb-41fe-aaff-b89b976ff101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metrics\n",
    "datasets = [\"slideseqv2_mouse_hippocampus\",\n",
    "            \"seqfish_mouse_organogenesis_embryo2\",\n",
    "            \"vizgen_merfish_mouse_liver\",\n",
    "            \"nanostring_cosmx_human_nsclc_batch5\",]\n",
    "models = [\"nichecompass_gatv2conv\",\n",
    "          \"nichecompass_gcnconv\",\n",
    "          \"staci\",\n",
    "          \"deeplinc\",\n",
    "          \"graphst\",\n",
    "          \"sagenet\",\n",
    "          #\"scvi\",\n",
    "          #\"expimap\"\n",
    "         ]\n",
    "\n",
    "summary_df = pd.DataFrame()\n",
    "for dataset in datasets:\n",
    "    dataset_df = pd.DataFrame()\n",
    "    for model in models:\n",
    "        try:\n",
    "            benchmark_df = pd.read_csv(f\"{benchmarking_folder_path}/{dataset}_{model}_metrics.csv\")\n",
    "            #adata = sc.read_h5ad(f\"../../artifacts/single_sample_method_benchmarking/{dataset}_{model}.h5ad\")\n",
    "            #training_durations = []\n",
    "            #for run_number in [1, 2, 3, 4, 5, 6, 7, 8]:\n",
    "            #    training_durations.append(adata.uns[f\"{model.split('_')[0]}_model_training_duration_run{run_number}\"])\n",
    "            #benchmark_df[\"run_time\"] = training_durations\n",
    "            #benchmark_df = benchmark_df[[\"dataset\", \"run_number\", \"run_time\", \"gcs\", \"mlami\", \"cas\", \"clisis\", \"nasw\", \"cnmi\", \"cari\", \"casw\", \"clisi\"]]\n",
    "            #benchmark_df.to_csv(f\"{benchmarking_folder_path}/{dataset}_{model}_metrics.csv\", index=False)\n",
    "            benchmark_df[\"model\"] = model\n",
    "            dataset_df = pd.concat([dataset_df, benchmark_df], ignore_index=True)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Did not find file {benchmarking_folder_path}/{dataset}_{model}_metrics.csv. Continuing...\")\n",
    "            missing_run_data = {\n",
    "                \"dataset\": [dataset] * 8,\n",
    "                \"model\": [model] * 8,\n",
    "                \"run_number\": [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "                \"run_time\": [np.nan] * 8\n",
    "            }\n",
    "            missing_run_df = pd.DataFrame(missing_run_data)\n",
    "            dataset_df = dataset_df.append(missing_run_df, ignore_index=True)\n",
    "            \n",
    "    # Apply min-max scaling to metric columns\n",
    "    for i in range(len(metric_cols_single_sample)):\n",
    "        min_val = dataset_df[metric_cols_single_sample[i]].min()\n",
    "        max_val = dataset_df[metric_cols_single_sample[i]].max()\n",
    "        dataset_df[metric_cols_single_sample[i] + \"_scaled\"] = ((\n",
    "            dataset_df[metric_cols_single_sample[i]] - min_val) / (max_val - min_val))\n",
    "\n",
    "    summary_df = pd.concat([summary_df, dataset_df], ignore_index=True)\n",
    "    continue\n",
    "\n",
    "cat_0_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_single_sample[0:2]]\n",
    "cat_1_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_single_sample[2:4]]\n",
    "cat_2_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_single_sample[4:6]]\n",
    "    \n",
    "summary_df[category_cols_single_sample[0]] = np.average(summary_df[cat_0_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_single_sample[0:2],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_single_sample[1]] = np.average(summary_df[cat_1_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_single_sample[2:4],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_single_sample[2]] = np.average(summary_df[cat_2_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_single_sample[4:6],\n",
    "                                                        axis=1)\n",
    "summary_df[\"Overall Score\"] = np.average(summary_df[category_cols_single_sample[:3]],\n",
    "                                         weights=category_col_weights_single_sample[:3],\n",
    "                                         axis=1)\n",
    "\n",
    "# Reformat for plot\n",
    "summary_df.replace({\"nichecompass_gatv2conv\": \"NicheCompass\",\n",
    "                    \"nichecompass_gcnconv\": \"NicheCompass Light\",\n",
    "                    \"staci\": \"STACI\",\n",
    "                    \"deeplinc\": \"DeepLinc\",\n",
    "                    \"expimap\": \"expiMap\",\n",
    "                    \"graphst\": \"GraphST\",\n",
    "                    \"sagenet\": \"SageNet\",\n",
    "                    \"scvi\": \"scVI\"}, inplace=True)\n",
    "\n",
    "# Plot over all loss weights combinations\n",
    "# Prepare metrics table plot\n",
    "group_cols = [\"dataset\", \"model\"]\n",
    "aggregate_df = summary_df.groupby(group_cols).mean(\"Overall Score\").sort_values(\"Overall Score\", ascending=False)[\n",
    "    metric_cols_single_sample + [\"Overall Score\"]].reset_index()\n",
    "\n",
    "unrolled_df = pd.melt(\n",
    "    aggregate_df, \n",
    "    id_vars=group_cols,\n",
    "    value_vars=metric_cols_single_sample + [\"Overall Score\"],\n",
    "    var_name=\"score_type\", \n",
    "    value_name=\"score\")\n",
    "\n",
    "# Create spatial indicator column\n",
    "def is_spatially_aware_model(row):\n",
    "    if row[\"model\"] in [\"NicheCompass GCN\", \"NicheCompass GATv2\", \"DeepLinc\", \"GraphST\", \"SageNet\"]:\n",
    "        return True\n",
    "    return False\n",
    "unrolled_df[\"spatially_aware\"] = unrolled_df.apply(lambda row: is_spatially_aware_model(row), axis=1)\n",
    "unrolled_df = unrolled_df[[\"dataset\", \"spatially_aware\", \"model\", \"score_type\", \"score\"]]\n",
    "\n",
    "# Order datasets\n",
    "unrolled_df[\"dataset\"] = pd.Categorical(unrolled_df[\"dataset\"], categories=datasets, ordered=True)\n",
    "unrolled_df = unrolled_df.sort_values(by=\"dataset\")\n",
    "\n",
    "#print(summary_df[\"model\"].value_counts())\n",
    "#print(summary_df[summary_df.isna().any(axis=1)])\n",
    "\n",
    "summary_df[\"model\"] = summary_df[\"model\"].replace(\"NicheCompass GCN\", \"NicheCompass Light\")\n",
    "summary_df[\"model\"] = summary_df[\"model\"].replace(\"NicheCompass GATv2\", \"NicheCompass\")\n",
    "\n",
    "summary_df[\"dataset\"] = summary_df[\"dataset\"].replace(\n",
    "    {\"slideseqv2_mouse_hippocampus\": \"SlideSeqV2 Mouse Hippocampus\",\n",
    "     \"seqfish_mouse_organogenesis_embryo2\": \"seqFISH Mouse Organogenesis\",\n",
    "     \"nanostring_cosmx_human_nsclc_batch5\": \"nanoString CosMx Human NSCLC\",\n",
    "     \"vizgen_merfish_mouse_liver\": \"MERFISH Mouse Liver\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8673ab75-6490-4d77-bb22-0e14dcfc7821",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "model_palette = {\"NicheCompass\": \"#8C96C6\",\n",
    "                 \"NicheCompass Light\": \"#42B6C7\",\n",
    "                 \"STACI\": \"#FFD700\",\n",
    "                 \"DeepLinc\": \"#0E1C4A\",\n",
    "                 \"GraphST\": \"#D78FF8\",\n",
    "                 \"SageNet\": \"#F46AA2\",\n",
    "                 \"scVI\": \"#FE8B3B\",\n",
    "                 \"expiMap\": \"#7E0028\",\n",
    "                 }\n",
    "\n",
    "plt.figure(figsize=(fig_width_8_ticks, fig_height))\n",
    "ax = sns.barplot(data=summary_df,\n",
    "                 x=\"cas\",\n",
    "                 y=\"dataset\",\n",
    "                 hue=\"model\",\n",
    "                 orient=\"h\",\n",
    "                 palette=model_palette)\n",
    "for i in range(summary_df[\"dataset\"].nunique()):\n",
    "    ax.axhline(0.5 + 1 * i, color='gray', linestyle='--', linewidth=2)\n",
    "\n",
    "new_labels = [label.get_text().replace(' ', '\\n') if i < 3 else label.get_text().replace(' H', '\\nH', -1).replace(' N', '\\nN', -1).replace(' CosMx', '\\nCosMx', -1) for i, label in enumerate(ax.get_yticklabels())]\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_yticklabels(new_labels)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(\"CAS\", fontsize=fontsize)\n",
    "plt.yticks(fontsize=row_fontsize)\n",
    "plt.xticks([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8], fontsize=fontsize)\n",
    "plt.xlim(0.1, 0.9)\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{benchmarking_folder_path}/benchmarking_barplot_cas.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e191a26c-c010-42ff-a0fa-05ee03f1627e",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = summary_df[summary_df[\"dataset\"] == \"SlideSeqV2 Mouse Hippocampus\"]\n",
    "metrics_temp_df = temp_df.groupby(\"model\")[[\"cas\"]].mean()\n",
    "metrics_temp_df.iloc[2] / metrics_temp_df.iloc[1] # NC vs GraphST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c285b8-5a4f-41b7-bac1-49fc46d6cc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = summary_df[summary_df[\"dataset\"] == \"seqFISH Mouse Organogenesis\"]\n",
    "metrics_temp_df = temp_df.groupby(\"model\")[[\"cas\"]].mean()\n",
    "metrics_temp_df.iloc[2] / metrics_temp_df.iloc[4] # NC vs STACI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be03a347-0043-4431-8493-00387e223420",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "model_palette = {\"NicheCompass\": \"#8C96C6\",\n",
    "                 \"NicheCompass Light\": \"#42B6C7\",\n",
    "                 \"STACI\": \"#FFD700\",\n",
    "                 \"DeepLinc\": \"#0E1C4A\",\n",
    "                 \"GraphST\": \"#D78FF8\",\n",
    "                 \"SageNet\": \"#F46AA2\",\n",
    "                 \"scVI\": \"#FE8B3B\",\n",
    "                 \"expiMap\": \"#7E0028\",\n",
    "                 }\n",
    "\n",
    "plt.figure(figsize=(fig_width_8_ticks, fig_height))\n",
    "ax = sns.barplot(data=summary_df,\n",
    "                 x=\"mlami\",\n",
    "                 y=\"dataset\",\n",
    "                 hue=\"model\",\n",
    "                 orient=\"h\",\n",
    "                 palette=model_palette)\n",
    "for i in range(summary_df[\"dataset\"].nunique()):\n",
    "    ax.axhline(0.5 + 1 * i, color='gray', linestyle='--', linewidth=2)\n",
    "\n",
    "new_labels = [label.get_text().replace(' ', '\\n') if i < 3 else label.get_text().replace(' H', '\\nH', -1).replace(' N', '\\nN', -1).replace(' N', '\\nN', -1).replace(' CosMx', '\\nCosMx', -1) for i, label in enumerate(ax.get_yticklabels())]\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_yticklabels(new_labels)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(\"MLAMI\", fontsize=fontsize)\n",
    "plt.yticks(fontsize=row_fontsize)\n",
    "plt.xticks([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8], fontsize=fontsize)\n",
    "plt.xlim(0.1, 0.9)\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{benchmarking_folder_path}/benchmarking_barplot_mlami.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33879234-7076-4753-acec-07ab10cfcbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = summary_df[summary_df[\"dataset\"] == \"SlideSeqV2 Mouse Hippocampus\"]\n",
    "metrics_temp_df = temp_df.groupby(\"model\")[[\"mlami\"]].mean()\n",
    "metrics_temp_df.iloc[2] / metrics_temp_df.iloc[1] # NC vs GraphST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb33f785-e63e-4ae8-a5f0-74e2cf48cd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = summary_df[summary_df[\"dataset\"] == \"seqFISH Mouse Organogenesis\"]\n",
    "metrics_temp_df = temp_df.groupby(\"model\")[[\"mlami\"]].mean()\n",
    "metrics_temp_df.iloc[2] / metrics_temp_df.iloc[4] # NC vs STACI"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b9784c7b-e0a2-497b-b1a2-5bbb2917b1d5",
   "metadata": {},
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "model_palette = {\"NicheCompass\": \"#8C96C6\",\n",
    "                 \"NicheCompass Light\": \"#42B6C7\",\n",
    "                 \"STACI\": \"#FFD700\",\n",
    "                 \"DeepLinc\": \"#0E1C4A\",\n",
    "                 \"GraphST\": \"#D78FF8\",\n",
    "                 \"SageNet\": \"#F46AA2\",\n",
    "                 \"scVI\": \"#FE8B3B\",\n",
    "                 \"expiMap\": \"#7E0028\",\n",
    "                 }\n",
    "\n",
    "plt.figure(figsize=(fig_width_9_ticks, fig_height))\n",
    "ax = sns.barplot(data=summary_df,\n",
    "                 x=\"Global Spatial Conservation Score\",\n",
    "                 y=\"dataset\",\n",
    "                 hue=\"model\",\n",
    "                 orient=\"h\",\n",
    "                 palette=model_palette)\n",
    "for i in range(summary_df[\"dataset\"].nunique()):\n",
    "    ax.axhline(0.5 + 1 * i, color='gray', linestyle='--', linewidth=2)\n",
    "\n",
    "new_labels = [label.get_text().replace(' ', '\\n') if i < 3 else label.get_text().replace(' H', '\\nH', -1).replace(' N', '\\nN', -1).replace(' N', '\\nN', -1).replace(' CosMx', '\\nCosMx', -1) for i, label in enumerate(ax.get_yticklabels())]\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_yticklabels(new_labels)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(\"Global Spatial Conservation Score\", fontsize=fontsize)\n",
    "plt.yticks(fontsize=row_fontsize)\n",
    "plt.xticks([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], fontsize=fontsize)\n",
    "plt.xlim(0.1, 1.0)\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{benchmarking_folder_path}/benchmarking_barplot_global_spatial_conservation_score.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a422236b-f122-4ea8-99a0-70d5e8f6cc58",
   "metadata": {},
   "source": [
    "temp_df = summary_df[summary_df[\"dataset\"] == \"SlideSeqV2 Mouse Hippocampus\"]\n",
    "metrics_temp_df = temp_df.groupby(\"model\")[[\"Global Spatial Conservation Score\"]].mean()\n",
    "metrics_temp_df.iloc[2] / metrics_temp_df.iloc[1] # NC vs GraphST"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2a85b329-ff21-46d9-8c52-448f4e4b0ac5",
   "metadata": {},
   "source": [
    "temp_df = summary_df[summary_df[\"dataset\"] == \"seqFISH Mouse Organogenesis\"]\n",
    "metrics_temp_df = temp_df.groupby(\"model\")[[\"Global Spatial Conservation Score\"]].mean()\n",
    "metrics_temp_df.iloc[2] / metrics_temp_df.iloc[4] # NC vs STACI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd6204a-627a-440f-80e0-928b1b22edff",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "model_palette = {\"NicheCompass\": \"#8C96C6\",\n",
    "                 \"NicheCompass Light\": \"#42B6C7\",\n",
    "                 \"STACI\": \"#FFD700\",\n",
    "                 \"DeepLinc\": \"#0E1C4A\",\n",
    "                 \"GraphST\": \"#D78FF8\",\n",
    "                 \"SageNet\": \"#F46AA2\",\n",
    "                 \"scVI\": \"#FE8B3B\",\n",
    "                 \"expiMap\": \"#7E0028\",\n",
    "                 }\n",
    "\n",
    "plt.figure(figsize=(fig_width_2_ticks, fig_height))\n",
    "ax = sns.barplot(data=summary_df,\n",
    "                 x=\"clisis\",\n",
    "                 y=\"dataset\",\n",
    "                 hue=\"model\",\n",
    "                 orient=\"h\",\n",
    "                 palette=model_palette)\n",
    "for i in range(summary_df[\"dataset\"].nunique()):\n",
    "    ax.axhline(0.5 + 1 * i, color='gray', linestyle='--', linewidth=2)\n",
    "\n",
    "new_labels = [label.get_text().replace(' ', '\\n') if i < 3 else label.get_text().replace(' H', '\\nH', -1).replace(' N', '\\nN', -1).replace(' N', '\\nN', -1).replace(' CosMx', '\\nCosMx', -1) for i, label in enumerate(ax.get_yticklabels())]\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_yticklabels(new_labels)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(\"CLISIS\", fontsize=fontsize)\n",
    "plt.yticks(fontsize=row_fontsize)\n",
    "plt.xticks([0.8, 0.9], fontsize=fontsize)\n",
    "plt.xlim(0.8, 1.0)\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{benchmarking_folder_path}/benchmarking_barplot_clisis.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d8754f-5d5d-4d53-b935-dcbf862c9758",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = summary_df[summary_df[\"dataset\"] == \"SlideSeqV2 Mouse Hippocampus\"]\n",
    "metrics_temp_df = temp_df.groupby(\"model\")[[\"clisis\"]].mean()\n",
    "metrics_temp_df.iloc[2] / metrics_temp_df.iloc[1] # NC vs GraphST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0671a1c1-49ed-4387-bdae-ca0305ccdfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = summary_df[summary_df[\"dataset\"] == \"seqFISH Mouse Organogenesis\"]\n",
    "metrics_temp_df = temp_df.groupby(\"model\")[[\"clisis\"]].mean()\n",
    "metrics_temp_df.iloc[2] / metrics_temp_df.iloc[4] # NC vs STACI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a3a7cd-628c-4295-894a-055ee565311a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "model_palette = {\"NicheCompass\": \"#8C96C6\",\n",
    "                 \"NicheCompass Light\": \"#42B6C7\",\n",
    "                 \"STACI\": \"#FFD700\",\n",
    "                 \"DeepLinc\": \"#0E1C4A\",\n",
    "                 \"GraphST\": \"#D78FF8\",\n",
    "                 \"SageNet\": \"#F46AA2\",\n",
    "                 \"scVI\": \"#FE8B3B\",\n",
    "                 \"expiMap\": \"#7E0028\",\n",
    "                 }\n",
    "\n",
    "plt.figure(figsize=(fig_width_3_ticks, fig_height))\n",
    "ax = sns.barplot(data=summary_df,\n",
    "                 x=\"gcs\",\n",
    "                 y=\"dataset\",\n",
    "                 hue=\"model\",\n",
    "                 orient=\"h\",\n",
    "                 palette=model_palette)\n",
    "for i in range(summary_df[\"dataset\"].nunique()):\n",
    "    ax.axhline(0.5 + 1 * i, color='gray', linestyle='--', linewidth=2)\n",
    "\n",
    "new_labels = [label.get_text().replace(' ', '\\n') if i < 3 else label.get_text().replace(' H', '\\nH', -1).replace(' N', '\\nN', -1).replace(' N', '\\nN', -1).replace(' CosMx', '\\nCosMx', -1) for i, label in enumerate(ax.get_yticklabels())]\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_yticklabels(new_labels)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(\"GCS\", fontsize=fontsize)\n",
    "plt.yticks(fontsize=row_fontsize)\n",
    "plt.xticks([0.7, 0.8, 0.9], fontsize=fontsize)\n",
    "plt.xlim(0.7, 1.0)\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{benchmarking_folder_path}/benchmarking_barplot_gcs.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5b5304-d4c0-4a4f-a3d8-9c62c90adb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = summary_df[summary_df[\"dataset\"] == \"SlideSeqV2 Mouse Hippocampus\"]\n",
    "metrics_temp_df = temp_df.groupby(\"model\")[[\"gcs\"]].mean()\n",
    "metrics_temp_df.iloc[2] / metrics_temp_df.iloc[1] # NC vs GraphST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851c5385-343b-46a8-bcee-4d6979018b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = summary_df[summary_df[\"dataset\"] == \"seqFISH Mouse Organogenesis\"]\n",
    "metrics_temp_df = temp_df.groupby(\"model\")[[\"gcs\"]].mean()\n",
    "metrics_temp_df.iloc[2] / metrics_temp_df.iloc[4] # NC vs STACI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026c01eb-0550-4a44-9a6d-2cfc0abf34b9",
   "metadata": {},
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "model_palette = {\"NicheCompass\": \"#8C96C6\",\n",
    "                 \"NicheCompass Light\": \"#42B6C7\",\n",
    "                 \"STACI\": \"#FFD700\",\n",
    "                 \"DeepLinc\": \"#0E1C4A\",\n",
    "                 \"GraphST\": \"#D78FF8\",\n",
    "                 \"SageNet\": \"#F46AA2\",\n",
    "                 \"scVI\": \"#FE8B3B\",\n",
    "                 \"expiMap\": \"#7E0028\",\n",
    "                 }\n",
    "\n",
    "plt.figure(figsize=(fig_width_9_ticks, fig_height))\n",
    "ax = sns.barplot(data=summary_df,\n",
    "                 x=\"Local Spatial Conservation Score\",\n",
    "                 y=\"dataset\",\n",
    "                 hue=\"model\",\n",
    "                 orient=\"h\",\n",
    "                 palette=model_palette)\n",
    "for i in range(summary_df[\"dataset\"].nunique()):\n",
    "    ax.axhline(0.5 + 1 * i, color='gray', linestyle='--', linewidth=2)\n",
    "\n",
    "new_labels = [label.get_text().replace(' ', '\\n') if i < 3 else label.get_text().replace(' H', '\\nH', -1).replace(' N', '\\nN', -1).replace(' CosMx', '\\nCosMx', -1) for i, label in enumerate(ax.get_yticklabels())]\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_yticklabels(new_labels)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(\"Local Spatial Conservation Score\", fontsize=fontsize)\n",
    "plt.yticks(fontsize=row_fontsize)\n",
    "plt.xticks([0., 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], fontsize=fontsize)\n",
    "plt.xlim(0., 1.0)\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{benchmarking_folder_path}/benchmarking_barplot_local_spatial_conservation_score.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8f65bf4b-48f5-4997-908d-322bedbdb9af",
   "metadata": {},
   "source": [
    "temp_df = summary_df[summary_df[\"dataset\"] == \"SlideSeqV2 Mouse Hippocampus\"]\n",
    "metrics_temp_df = temp_df.groupby(\"model\")[[\"Local Spatial Conservation Score\"]].mean()\n",
    "metrics_temp_df.iloc[2] / metrics_temp_df.iloc[1] # NC vs GraphST"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9373807d-ffe4-43c5-9435-053001de26e5",
   "metadata": {},
   "source": [
    "temp_df = summary_df[summary_df[\"dataset\"] == \"seqFISH Mouse Organogenesis\"]\n",
    "metrics_temp_df = temp_df.groupby(\"model\")[[\"Local Spatial Conservation Score\"]].mean()\n",
    "metrics_temp_df.iloc[2] / metrics_temp_df.iloc[4] # NC vs STACI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0980900-e2d4-4ac0-91d2-37a75ad04c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df[\"Spatial Conservation Score\"] = (summary_df[\"Global Spatial Conservation Score\"] + summary_df[\"Local Spatial Conservation Score\"])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6761ecd-7851-4a4d-8acb-af31de076619",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "model_palette = {\"NicheCompass\": \"#8C96C6\",\n",
    "                 \"NicheCompass Light\": \"#42B6C7\",\n",
    "                 \"STACI\": \"#FFD700\",\n",
    "                 \"DeepLinc\": \"#0E1C4A\",\n",
    "                 \"GraphST\": \"#D78FF8\",\n",
    "                 \"SageNet\": \"#F46AA2\",\n",
    "                 \"scVI\": \"#FE8B3B\",\n",
    "                 \"expiMap\": \"#7E0028\",\n",
    "                 }\n",
    "\n",
    "plt.figure(figsize=(fig_width_10_ticks, fig_height))\n",
    "ax = sns.barplot(data=summary_df,\n",
    "                 x=\"Spatial Conservation Score\",\n",
    "                 y=\"dataset\",\n",
    "                 hue=\"model\",\n",
    "                 orient=\"h\",\n",
    "                 palette=model_palette)\n",
    "for i in range(summary_df[\"dataset\"].nunique()):\n",
    "    ax.axhline(0.5 + 1 * i, color='gray', linestyle='--', linewidth=2)\n",
    "\n",
    "new_labels = [label.get_text().replace(' ', '\\n') if i < 3 else label.get_text().replace(' H', '\\nH', -1).replace(' N', '\\nN', -1).replace(' CosMx', '\\nCosMx', -1) for i, label in enumerate(ax.get_yticklabels())]\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_yticklabels(new_labels)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(\"Spatial Conservation Score\", fontsize=fontsize)\n",
    "plt.yticks(fontsize=row_fontsize)\n",
    "plt.xticks([0., 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], fontsize=fontsize)\n",
    "plt.xlim(0., 1.0)\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{benchmarking_folder_path}/benchmarking_barplot_spatial_conservation_score.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c562dd-ff23-49cb-9199-5bbb1a9e00ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = summary_df[summary_df[\"dataset\"] == \"SlideSeqV2 Mouse Hippocampus\"]\n",
    "metrics_temp_df = temp_df.groupby(\"model\")[[\"Spatial Conservation Score\"]].mean()\n",
    "metrics_temp_df.iloc[2] / metrics_temp_df.iloc[1] # NC vs GraphST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a73de99-1100-4f80-9490-400564eed849",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = summary_df[summary_df[\"dataset\"] == \"seqFISH Mouse Organogenesis\"]\n",
    "metrics_temp_df = temp_df.groupby(\"model\")[[\"Spatial Conservation Score\"]].mean()\n",
    "metrics_temp_df.iloc[2] / metrics_temp_df.iloc[4] # NC vs STACI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db62c0e0-e054-428b-9c85-38a75d6156fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "model_palette = {\"NicheCompass\": \"#8C96C6\",\n",
    "                 \"NicheCompass Light\": \"#42B6C7\",\n",
    "                 \"STACI\": \"#FFD700\",\n",
    "                 \"DeepLinc\": \"#0E1C4A\",\n",
    "                 \"GraphST\": \"#D78FF8\",\n",
    "                 \"SageNet\": \"#F46AA2\",\n",
    "                 \"scVI\": \"#FE8B3B\",\n",
    "                 \"expiMap\": \"#7E0028\",\n",
    "                 }\n",
    "\n",
    "plt.figure(figsize=(fig_width_6_ticks, fig_height))\n",
    "ax = sns.barplot(data=summary_df,\n",
    "                 x=\"cnmi\",\n",
    "                 y=\"dataset\",\n",
    "                 hue=\"model\",\n",
    "                 orient=\"h\",\n",
    "                 palette=model_palette)\n",
    "for i in range(summary_df[\"dataset\"].nunique()):\n",
    "    ax.axhline(0.5 + 1 * i, color='gray', linestyle='--', linewidth=2)\n",
    "\n",
    "new_labels = [label.get_text().replace(' ', '\\n') if i < 3 else label.get_text().replace(' H', '\\nH', -1).replace(' N', '\\nN', -1).replace(' CosMx', '\\nCosMx', -1) for i, label in enumerate(ax.get_yticklabels())]\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_yticklabels(new_labels)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(\"CNMI\", fontsize=fontsize)\n",
    "plt.yticks(fontsize=fontsize)\n",
    "plt.xticks([0., 0.1, 0.2, 0.3, 0.4, 0.5], fontsize=fontsize)\n",
    "plt.xlim(0., 0.6)\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{benchmarking_folder_path}/benchmarking_barplot_cnmi.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8315f18c-1b56-48a0-ad41-342e30eb40a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "model_palette = {\"NicheCompass\": \"#8C96C6\",\n",
    "                 \"NicheCompass Light\": \"#42B6C7\",\n",
    "                 \"STACI\": \"#FFD700\",\n",
    "                 \"DeepLinc\": \"#0E1C4A\",\n",
    "                 \"GraphST\": \"#D78FF8\",\n",
    "                 \"SageNet\": \"#F46AA2\",\n",
    "                 \"scVI\": \"#FE8B3B\",\n",
    "                 \"expiMap\": \"#7E0028\",\n",
    "                 }\n",
    "\n",
    "plt.figure(figsize=(fig_width_2_ticks, fig_height))\n",
    "ax = sns.barplot(data=summary_df,\n",
    "                 x=\"nasw\",\n",
    "                 y=\"dataset\",\n",
    "                 hue=\"model\",\n",
    "                 orient=\"h\",\n",
    "                 palette=model_palette)\n",
    "for i in range(summary_df[\"dataset\"].nunique()):\n",
    "    ax.axhline(0.5 + 1 * i, color='gray', linestyle='--', linewidth=2)\n",
    "\n",
    "new_labels = [label.get_text().replace(' ', '\\n') if i < 3 else label.get_text().replace(' H', '\\nH', -1).replace(' N', '\\nN', -1).replace(' CosMx', '\\nCosMx', -1) for i, label in enumerate(ax.get_yticklabels())]\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_yticklabels(new_labels)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(\"NASW\", fontsize=fontsize)\n",
    "plt.yticks(fontsize=fontsize)\n",
    "plt.xticks([0.5, 0.6], fontsize=fontsize)\n",
    "plt.xlim(0.5, 0.7)\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{benchmarking_folder_path}/benchmarking_barplot_nasw.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf7aac5-b97d-486d-8be1-60290d99b22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = summary_df[summary_df[\"dataset\"] == \"SlideSeqV2 Mouse Hippocampus\"]\n",
    "metrics_temp_df = temp_df.groupby(\"model\")[[\"nasw\"]].mean()\n",
    "metrics_temp_df.iloc[2] / metrics_temp_df.iloc[1] # NC vs GraphST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48cab40-5723-4ea9-b0b3-59fc78db74e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = summary_df[summary_df[\"dataset\"] == \"seqFISH Mouse Organogenesis\"]\n",
    "metrics_temp_df = temp_df.groupby(\"model\")[[\"nasw\"]].mean()\n",
    "metrics_temp_df.iloc[2] / metrics_temp_df.iloc[4] # NC vs STACI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e056ef-e52c-4116-9a6e-900f6cee22fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "model_palette = {\"NicheCompass\": \"#8C96C6\",\n",
    "                 \"NicheCompass Light\": \"#42B6C7\",\n",
    "                 \"STACI\": \"#FFD700\",\n",
    "                 \"DeepLinc\": \"#0E1C4A\",\n",
    "                 \"GraphST\": \"#D78FF8\",\n",
    "                 \"SageNet\": \"#F46AA2\",\n",
    "                 \"scVI\": \"#FE8B3B\",\n",
    "                 \"expiMap\": \"#7E0028\",\n",
    "                 }\n",
    "\n",
    "plt.figure(figsize=(fig_width_7_ticks, 5))\n",
    "ax = sns.barplot(data=summary_df,\n",
    "                 x=\"Niche Coherence Score\",\n",
    "                 y=\"dataset\",\n",
    "                 hue=\"model\",\n",
    "                 orient=\"h\",\n",
    "                 palette=model_palette)\n",
    "for i in range(summary_df[\"dataset\"].nunique()):\n",
    "    ax.axhline(0.5 + 1 * i, color='gray', linestyle='--', linewidth=2)\n",
    "\n",
    "new_labels = [label.get_text().replace(' ', '\\n') if i < 3 else label.get_text().replace(' H', '\\nH', -1).replace(' N', '\\nN', -1).replace(' CosMx', '\\nCosMx', -1) for i, label in enumerate(ax.get_yticklabels())]\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_yticklabels(new_labels)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(\"Niche Coherence Score\", fontsize=fontsize)\n",
    "plt.yticks(fontsize=row_fontsize)\n",
    "plt.xticks([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7], fontsize=fontsize)\n",
    "plt.xlim(0.1, 0.8)\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{benchmarking_folder_path}/benchmarking_barplot_niche_coherence_score.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9ccfe0-6e68-4e5a-94ad-80e27ba5faf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = summary_df[summary_df[\"dataset\"] == \"SlideSeqV2 Mouse Hippocampus\"]\n",
    "metrics_temp_df = temp_df.groupby(\"model\")[[\"Niche Coherence Score\"]].mean()\n",
    "metrics_temp_df.iloc[2] / metrics_temp_df.iloc[1] # NC vs GraphST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68261152-9df8-445a-a8a2-eb45c075a27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = summary_df[summary_df[\"dataset\"] == \"seqFISH Mouse Organogenesis\"]\n",
    "metrics_temp_df = temp_df.groupby(\"model\")[[\"Niche Coherence Score\"]].mean()\n",
    "metrics_temp_df.iloc[2] / metrics_temp_df.iloc[4] # NC vs STACI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae744721-2649-4e0b-87e6-e00d28a6d534",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_palette = {\"NicheCompass\": \"#8C96C6\",\n",
    "                 \"NicheCompass Light\": \"#42B6C7\",\n",
    "                 \"STACI\": \"#FFD700\",\n",
    "                 \"DeepLinc\": \"#0E1C4A\",\n",
    "                 \"GraphST\": \"#D78FF8\",\n",
    "                 \"SageNet\": \"#F46AA2\",\n",
    "                 \"scVI\": \"#FE8B3B\",\n",
    "                 \"expiMap\": \"#7E0028\",\n",
    "                 }\n",
    "\n",
    "plt.figure(figsize=(fig_width_6_ticks, fig_height))\n",
    "ax = sns.barplot(data=summary_df,\n",
    "                 x=\"Overall Score\",\n",
    "                 y=\"dataset\",\n",
    "                 hue=\"model\",\n",
    "                 orient=\"h\",\n",
    "                 palette=model_palette)\n",
    "for i in range(summary_df[\"dataset\"].nunique()):\n",
    "    ax.axhline(0.5 + 1 * i, color='gray', linestyle='--', linewidth=2)\n",
    "\n",
    "new_labels = [label.get_text().replace(' ', '\\n') if i < 3 else label.get_text().replace(' H', '\\nH', -1).replace(' N', '\\nN', -1).replace(' CosMx', '\\nCosMx', -1) for i, label in enumerate(ax.get_yticklabels())]\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_yticklabels(new_labels)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(\"Overall Score\", fontsize=fontsize)\n",
    "plt.yticks(fontsize=fontsize)\n",
    "plt.xticks([0.2, 0.3, 0.4, 0.5, 0.6, 0.7], fontsize=fontsize)\n",
    "plt.xlim(0.2, 0.8)\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{benchmarking_folder_path}/benchmarking_barplot_overall_score.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81bc2d1-2e26-40d6-99a5-9c510e8fb9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = summary_df[summary_df[\"dataset\"] == \"SlideSeqV2 Mouse Hippocampus\"]\n",
    "metrics_temp_df = temp_df.groupby(\"model\")[[\"Overall Score\"]].mean()\n",
    "metrics_temp_df.iloc[2] / metrics_temp_df.iloc[1] # NC vs GraphST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04054b32-46e0-4411-bb88-9c4862f8ea7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = summary_df[summary_df[\"dataset\"] == \"seqFISH Mouse Organogenesis\"]\n",
    "metrics_temp_df = temp_df.groupby(\"model\")[[\"Overall Score\"]].mean()\n",
    "metrics_temp_df.iloc[2] / metrics_temp_df.iloc[4] # NC vs STACI"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a6184783-6c06-4349-ba4e-6df1aaac4759",
   "metadata": {},
   "source": [
    "# Plot table\n",
    "plot_metrics_table(\n",
    "    df=unrolled_df,\n",
    "    model_col=\"model\",\n",
    "    model_col_width=1.9,\n",
    "    group_col=\"dataset\",\n",
    "    metric_cols=metric_cols_single_sample, # metric_cols_single_sample,\n",
    "    metric_col_weights=metric_col_weights_single_sample, # metric_col_weights_single_sample,\n",
    "    metric_col_titles=[col.replace(\" \", \"\\n\") for col in metric_col_titles_single_sample],\n",
    "    metric_col_width=0.7, # 0.8,\n",
    "    aggregate_col_width=1.,\n",
    "    plot_width=30, # 32,\n",
    "    plot_height=8,\n",
    "    show=True,\n",
    "    save_dir=benchmarking_folder_path,\n",
    "    save_name=f\"benchmarking_metrics_all_datasets.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed2b7ca-7caf-4901-8141-509f9dd7f571",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
