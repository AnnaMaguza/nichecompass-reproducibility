{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "364a9ebc-3e3c-4645-9049-a34bd084c8a8",
   "metadata": {},
   "source": [
    "# expiMap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c55227-147e-417f-b0dd-bb0b7f322930",
   "metadata": {},
   "source": [
    "- **Creator**: Sebastian Birk (<sebastian.birk@helmholtz-munich.de>).\n",
    "- **Affiliation:** Helmholtz Munich, Institute of Computational Biology (ICB), Talavera-LÃ³pez Lab\n",
    "- **Date of Creation:** 05.01.2023\n",
    "- **Date of Last Modification:** 18.08.2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa669117-f347-4666-b112-8ea6669fd9e9",
   "metadata": {},
   "source": [
    "- The expiMap source code is available at https://github.com/theislab/scarches.\n",
    "- The corresponding preprint is \"Lotfollahi, M. et al. Biologically informed deep learning to infer gene program activity in single cells. bioRxiv 2022.02.05.479217 (2022) doi:10.1101/2022.02.05.479217\".\n",
    "- The workflow of this notebook follows the tutorial from https://scarches.readthedocs.io/en/latest/expimap_surgery_pipeline_basic.html.\n",
    "- We use a modified version of the NicheCompass gene program mask with only target genes as the gene program mask for expimap. The reasons are that it is relevant for cell communication, to improve comparability and since the expiMap method did not work well on this dataset with the reactome gene program used in the above cited tutorial.\n",
    "- The authors use raw counts as input to expiMap. Therefore, we also use raw counts (stored in adata.X)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7529cde5-be12-403b-a94c-07561774b86c",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faad87bd-fef5-4429-a175-d714c491ae76",
   "metadata": {},
   "source": [
    "### 1.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7f93960-c759-424f-8cb2-1d8698acae2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank: 0] Global seed set to 0\n",
      "/home/aih/sebastian.birk/.local/lib/python3.9/site-packages/flax/struct.py:136: FutureWarning: jax.tree_util.register_keypaths is deprecated, and will be removed in a future release. Please use `register_pytree_with_keys()` instead.\n",
      "  jax.tree_util.register_keypaths(data_clz, keypaths)\n",
      "/home/aih/sebastian.birk/.local/lib/python3.9/site-packages/flax/struct.py:136: FutureWarning: jax.tree_util.register_keypaths is deprecated, and will be removed in a future release. Please use `register_pytree_with_keys()` instead.\n",
      "  jax.tree_util.register_keypaths(data_clz, keypaths)\n",
      "WARNING:root:mvTCR is not installed. To use mvTCR models, please install it first using \"pip install mvtcr\"\n",
      "WARNING:root:multigrate is not installed. To use multigrate models, please install it first using \"pip install multigrate\".\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import gdown\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import scarches as sca\n",
    "import scipy.sparse as sp\n",
    "import squidpy as sq\n",
    "from nichecompass.utils import (add_gps_from_gp_dict_to_adata,\n",
    "                                extract_gp_dict_from_mebocost_es_interactions,\n",
    "                                extract_gp_dict_from_nichenet_lrt_interactions,\n",
    "                                extract_gp_dict_from_omnipath_lr_interactions,\n",
    "                                filter_and_combine_gp_dict_gps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b5efa5-2052-4986-8ae5-89cfab018515",
   "metadata": {},
   "source": [
    "### 1.2 Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5c8b48a-ed5e-48b5-8c5c-c1de11493aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"expimap\"\n",
    "latent_key = f\"{model_name}_latent\"\n",
    "leiden_resolution = 0.5 # used for Leiden clustering of latent space\n",
    "random_seed = 0 # used for Leiden clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28adc110-0f41-4a71-9838-dc7f0687809a",
   "metadata": {},
   "source": [
    "### 1.3 Run Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "334b87ca-3387-4ba9-8567-84bc4754ff0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.set_figure_params(figsize=(6, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ab6b302-1c0b-4937-8624-40629ada2e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get time of notebook execution for timestamping saved artifacts\n",
    "now = datetime.now()\n",
    "current_timestamp = now.strftime(\"%d%m%Y_%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85538952-006b-4b0b-a50c-fe7445ce22e2",
   "metadata": {},
   "source": [
    "### 1.4 Configure Paths and Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ddcc49c-ba22-4155-acd5-05b5b810e091",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder_path = \"../../datasets/srt_data/gold/\"\n",
    "benchmarking_folder_path = \"../../artifacts/single_sample_method_benchmarking\"\n",
    "figure_folder_path = f\"../../figures\"\n",
    "gp_data_folder_path = \"../../datasets/gp_data\" # gene program data\n",
    "ga_data_folder_path = \"../../datasets/ga_data\" # gene annotation data\n",
    "\n",
    "# Create required directories\n",
    "os.makedirs(gp_data_folder_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d974cd00-eafa-4432-b172-fafc4058a619",
   "metadata": {},
   "source": [
    "## 2. expiMap Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8791f7bf-e9f3-4384-9cef-2d6719d2d1fd",
   "metadata": {},
   "source": [
    "### 2.1 Prepare Gene Program Mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d721fdf-088a-4726-a10c-df7105c967bc",
   "metadata": {},
   "source": [
    "#### 2.1.1 Mouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dd3a336-6522-43f7-94c0-9eca6ddd489b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing the gene program mask...\n",
      "Number of gene programs before filtering and combining: 1818.\n",
      "Number of gene programs after filtering and combining: 1818.\n"
     ]
    }
   ],
   "source": [
    "species = \"mouse\"\n",
    "\n",
    "nichenet_lr_network_file_path = gp_data_folder_path + \\\n",
    "                                \"/nichenet_lr_network_v2_\" \\\n",
    "                                f\"{species}.csv\"\n",
    "nichenet_ligand_target_matrix_file_path = gp_data_folder_path + \\\n",
    "                                          \"/nichenet_ligand_target_matrix_\" \\\n",
    "                                          f\"v2_{species}.csv\"\n",
    "omnipath_lr_network_file_path = gp_data_folder_path + \\\n",
    "                                     \"/omnipath_lr_network.csv\"\n",
    "gene_orthologs_mapping_file_path = ga_data_folder_path + \\\n",
    "                                   \"/human_mouse_gene_orthologs.csv\"\n",
    "\n",
    "print(\"\\nPreparing the gene program mask...\")\n",
    "# OmniPath gene programs\n",
    "mouse_omnipath_gp_dict = extract_gp_dict_from_omnipath_lr_interactions(\n",
    "    species=species,\n",
    "    min_curation_effort=0,\n",
    "    load_from_disk=True,\n",
    "    save_to_disk=False,\n",
    "    lr_network_file_path=omnipath_lr_network_file_path,\n",
    "    gene_orthologs_mapping_file_path=gene_orthologs_mapping_file_path,\n",
    "    plot_gp_gene_count_distributions=False)\n",
    "\n",
    "# NicheNet gene programs\n",
    "mouse_nichenet_gp_dict = extract_gp_dict_from_nichenet_lrt_interactions(\n",
    "    species=species,\n",
    "    version=\"v2\",\n",
    "    keep_target_genes_ratio=1.0,\n",
    "    max_n_target_genes_per_gp=250,\n",
    "    load_from_disk=True,\n",
    "    save_to_disk=False,\n",
    "    lr_network_file_path=nichenet_lr_network_file_path,\n",
    "    ligand_target_matrix_file_path=nichenet_ligand_target_matrix_file_path,\n",
    "    gene_orthologs_mapping_file_path=gene_orthologs_mapping_file_path,\n",
    "    plot_gp_gene_count_distributions=False)\n",
    "\n",
    "# Combine gene programs into one dictionary\n",
    "mouse_combined_gp_dict = dict(mouse_omnipath_gp_dict)\n",
    "mouse_combined_gp_dict.update(mouse_nichenet_gp_dict)\n",
    "\n",
    "mouse_mebocost_gp_dict = extract_gp_dict_from_mebocost_es_interactions(\n",
    "    dir_path=f\"{gp_data_folder_path}/metabolite_enzyme_sensor_gps\",\n",
    "    species=species,\n",
    "    plot_gp_gene_count_distributions=False)\n",
    "\n",
    "mouse_combined_gp_dict.update(mouse_mebocost_gp_dict)\n",
    "    \n",
    "# Filter and combine gene programs\n",
    "mouse_combined_new_gp_dict = filter_and_combine_gp_dict_gps(\n",
    "    gp_dict=mouse_combined_gp_dict,\n",
    "    gp_filter_mode=\"subset\",\n",
    "    combine_overlap_gps=True,\n",
    "    overlap_thresh_source_genes=0.9,\n",
    "    overlap_thresh_target_genes=0.9,\n",
    "    overlap_thresh_genes=0.9,\n",
    "    verbose=False)\n",
    "\n",
    "print(\"Number of gene programs before filtering and combining: \"\n",
    "      f\"{len(mouse_combined_new_gp_dict)}.\")\n",
    "print(f\"Number of gene programs after filtering and combining: \"\n",
    "      f\"{len(mouse_combined_new_gp_dict)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69401d81-1893-4a20-a70b-6623778bb797",
   "metadata": {},
   "source": [
    "#### 2.1.2 Human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9460b8e-9247-44f9-9d85-54cb40c0f851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing the gene program mask...\n",
      "Number of gene programs before filtering and combining: 1691.\n",
      "Number of gene programs after filtering and combining: 1691.\n"
     ]
    }
   ],
   "source": [
    "species = \"human\"\n",
    "\n",
    "nichenet_lr_network_file_path = gp_data_folder_path + \\\n",
    "                                \"/nichenet_lr_network_v2_\" \\\n",
    "                                f\"{species}.csv\"\n",
    "nichenet_ligand_target_matrix_file_path = gp_data_folder_path + \\\n",
    "                                          \"/nichenet_ligand_target_matrix_\" \\\n",
    "                                          f\"v2_{species}.csv\"\n",
    "omnipath_lr_network_file_path = gp_data_folder_path + \\\n",
    "                                     \"/omnipath_lr_network.csv\"\n",
    "gene_orthologs_mapping_file_path = ga_data_folder_path + \\\n",
    "                                   \"/human_mouse_gene_orthologs.csv\"\n",
    "\n",
    "print(\"\\nPreparing the gene program mask...\")\n",
    "# OmniPath gene programs\n",
    "human_omnipath_gp_dict = extract_gp_dict_from_omnipath_lr_interactions(\n",
    "    species=species,\n",
    "    min_curation_effort=0,\n",
    "    load_from_disk=True,\n",
    "    save_to_disk=False,\n",
    "    lr_network_file_path=omnipath_lr_network_file_path,\n",
    "    gene_orthologs_mapping_file_path=gene_orthologs_mapping_file_path,\n",
    "    plot_gp_gene_count_distributions=False)\n",
    "\n",
    "# NicheNet gene programs\n",
    "human_nichenet_gp_dict = extract_gp_dict_from_nichenet_lrt_interactions(\n",
    "    species=species,\n",
    "    version=\"v2\",\n",
    "    keep_target_genes_ratio=1.0,\n",
    "    max_n_target_genes_per_gp=250,\n",
    "    load_from_disk=True,\n",
    "    save_to_disk=False,\n",
    "    lr_network_file_path=nichenet_lr_network_file_path,\n",
    "    ligand_target_matrix_file_path=nichenet_ligand_target_matrix_file_path,\n",
    "    gene_orthologs_mapping_file_path=gene_orthologs_mapping_file_path,\n",
    "    plot_gp_gene_count_distributions=False)\n",
    "\n",
    "# Combine gene programs into one dictionary\n",
    "human_combined_gp_dict = dict(human_omnipath_gp_dict)\n",
    "human_combined_gp_dict.update(human_nichenet_gp_dict)\n",
    "\n",
    "human_mebocost_gp_dict = extract_gp_dict_from_mebocost_es_interactions(\n",
    "    dir_path=f\"{gp_data_folder_path}/metabolite_enzyme_sensor_gps\",\n",
    "    species=species,\n",
    "    plot_gp_gene_count_distributions=False)\n",
    "\n",
    "human_combined_gp_dict.update(human_mebocost_gp_dict)\n",
    "    \n",
    "# Filter and combine gene programs\n",
    "human_combined_new_gp_dict = filter_and_combine_gp_dict_gps(\n",
    "    gp_dict=human_combined_gp_dict,\n",
    "    gp_filter_mode=\"subset\",\n",
    "    combine_overlap_gps=True,\n",
    "    overlap_thresh_source_genes=0.9,\n",
    "    overlap_thresh_target_genes=0.9,\n",
    "    overlap_thresh_genes=0.9,\n",
    "    verbose=False)\n",
    "\n",
    "print(\"Number of gene programs before filtering and combining: \"\n",
    "      f\"{len(human_combined_new_gp_dict)}.\")\n",
    "print(f\"Number of gene programs after filtering and combining: \"\n",
    "      f\"{len(human_combined_new_gp_dict)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df82c18e-4444-4e82-88d9-afc843f5e480",
   "metadata": {},
   "source": [
    "### 2.2 Define Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ea39b0f-9c9a-459a-ba2e-c843802a8e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_expimap_models(dataset,\n",
    "                         gp_dict,\n",
    "                         cell_type_key,\n",
    "                         adata_new=None,\n",
    "                         n_start_run=1,\n",
    "                         n_end_run=8,\n",
    "                         n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16],\n",
    "                         plot_latent_umaps: bool=False):\n",
    "    \n",
    "    # Configure figure folder path\n",
    "    dataset_figure_folder_path = f\"{figure_folder_path}/{dataset}/method_benchmarking/expimap/{current_timestamp}\"\n",
    "    os.makedirs(dataset_figure_folder_path, exist_ok=True)\n",
    "    \n",
    "    # Create new adata to store results from training runs in storage-efficient way\n",
    "    if adata_new is None:\n",
    "        adata_original = sc.read_h5ad(data_folder_path + f\"{dataset}.h5ad\")\n",
    "        adata_new = sc.AnnData(sp.csr_matrix(\n",
    "            (adata_original.shape[0], adata_original.shape[1]),\n",
    "            dtype=np.float32))\n",
    "        adata_new.var_names = adata_original.var_names\n",
    "        adata_new.obs_names = adata_original.obs_names\n",
    "        adata_new.obs[\"cell_type\"] = adata_original.obs[cell_type_key].values\n",
    "        adata_new.obsm[\"spatial\"] = adata_original.obsm[\"spatial\"]\n",
    "        del(adata_original)\n",
    "    \n",
    "    model_seeds = list(range(10))\n",
    "    for run_number, n_neighbors in zip(np.arange(n_start_run, n_end_run+1), n_neighbor_list):\n",
    "        # n_neighbors is here only used for the latent neighbor graph construction used for\n",
    "        # UMAP generation and clustering as expiMap is not a spatial method\n",
    "        \n",
    "        # Load data\n",
    "        adata = sc.read_h5ad(data_folder_path + f\"{dataset}.h5ad\")\n",
    "        \n",
    "        # Store raw counts in optimized format in adata.X\n",
    "        adata.layers[\"counts\"] = adata.layers[\"counts\"].tocsr()\n",
    "        adata.X = adata.layers[\"counts\"]\n",
    "        \n",
    "        adata.obs[\"batch\"] == \"batch1\"  \n",
    "        \n",
    "        # Add the gene program dictionary as binary masks to the adata for model training\n",
    "        # Use only target genes from the NicheCompass gene program mask\n",
    "        add_gps_from_gp_dict_to_adata(\n",
    "            gp_dict=gp_dict,\n",
    "            adata=adata,\n",
    "            genes_uppercase=True,\n",
    "            gp_targets_mask_key=\"I\",\n",
    "            gp_sources_mask_key=\"_\",\n",
    "            gp_names_key=\"terms\",\n",
    "            min_genes_per_gp=1,\n",
    "            min_source_genes_per_gp=0,\n",
    "            min_target_genes_per_gp=0,\n",
    "            max_genes_per_gp=None,\n",
    "            max_source_genes_per_gp=None,\n",
    "            max_target_genes_per_gp=None)\n",
    "\n",
    "        # Determine dimensionality of hidden encoder\n",
    "        n_hidden_encoder = len(adata.uns[\"terms\"])\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Initialize model\n",
    "        intr_cvae = sca.models.EXPIMAP(adata=adata,\n",
    "                                       condition_key=\"batch\",\n",
    "                                       hidden_layer_sizes=[256, 256, 256],\n",
    "                                       recon_loss=\"nb\")\n",
    "\n",
    "        # Train model\n",
    "        early_stopping_kwargs = {\n",
    "            \"early_stopping_metric\": \"val_unweighted_loss\",\n",
    "            \"threshold\": 0,\n",
    "            \"patience\": 50,\n",
    "            \"reduce_lr\": True,\n",
    "            \"lr_patience\": 13,\n",
    "            \"lr_factor\": 0.1}\n",
    "        intr_cvae.train(\n",
    "            n_epochs=400,\n",
    "            alpha_epoch_anneal=100,\n",
    "            alpha=0.7,\n",
    "            alpha_kl=0.5,\n",
    "            weight_decay=0.,\n",
    "            early_stopping_kwargs=early_stopping_kwargs,\n",
    "            use_early_stopping=True,\n",
    "            monitor_only_val=False,\n",
    "            seed=model_seeds[run_number-1])\n",
    "\n",
    "        # Store latent representation\n",
    "        adata.obsm[latent_key] = intr_cvae.get_latent(mean=False, only_active=True)\n",
    "        \n",
    "        # Measure time for model training\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        hours, rem = divmod(elapsed_time, 3600)\n",
    "        minutes, seconds = divmod(rem, 60)\n",
    "        print(f\"Duration of model training in run {run_number}: {int(hours)} hours, {int(minutes)} minutes and {int(seconds)} seconds.\")\n",
    "        adata_new.uns[f\"{model_name}_model_training_duration_run{run_number}\"] = (\n",
    "            elapsed_time)\n",
    "\n",
    "        if plot_latent_umaps:\n",
    "            # Use expiMap latent space for UMAP generation\n",
    "            sc.pp.neighbors(adata,\n",
    "                            use_rep=latent_key,\n",
    "                            n_neighbors=n_neighbors)\n",
    "            sc.tl.umap(adata)\n",
    "            fig = sc.pl.umap(adata,\n",
    "                             color=[cell_type_key],\n",
    "                             title=\"Latent Space with Cell Types: expiMap\",\n",
    "                             return_fig=True)\n",
    "            fig.savefig(f\"{dataset_figure_folder_path}/latent_{model_name}\"\n",
    "                        f\"_cell_types_run{run_number}.png\",\n",
    "                        bbox_inches=\"tight\")\n",
    "\n",
    "            # Compute latent Leiden clustering\n",
    "            sc.tl.leiden(adata=adata,\n",
    "                         resolution=leiden_resolution,\n",
    "                         random_state=random_seed,\n",
    "                         key_added=f\"latent_{model_name}_leiden_{str(leiden_resolution)}\")\n",
    "\n",
    "            # Create subplot of latent Leiden cluster annotations in physical and latent space\n",
    "            fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(6, 12))\n",
    "            title = fig.suptitle(t=\"Latent and Physical Space with Leiden Clusters: expiMap\")\n",
    "            sc.pl.umap(adata=adata,\n",
    "                       color=[f\"latent_{model_name}_leiden_{str(leiden_resolution)}\"],\n",
    "                       title=f\"Latent Space with Leiden Clusters\",\n",
    "                       ax=axs[0],\n",
    "                       show=False)\n",
    "            sq.pl.spatial_scatter(adata=adata,\n",
    "                                  color=[f\"latent_{model_name}_leiden_{str(leiden_resolution)}\"],\n",
    "                                  title=f\"Physical Space with Leiden Clusters\",\n",
    "                                  shape=None,\n",
    "                                  ax=axs[1])\n",
    "\n",
    "            # Create and position shared legend\n",
    "            handles, labels = axs[0].get_legend_handles_labels()\n",
    "            lgd = fig.legend(handles, labels, bbox_to_anchor=(1.25, 0.9185))\n",
    "            axs[0].get_legend().remove()\n",
    "            axs[1].get_legend().remove()\n",
    "\n",
    "            # Adjust, save and display plot\n",
    "            plt.subplots_adjust(wspace=0, hspace=0.2)\n",
    "            fig.savefig(f\"{dataset_figure_folder_path}/latent_physical_comparison_\"\n",
    "                        f\"{model_name}_run{run_number}.png\",\n",
    "                        bbox_extra_artists=(lgd, title),\n",
    "                        bbox_inches=\"tight\")\n",
    "            plt.show()\n",
    "\n",
    "        # Store latent representation\n",
    "        adata_new.obsm[latent_key + f\"_run{run_number}\"] = adata.obsm[latent_key]\n",
    "\n",
    "        # Store intermediate adata to disk\n",
    "        adata_new.write(f\"{benchmarking_folder_path}/{dataset}_{model_name}4.h5ad\")\n",
    "\n",
    "    # Store final adata to disk\n",
    "    adata_new.write(f\"{benchmarking_folder_path}/{dataset}_{model_name}4.h5ad\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f25415-e54e-4d2e-a6e3-bd6f3eef0d72",
   "metadata": {},
   "source": [
    "### 2.3 Train Models on Benchmarking Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4db49c6-c78d-472f-9d4a-9fe22a948623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INITIALIZING NEW NETWORK..............\n",
      "Encoder Architecture:\n",
      "\tInput Layer in, out and cond: 347 256 1\n",
      "\tHidden Layer 1 in/out: 256 256\n",
      "\tHidden Layer 2 in/out: 256 256\n",
      "\tMean/Var Layer in/out: 256 1378\n",
      "Decoder Architecture:\n",
      "\tMasked linear layer in, ext_m, ext, cond, out:  1378 0 0 1 347\n",
      "\twith hard mask.\n",
      "Last Decoder layer: softmax\n",
      "Preparing (367335, 347)\n",
      "Instantiating dataset\n",
      "Init the group lasso proximal operator for the main terms.\n",
      " |âââââ---------------| 26.5%  - epoch_loss: 355.1935886999 - epoch_recon_loss: 324.3994851638 - epoch_kl_loss: 61.5882069776 - val_loss: 354.3012385883 - val_recon_loss: 325.2138209326 - val_kl_loss: 58.174834527271945"
     ]
    }
   ],
   "source": [
    "train_expimap_models(dataset=\"vizgen_merfish_mouse_liver\",\n",
    "                     gp_dict=mouse_combined_new_gp_dict,\n",
    "                     cell_type_key=\"Cell_Type\",\n",
    "                     adata_new=None,\n",
    "                     n_start_run=4,\n",
    "                     n_end_run=4,\n",
    "                     n_neighbor_list=[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7cd035-1727-4316-98f2-d8652f717699",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_expimap_models(dataset=\"seqfish_mouse_organogenesis_embryo2\",\n",
    "                     gp_dict=mouse_combined_new_gp_dict,\n",
    "                     cell_type_key=\"celltype_mapped_refined\",\n",
    "                     adata_new=None,\n",
    "                     n_start_run=1,\n",
    "                     n_end_run=8,\n",
    "                     n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1659054d-fa4b-4e42-807f-1ec2e0fba87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subsample_pct in [50, 25, 10, 5, 1]:\n",
    "    train_expimap_models(dataset=f\"seqfish_mouse_organogenesis_subsample_{subsample_pct}pct_embryo2\",\n",
    "                         gp_dict=mouse_combined_new_gp_dict,\n",
    "                         cell_type_key=\"celltype_mapped_refined\",\n",
    "                         adata_new=None,\n",
    "                         n_start_run=1,\n",
    "                         n_end_run=8,\n",
    "                         n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a61a165-ad03-4422-b383-1b2d79218bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_new = sc.read_h5ad(\"../../artifacts/single_sample_method_benchmarking/slideseqv2_mouse_hippocampus_expimap.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994fb0fe-2d2b-42cc-99b9-ac7459c60c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace/projects/nichecompass-reproducibility/artifacts/single_sample_method_benchmarking/.h5ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0db492dc-56da-4ae1-806d-dea051e5eb8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs Ã n_vars = 41786 Ã 4000\n",
       "    obs: 'cell_type'\n",
       "    uns: 'expimap_model_training_duration_run1', 'expimap_model_training_duration_run2', 'expimap_model_training_duration_run3', 'expimap_model_training_duration_run4'\n",
       "    obsm: 'expimap_latent_run1', 'expimap_latent_run2', 'expimap_latent_run3', 'expimap_latent_run4', 'spatial'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50aa8428-5193-46e3-8eba-75a991ca2a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INITIALIZING NEW NETWORK..............\n",
      "Encoder Architecture:\n",
      "\tInput Layer in, out and cond: 4000 256 1\n",
      "\tHidden Layer 1 in/out: 256 256\n",
      "\tHidden Layer 2 in/out: 256 256\n",
      "\tMean/Var Layer in/out: 256 1519\n",
      "Decoder Architecture:\n",
      "\tMasked linear layer in, ext_m, ext, cond, out:  1519 0 0 1 4000\n",
      "\twith hard mask.\n",
      "Last Decoder layer: softmax\n",
      "Preparing (41786, 4000)\n",
      "Instantiating dataset\n",
      "Init the group lasso proximal operator for the main terms.\n",
      " |âââââââââââââââ-----| 76.5%  - epoch_loss: 248.2416426989 - epoch_recon_loss: 237.7827648760 - epoch_kl_loss: 20.9177552437 - val_loss: 187.7813609730 - val_recon_loss: 176.4809537945 - val_kl_loss: 22.60081429919223\n",
      "ADJUSTED LR\n",
      " |ââââââââââââââââ----| 81.5%  - epoch_loss: 248.2543669201 - epoch_recon_loss: 237.7391166428 - epoch_kl_loss: 21.0304999189 - val_loss: 187.6399536133 - val_recon_loss: 176.3549083363 - val_kl_loss: 22.5700888200\n",
      "ADJUSTED LR\n",
      " |âââââââââââââââââ---| 87.2%  - epoch_loss: 246.7987417623 - epoch_recon_loss: 236.3232966832 - epoch_kl_loss: 20.9508900026 - val_loss: 187.6157319040 - val_recon_loss: 176.3190275250 - val_kl_loss: 22.5934080644\n",
      "ADJUSTED LR\n",
      " |ââââââââââââââââââ--| 90.5%  - epoch_loss: 247.5522546055 - epoch_recon_loss: 237.0374345325 - epoch_kl_loss: 21.0296398669 - val_loss: 187.6599259810 - val_recon_loss: 176.3536409320 - val_kl_loss: 22.6125703291\n",
      "ADJUSTED LR\n",
      " |âââââââââââââââââââ-| 96.2%  - epoch_loss: 248.4185516461 - epoch_recon_loss: 237.8898707799 - epoch_kl_loss: 21.0573625824 - val_loss: 187.6956505053 - val_recon_loss: 176.3933910023 - val_kl_loss: 22.6045202197\n",
      "ADJUSTED LR\n",
      " |âââââââââââââââââââ-| 99.5%  - epoch_loss: 248.1267519062 - epoch_recon_loss: 237.6406293078 - epoch_kl_loss: 20.9722436529 - val_loss: 187.6005484841 - val_recon_loss: 176.2997755571 - val_kl_loss: 22.6015452183\n",
      "ADJUSTED LR\n",
      " |ââââââââââââââââââââ| 100.0%  - epoch_loss: 247.9923464198 - epoch_recon_loss: 237.4936971340 - epoch_kl_loss: 20.9972994668 - val_loss: 187.6800685073 - val_recon_loss: 176.3734320438 - val_kl_loss: 22.6132748344\n",
      "Saving best state of network...\n",
      "Best State was in Epoch 370\n",
      "Duration of model training in run 5: 0 hours, 42 minutes and 50 seconds.\n",
      "\n",
      "INITIALIZING NEW NETWORK..............\n",
      "Encoder Architecture:\n",
      "\tInput Layer in, out and cond: 4000 256 1\n",
      "\tHidden Layer 1 in/out: 256 256\n",
      "\tHidden Layer 2 in/out: 256 256\n",
      "\tMean/Var Layer in/out: 256 1519\n",
      "Decoder Architecture:\n",
      "\tMasked linear layer in, ext_m, ext, cond, out:  1519 0 0 1 4000\n",
      "\twith hard mask.\n",
      "Last Decoder layer: softmax\n",
      "Preparing (41786, 4000)\n",
      "Instantiating dataset\n",
      "Init the group lasso proximal operator for the main terms.\n",
      " |âââââââââââââââââââ-| 96.2%  - epoch_loss: 247.5298003631 - epoch_recon_loss: 237.3378416827 - epoch_kl_loss: 20.3839178734 - val_loss: 186.6409213904 - val_recon_loss: 175.5214501583 - val_kl_loss: 22.23894315786495\n",
      "ADJUSTED LR\n",
      " |âââââââââââââââââââ-| 99.5%  - epoch_loss: 247.1460326318 - epoch_recon_loss: 236.9475210800 - epoch_kl_loss: 20.3970237135 - val_loss: 186.5828760320 - val_recon_loss: 175.4428146825 - val_kl_loss: 22.2801225258\n",
      "ADJUSTED LR\n",
      " |ââââââââââââââââââââ| 100.0%  - epoch_loss: 248.0129491066 - epoch_recon_loss: 237.8012740466 - epoch_kl_loss: 20.4233494778 - val_loss: 186.3275340687 - val_recon_loss: 175.2146574078 - val_kl_loss: 22.2257548246\n",
      "Saving best state of network...\n",
      "Best State was in Epoch 370\n",
      "Duration of model training in run 6: 0 hours, 42 minutes and 48 seconds.\n",
      "\n",
      "INITIALIZING NEW NETWORK..............\n",
      "Encoder Architecture:\n",
      "\tInput Layer in, out and cond: 4000 256 1\n",
      "\tHidden Layer 1 in/out: 256 256\n",
      "\tHidden Layer 2 in/out: 256 256\n",
      "\tMean/Var Layer in/out: 256 1519\n",
      "Decoder Architecture:\n",
      "\tMasked linear layer in, ext_m, ext, cond, out:  1519 0 0 1 4000\n",
      "\twith hard mask.\n",
      "Last Decoder layer: softmax\n",
      "Preparing (41786, 4000)\n",
      "Instantiating dataset\n",
      "Init the group lasso proximal operator for the main terms.\n",
      " |ââââââââââââââââââ--| 93.2%  - epoch_loss: 248.6033791782 - epoch_recon_loss: 238.2402741828 - epoch_kl_loss: 20.7262101271 - val_loss: 186.4460389108 - val_recon_loss: 175.2388795795 - val_kl_loss: 22.41431970314413\n",
      "ADJUSTED LR\n",
      " |ââââââââââââââââââââ| 100.0%  - epoch_loss: 247.2339713687 - epoch_recon_loss: 236.8962221730 - epoch_kl_loss: 20.6754998707 - val_loss: 186.3889511571 - val_recon_loss: 175.1836857651 - val_kl_loss: 22.4105272582\n",
      "Saving best state of network...\n",
      "Best State was in Epoch 395\n",
      "Duration of model training in run 7: 0 hours, 43 minutes and 41 seconds.\n",
      "\n",
      "INITIALIZING NEW NETWORK..............\n",
      "Encoder Architecture:\n",
      "\tInput Layer in, out and cond: 4000 256 1\n",
      "\tHidden Layer 1 in/out: 256 256\n",
      "\tHidden Layer 2 in/out: 256 256\n",
      "\tMean/Var Layer in/out: 256 1519\n",
      "Decoder Architecture:\n",
      "\tMasked linear layer in, ext_m, ext, cond, out:  1519 0 0 1 4000\n",
      "\twith hard mask.\n",
      "Last Decoder layer: softmax\n",
      "Preparing (41786, 4000)\n",
      "Instantiating dataset\n",
      "Init the group lasso proximal operator for the main terms.\n",
      " |ââââââââââââââââ----| 81.2%  - epoch_loss: 247.7341653733 - epoch_recon_loss: 237.3621603518 - epoch_kl_loss: 20.7440104387 - val_loss: 187.1806229100 - val_recon_loss: 176.2424552224 - val_kl_loss: 21.87633739827107\n",
      "ADJUSTED LR\n",
      " |âââââââââââââââââ---| 87.5%  - epoch_loss: 247.3232848498 - epoch_recon_loss: 236.9624355083 - epoch_kl_loss: 20.7216992670 - val_loss: 187.0004855069 - val_recon_loss: 175.9861177387 - val_kl_loss: 22.0287351897\n",
      "ADJUSTED LR\n",
      " |ââââââââââââââââââ--| 94.0%  - epoch_loss: 246.7526072288 - epoch_recon_loss: 236.3651848099 - epoch_kl_loss: 20.7748454282 - val_loss: 186.8707210656 - val_recon_loss: 175.8189993194 - val_kl_loss: 22.1034464403\n",
      "ADJUSTED LR\n",
      " |âââââââââââââââââââ-| 97.2%  - epoch_loss: 248.0283393600 - epoch_recon_loss: 237.6242304173 - epoch_kl_loss: 20.8082175352 - val_loss: 186.9308749112 - val_recon_loss: 175.8801639441 - val_kl_loss: 22.1014216452\n",
      "ADJUSTED LR\n",
      " |ââââââââââââââââââââ| 100.0%  - epoch_loss: 248.6457149999 - epoch_recon_loss: 238.2603423449 - epoch_kl_loss: 20.7707447454 - val_loss: 186.9179849336 - val_recon_loss: 175.8738130512 - val_kl_loss: 22.0883446318\n",
      "Saving best state of network...\n",
      "Best State was in Epoch 361\n",
      "Duration of model training in run 8: 0 hours, 42 minutes and 59 seconds.\n"
     ]
    }
   ],
   "source": [
    "train_expimap_models(dataset=\"slideseqv2_mouse_hippocampus\",\n",
    "                     cell_type_key=\"cell_type\",\n",
    "                     gp_dict=mouse_combined_new_gp_dict,\n",
    "                     adata_new=adata_new,\n",
    "                     n_start_run=5,\n",
    "                     n_end_run=8,\n",
    "                     n_neighbor_list=[12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0716d8a-fdc9-4308-950d-decc145cef40",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_expimap_models(dataset=\"nanostring_cosmx_human_nsclc_batch5\",\n",
    "                     gp_dict=human_combined_new_gp_dict,\n",
    "                     cell_type_key=\"cell_type\",\n",
    "                     adata_new=None,\n",
    "                     n_start_run=1,\n",
    "                     n_end_run=8,\n",
    "                     n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b3d1af-a005-4790-bbd9-65e7c286ab1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subsample_pct in [50, 25, 10, 5, 1]:\n",
    "    train_expimap_models(dataset=f\"nanostring_cosmx_human_nsclc_subsample_{subsample_pct}pct_batch5\",\n",
    "                         gp_dict=human_combined_new_gp_dict,\n",
    "                         cell_type_key=\"cell_type\",\n",
    "                         adata_new=None,\n",
    "                         n_start_run=1,\n",
    "                         n_end_run=8,\n",
    "                         n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c63c2f3-38ca-476d-bf2e-cac68c30f9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INITIALIZING NEW NETWORK..............\n",
      "Encoder Architecture:\n",
      "\tInput Layer in, out and cond: 347 256 1\n",
      "\tHidden Layer 1 in/out: 256 256\n",
      "\tHidden Layer 2 in/out: 256 256\n",
      "\tMean/Var Layer in/out: 256 1378\n",
      "Decoder Architecture:\n",
      "\tMasked linear layer in, ext_m, ext, cond, out:  1378 0 0 1 347\n",
      "\twith hard mask.\n",
      "Last Decoder layer: softmax\n",
      "Preparing (367335, 347)\n",
      "Instantiating dataset\n",
      "Init the group lasso proximal operator for the main terms.\n",
      " |--------------------| 2.0%  - epoch_loss: 321.5184510010 - epoch_recon_loss: 309.3502147998 - epoch_kl_loss: 347.6638874286 - val_loss: 317.9892396296 - val_recon_loss: 306.5904143330 - val_kl_loss: 325.68070542601245"
     ]
    }
   ],
   "source": [
    "train_expimap_models(dataset=\"vizgen_merfish_mouse_liver\",\n",
    "                     gp_dict=mouse_combined_new_gp_dict,\n",
    "                     cell_type_key=\"Cell_Type\",\n",
    "                     adata_new=None,\n",
    "                     n_start_run=1,\n",
    "                     n_end_run=8,\n",
    "                     n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2bfa53-80b3-4ba3-8da4-47b06443e731",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subsample_pct in [50, 25, 10, 5, 1]:\n",
    "    train_expimap_models(dataset=f\"vizgen_merfish_mouse_liver_subsample_{subsample_pct}pct\",\n",
    "                         cell_type_key=\"Cell_Type\",\n",
    "                         gp_dict=mouse_combined_new_gp_dict,\n",
    "                         adata_new=None,\n",
    "                         n_start_run=1,\n",
    "                         n_end_run=8,\n",
    "                         n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167e90f9-a124-4180-a142-f295f4ca7128",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_expimap_models(dataset=\"slideseqv2_mouse_hippocampus\",\n",
    "                     cell_type_key=\"cell_type\",\n",
    "                     gp_dict=mouse_combined_new_gp_dict,\n",
    "                     adata_new=None,\n",
    "                     n_start_run=1,\n",
    "                     n_end_run=8,\n",
    "                     n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f389a8-62e6-4d1f-bcb6-2ded4e4d346c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subsample_pct in [50, 25, 10, 5, 1]:\n",
    "    train_expimap_models(dataset=f\"slideseqv2_mouse_hippocampus_subsample_{subsample_pct}pct\",\n",
    "                         cell_type_key=\"cell_type\",\n",
    "                         gp_dict=mouse_combined_new_gp_dict,\n",
    "                         adata_new=None,\n",
    "                         n_start_run=1,\n",
    "                         n_end_run=8,\n",
    "                         n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6930d44-724c-41bf-b3a1-f2ee1e5981c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INITIALIZING NEW NETWORK..............\n",
      "Encoder Architecture:\n",
      "\tInput Layer in, out and cond: 4000 256 1\n",
      "\tHidden Layer 1 in/out: 256 256\n",
      "\tHidden Layer 2 in/out: 256 256\n",
      "\tMean/Var Layer in/out: 256 1519\n",
      "Decoder Architecture:\n",
      "\tMasked linear layer in, ext_m, ext, cond, out:  1519 0 0 1 4000\n",
      "\twith hard mask.\n",
      "Last Decoder layer: softmax\n",
      "Preparing (4200, 4000)\n",
      "Instantiating dataset\n",
      "Init the group lasso proximal operator for the main terms.\n",
      " |ââââââââ------------| 44.2%  - epoch_loss: 250.4808059692 - epoch_recon_loss: 239.9593470256 - epoch_kl_loss: 21.0429208120 - val_loss: 210.9680557251 - val_recon_loss: 202.0970153809 - val_kl_loss: 17.7420668602451\n",
      "ADJUSTED LR\n",
      " |ââââââââââ----------| 53.2%  - epoch_loss: 253.1793116252 - epoch_recon_loss: 242.8261973063 - epoch_kl_loss: 20.7062323888 - val_loss: 211.7546730042 - val_recon_loss: 202.9318389893 - val_kl_loss: 17.6456756592\n",
      "ADJUSTED LR\n",
      " |âââââââââââ---------| 56.5%  - epoch_loss: 250.3492121379 - epoch_recon_loss: 239.8701512655 - epoch_kl_loss: 20.9581191381 - val_loss: 209.4955139160 - val_recon_loss: 200.5841255188 - val_kl_loss: 17.8227739334\n",
      "ADJUSTED LR\n",
      " |ââââââââââââ--------| 60.8%  - epoch_loss: 252.4460383097 - epoch_recon_loss: 242.0518035889 - epoch_kl_loss: 20.7884708405 - val_loss: 214.0494041443 - val_recon_loss: 205.3173065186 - val_kl_loss: 17.4642000198\n",
      "ADJUSTED LR\n",
      " |ââââââââââââ--------| 64.0%  - epoch_loss: 248.9351811727 - epoch_recon_loss: 238.5394892375 - epoch_kl_loss: 20.7913810094 - val_loss: 211.4111557007 - val_recon_loss: 202.5878257751 - val_kl_loss: 17.6466603279\n",
      "ADJUSTED LR\n",
      " |âââââââââââââ-------| 67.2%  - epoch_loss: 249.2079920451 - epoch_recon_loss: 238.7780685425 - epoch_kl_loss: 20.8598479589 - val_loss: 210.0970687866 - val_recon_loss: 201.3379745483 - val_kl_loss: 17.5181946754\n",
      "ADJUSTED LR\n",
      " |ââââââââââââââ------| 70.0%  - epoch_loss: 251.8583867391 - epoch_recon_loss: 241.3667790731 - epoch_kl_loss: 20.9832138062 - val_loss: 212.7227210999 - val_recon_loss: 203.8436927795 - val_kl_loss: 17.7580499649\n",
      "Stopping early: no improvement of more than 0 nats in 50 epochs\n",
      "If the early stopping criterion is too strong, please instantiate it with different parameters in the train method.\n",
      "Saving best state of network...\n",
      "Best State was in Epoch 228\n",
      "Duration of model training in run 1: 0 hours, 2 minutes and 25 seconds.\n",
      "\n",
      "INITIALIZING NEW NETWORK..............\n",
      "Encoder Architecture:\n",
      "\tInput Layer in, out and cond: 4000 256 1\n",
      "\tHidden Layer 1 in/out: 256 256\n",
      "\tHidden Layer 2 in/out: 256 256\n",
      "\tMean/Var Layer in/out: 256 1519\n",
      "Decoder Architecture:\n",
      "\tMasked linear layer in, ext_m, ext, cond, out:  1519 0 0 1 4000\n",
      "\twith hard mask.\n",
      "Last Decoder layer: softmax\n",
      "Preparing (4200, 4000)\n",
      "Instantiating dataset\n",
      "Init the group lasso proximal operator for the main terms.\n",
      " |ââââââââ------------| 43.8%  - epoch_loss: 251.8982849121 - epoch_recon_loss: 241.4566762288 - epoch_kl_loss: 20.8832181295 - val_loss: 215.5141410828 - val_recon_loss: 206.6234092712 - val_kl_loss: 17.7814579010845\n",
      "ADJUSTED LR\n",
      " |ââââââââââ----------| 50.5%  - epoch_loss: 253.0416539510 - epoch_recon_loss: 242.6150533040 - epoch_kl_loss: 20.8532009125 - val_loss: 211.5774078369 - val_recon_loss: 202.5166816711 - val_kl_loss: 18.1214542389\n",
      "ADJUSTED LR\n",
      " |âââââââââââ---------| 55.2%  - epoch_loss: 249.8577311198 - epoch_recon_loss: 239.3963623047 - epoch_kl_loss: 20.9227387110 - val_loss: 213.6907424927 - val_recon_loss: 204.7877922058 - val_kl_loss: 17.8059039116\n",
      "ADJUSTED LR\n",
      " |âââââââââââ---------| 58.5%  - epoch_loss: 248.5521097819 - epoch_recon_loss: 238.1413920085 - epoch_kl_loss: 20.8214348475 - val_loss: 211.0581359863 - val_recon_loss: 202.0071640015 - val_kl_loss: 18.1019425392\n",
      "ADJUSTED LR\n",
      " |ââââââââââââ--------| 61.8%  - epoch_loss: 251.9570541382 - epoch_recon_loss: 241.4975652059 - epoch_kl_loss: 20.9189805984 - val_loss: 212.9700622559 - val_recon_loss: 203.9760818481 - val_kl_loss: 17.9879598618\n",
      "ADJUSTED LR\n",
      " |ââââââââââââ--------| 64.5%  - epoch_loss: 252.0967569987 - epoch_recon_loss: 241.4807312012 - epoch_kl_loss: 21.2320480347 - val_loss: 213.4492225647 - val_recon_loss: 204.4693603516 - val_kl_loss: 17.9597253799\n",
      "Stopping early: no improvement of more than 0 nats in 50 epochs\n",
      "If the early stopping criterion is too strong, please instantiate it with different parameters in the train method.\n",
      "Saving best state of network...\n",
      "Best State was in Epoch 206\n",
      "Duration of model training in run 2: 0 hours, 2 minutes and 6 seconds.\n",
      "\n",
      "INITIALIZING NEW NETWORK..............\n",
      "Encoder Architecture:\n",
      "\tInput Layer in, out and cond: 4000 256 1\n",
      "\tHidden Layer 1 in/out: 256 256\n",
      "\tHidden Layer 2 in/out: 256 256\n",
      "\tMean/Var Layer in/out: 256 1519\n",
      "Decoder Architecture:\n",
      "\tMasked linear layer in, ext_m, ext, cond, out:  1519 0 0 1 4000\n",
      "\twith hard mask.\n",
      "Last Decoder layer: softmax\n",
      "Preparing (4200, 4000)\n",
      "Instantiating dataset\n",
      "Init the group lasso proximal operator for the main terms.\n",
      " |ââââââââ------------| 42.2%  - epoch_loss: 250.6516581217 - epoch_recon_loss: 239.9232004801 - epoch_kl_loss: 21.4569178263 - val_loss: 210.2947158813 - val_recon_loss: 201.1665916443 - val_kl_loss: 18.2562575340272\n",
      "ADJUSTED LR\n",
      " |âââââââââ-----------| 45.8%  - epoch_loss: 249.4042327881 - epoch_recon_loss: 238.5671447754 - epoch_kl_loss: 21.6741754532 - val_loss: 212.1342697144 - val_recon_loss: 202.9063529968 - val_kl_loss: 18.4558401108\n",
      "ADJUSTED LR\n",
      " |ââââââââââ----------| 52.0%  - epoch_loss: 250.6435419718 - epoch_recon_loss: 239.9422027588 - epoch_kl_loss: 21.4026793798 - val_loss: 211.8901405334 - val_recon_loss: 202.7379875183 - val_kl_loss: 18.3042984009\n",
      "ADJUSTED LR\n",
      " |âââââââââââ---------| 55.2%  - epoch_loss: 251.5494486491 - epoch_recon_loss: 240.8275207520 - epoch_kl_loss: 21.4438515981 - val_loss: 210.9268150330 - val_recon_loss: 201.7803688049 - val_kl_loss: 18.2928881645\n",
      "ADJUSTED LR\n",
      " |âââââââââââ---------| 58.5%  - epoch_loss: 255.3212987264 - epoch_recon_loss: 244.5282964071 - epoch_kl_loss: 21.5860048930 - val_loss: 212.6095352173 - val_recon_loss: 203.4879722595 - val_kl_loss: 18.2431297302\n",
      "ADJUSTED LR\n",
      " |ââââââââââââ--------| 61.3%  - epoch_loss: 250.0383483887 - epoch_recon_loss: 239.1791025798 - epoch_kl_loss: 21.7184908549 - val_loss: 212.2032089233 - val_recon_loss: 203.1239776611 - val_kl_loss: 18.1584620476\n",
      "Stopping early: no improvement of more than 0 nats in 50 epochs\n",
      "If the early stopping criterion is too strong, please instantiate it with different parameters in the train method.\n",
      "Saving best state of network...\n",
      "Best State was in Epoch 193\n",
      "Duration of model training in run 3: 0 hours, 2 minutes and 0 seconds.\n",
      "\n",
      "INITIALIZING NEW NETWORK..............\n",
      "Encoder Architecture:\n",
      "\tInput Layer in, out and cond: 4000 256 1\n",
      "\tHidden Layer 1 in/out: 256 256\n",
      "\tHidden Layer 2 in/out: 256 256\n",
      "\tMean/Var Layer in/out: 256 1519\n",
      "Decoder Architecture:\n",
      "\tMasked linear layer in, ext_m, ext, cond, out:  1519 0 0 1 4000\n",
      "\twith hard mask.\n",
      "Last Decoder layer: softmax\n",
      "Preparing (4200, 4000)\n",
      "Instantiating dataset\n",
      "Init the group lasso proximal operator for the main terms.\n",
      " |âââââââ-------------| 37.5%  - epoch_loss: 255.1086140951 - epoch_recon_loss: 244.5983963013 - epoch_kl_loss: 21.0204376221 - val_loss: 216.6652870178 - val_recon_loss: 207.9797935486 - val_kl_loss: 17.3709769249635\n",
      "ADJUSTED LR\n",
      " |ââââââââ------------| 41.2%  - epoch_loss: 256.6949544271 - epoch_recon_loss: 246.2046081543 - epoch_kl_loss: 20.9806939443 - val_loss: 217.8369522095 - val_recon_loss: 209.0721092224 - val_kl_loss: 17.5296902657\n",
      "ADJUSTED LR\n",
      " |ââââââââ------------| 44.5%  - epoch_loss: 252.1225540161 - epoch_recon_loss: 241.6146896362 - epoch_kl_loss: 21.0157297134 - val_loss: 213.4770011902 - val_recon_loss: 204.6692810059 - val_kl_loss: 17.6154456139\n",
      "ADJUSTED LR\n",
      " |âââââââââ-----------| 48.2%  - epoch_loss: 253.9620157878 - epoch_recon_loss: 243.4660695394 - epoch_kl_loss: 20.9918949763 - val_loss: 216.5363426208 - val_recon_loss: 207.6478538513 - val_kl_loss: 17.7769770622\n",
      "ADJUSTED LR\n",
      " |ââââââââââ----------| 51.5%  - epoch_loss: 254.2450673421 - epoch_recon_loss: 243.7281138102 - epoch_kl_loss: 21.0339050293 - val_loss: 214.5701370239 - val_recon_loss: 205.8075523376 - val_kl_loss: 17.5251669884\n",
      "ADJUSTED LR\n",
      " |ââââââââââ----------| 54.8%  - epoch_loss: 257.1718190511 - epoch_recon_loss: 246.7143463135 - epoch_kl_loss: 20.9149459203 - val_loss: 216.3669967651 - val_recon_loss: 207.5280494690 - val_kl_loss: 17.6778955460\n",
      "ADJUSTED LR\n",
      " |âââââââââââ---------| 57.5%  - epoch_loss: 252.2591684977 - epoch_recon_loss: 241.7371073405 - epoch_kl_loss: 21.0441214879 - val_loss: 214.8810501099 - val_recon_loss: 205.9776306152 - val_kl_loss: 17.8068299294\n",
      "Stopping early: no improvement of more than 0 nats in 50 epochs\n",
      "If the early stopping criterion is too strong, please instantiate it with different parameters in the train method.\n",
      "Saving best state of network...\n",
      "Best State was in Epoch 178\n",
      "Duration of model training in run 4: 0 hours, 1 minutes and 49 seconds.\n",
      "\n",
      "INITIALIZING NEW NETWORK..............\n",
      "Encoder Architecture:\n",
      "\tInput Layer in, out and cond: 4000 256 1\n",
      "\tHidden Layer 1 in/out: 256 256\n",
      "\tHidden Layer 2 in/out: 256 256\n",
      "\tMean/Var Layer in/out: 256 1519\n",
      "Decoder Architecture:\n",
      "\tMasked linear layer in, ext_m, ext, cond, out:  1519 0 0 1 4000\n",
      "\twith hard mask.\n",
      "Last Decoder layer: softmax\n",
      "Preparing (4200, 4000)\n",
      "Instantiating dataset\n",
      "Init the group lasso proximal operator for the main terms.\n",
      " |âââââââââââ---------| 56.0%  - epoch_loss: 250.1205403646 - epoch_recon_loss: 239.7900451660 - epoch_kl_loss: 20.6609910329 - val_loss: 208.7964019775 - val_recon_loss: 200.0592041016 - val_kl_loss: 17.4743919373627\n",
      "ADJUSTED LR\n",
      " |ââââââââââââ--------| 63.5%  - epoch_loss: 247.8859049479 - epoch_recon_loss: 237.6006301880 - epoch_kl_loss: 20.5705493927 - val_loss: 209.6766433716 - val_recon_loss: 200.9345359802 - val_kl_loss: 17.4842176437\n",
      "ADJUSTED LR\n",
      " |âââââââââââââ-------| 69.5%  - epoch_loss: 246.9005884806 - epoch_recon_loss: 236.7184056600 - epoch_kl_loss: 20.3643650691 - val_loss: 205.4476242065 - val_recon_loss: 196.7290039062 - val_kl_loss: 17.4372444153\n",
      "ADJUSTED LR\n",
      " |ââââââââââââââ------| 72.8%  - epoch_loss: 247.9560480754 - epoch_recon_loss: 237.6613937378 - epoch_kl_loss: 20.5893082301 - val_loss: 208.7788276672 - val_recon_loss: 200.0510406494 - val_kl_loss: 17.4555716515\n",
      "ADJUSTED LR\n",
      " |âââââââââââââââ-----| 76.8%  - epoch_loss: 252.7919626872 - epoch_recon_loss: 242.5061625163 - epoch_kl_loss: 20.5716018041 - val_loss: 205.2946777344 - val_recon_loss: 196.5178108215 - val_kl_loss: 17.5537362099\n",
      "ADJUSTED LR\n",
      " |ââââââââââââââââ----| 80.0%  - epoch_loss: 245.9855656942 - epoch_recon_loss: 235.7454386393 - epoch_kl_loss: 20.4802581787 - val_loss: 208.3424263000 - val_recon_loss: 199.6607666016 - val_kl_loss: 17.3633184433\n",
      "ADJUSTED LR\n",
      " |ââââââââââââââââ----| 83.2%  - epoch_loss: 250.3275227865 - epoch_recon_loss: 240.1569702148 - epoch_kl_loss: 20.3411064148 - val_loss: 207.7602462769 - val_recon_loss: 198.9181289673 - val_kl_loss: 17.6842331886\n",
      "ADJUSTED LR\n",
      " |âââââââââââââââââ---| 86.0%  - epoch_loss: 247.5729660034 - epoch_recon_loss: 237.2223648071 - epoch_kl_loss: 20.7012004217 - val_loss: 207.4528579712 - val_recon_loss: 198.6279258728 - val_kl_loss: 17.6498603821\n",
      "Stopping early: no improvement of more than 0 nats in 50 epochs\n",
      "If the early stopping criterion is too strong, please instantiate it with different parameters in the train method.\n",
      "Saving best state of network...\n",
      "Best State was in Epoch 292\n",
      "Duration of model training in run 5: 0 hours, 2 minutes and 49 seconds.\n",
      "\n",
      "INITIALIZING NEW NETWORK..............\n",
      "Encoder Architecture:\n",
      "\tInput Layer in, out and cond: 4000 256 1\n",
      "\tHidden Layer 1 in/out: 256 256\n",
      "\tHidden Layer 2 in/out: 256 256\n",
      "\tMean/Var Layer in/out: 256 1519\n",
      "Decoder Architecture:\n",
      "\tMasked linear layer in, ext_m, ext, cond, out:  1519 0 0 1 4000\n",
      "\twith hard mask.\n",
      "Last Decoder layer: softmax\n",
      "Preparing (4200, 4000)\n",
      "Instantiating dataset\n",
      "Init the group lasso proximal operator for the main terms.\n",
      " |âââââââââ-----------| 48.5%  - epoch_loss: 250.5171478271 - epoch_recon_loss: 239.9557637533 - epoch_kl_loss: 21.1227706273 - val_loss: 210.5942611694 - val_recon_loss: 201.3777236938 - val_kl_loss: 18.4330778122311\n",
      "ADJUSTED LR\n",
      " |ââââââââââ----------| 51.7%  - epoch_loss: 249.6591527303 - epoch_recon_loss: 239.0690836589 - epoch_kl_loss: 21.1801361720 - val_loss: 212.8014945984 - val_recon_loss: 203.6435890198 - val_kl_loss: 18.3158149719\n",
      "ADJUSTED LR\n",
      " |âââââââââââ---------| 56.5%  - epoch_loss: 250.7806477865 - epoch_recon_loss: 240.0593338013 - epoch_kl_loss: 21.4426267624 - val_loss: 208.9532699585 - val_recon_loss: 199.8116950989 - val_kl_loss: 18.2831501961\n",
      "ADJUSTED LR\n",
      " |âââââââââââ---------| 59.8%  - epoch_loss: 246.2468353271 - epoch_recon_loss: 235.4934768677 - epoch_kl_loss: 21.5067171733 - val_loss: 211.8062095642 - val_recon_loss: 202.8356628418 - val_kl_loss: 17.9410905838\n",
      "ADJUSTED LR\n",
      " |ââââââââââââ--------| 63.0%  - epoch_loss: 248.0120030721 - epoch_recon_loss: 237.3706207275 - epoch_kl_loss: 21.2827654521 - val_loss: 209.6245269775 - val_recon_loss: 200.4665489197 - val_kl_loss: 18.3159556389\n",
      "ADJUSTED LR\n",
      " |âââââââââââââ-------| 65.8%  - epoch_loss: 247.8062566121 - epoch_recon_loss: 237.2282506307 - epoch_kl_loss: 21.1560166677 - val_loss: 211.4913482666 - val_recon_loss: 202.4138755798 - val_kl_loss: 18.1549468040\n",
      "Stopping early: no improvement of more than 0 nats in 50 epochs\n",
      "If the early stopping criterion is too strong, please instantiate it with different parameters in the train method.\n",
      "Saving best state of network...\n",
      "Best State was in Epoch 211\n",
      "Duration of model training in run 6: 0 hours, 2 minutes and 7 seconds.\n",
      "\n",
      "INITIALIZING NEW NETWORK..............\n",
      "Encoder Architecture:\n",
      "\tInput Layer in, out and cond: 4000 256 1\n",
      "\tHidden Layer 1 in/out: 256 256\n",
      "\tHidden Layer 2 in/out: 256 256\n",
      "\tMean/Var Layer in/out: 256 1519\n",
      "Decoder Architecture:\n",
      "\tMasked linear layer in, ext_m, ext, cond, out:  1519 0 0 1 4000\n",
      "\twith hard mask.\n",
      "Last Decoder layer: softmax\n",
      "Preparing (4200, 4000)\n",
      "Instantiating dataset\n",
      "Init the group lasso proximal operator for the main terms.\n",
      " |âââââââ-------------| 39.8%  - epoch_loss: 252.9828399658 - epoch_recon_loss: 242.8614929199 - epoch_kl_loss: 20.2426941554 - val_loss: 211.6671295166 - val_recon_loss: 203.2733688354 - val_kl_loss: 16.7875175476702\n",
      "ADJUSTED LR\n",
      " |ââââââââ------------| 43.2%  - epoch_loss: 251.1670939128 - epoch_recon_loss: 241.0025177002 - epoch_kl_loss: 20.3291501363 - val_loss: 213.6832962036 - val_recon_loss: 205.0224304199 - val_kl_loss: 17.3217310905\n",
      "ADJUSTED LR\n",
      " |âââââââââ-----------| 46.5%  - epoch_loss: 253.8036432902 - epoch_recon_loss: 243.7218694051 - epoch_kl_loss: 20.1635474523 - val_loss: 215.6450080872 - val_recon_loss: 206.9637641907 - val_kl_loss: 17.3624892235\n",
      "ADJUSTED LR\n",
      " |âââââââââ-----------| 49.8%  - epoch_loss: 254.1102025350 - epoch_recon_loss: 243.9318588257 - epoch_kl_loss: 20.3566897710 - val_loss: 215.1875839233 - val_recon_loss: 206.6837463379 - val_kl_loss: 17.0076808929\n",
      "ADJUSTED LR\n",
      " |ââââââââââ----------| 53.5%  - epoch_loss: 252.5737386068 - epoch_recon_loss: 242.4258494059 - epoch_kl_loss: 20.2957770030 - val_loss: 214.3546943665 - val_recon_loss: 205.7091407776 - val_kl_loss: 17.2911086082\n",
      "ADJUSTED LR\n",
      " |âââââââââââ---------| 56.8%  - epoch_loss: 253.7062184652 - epoch_recon_loss: 243.5843510946 - epoch_kl_loss: 20.2437314351 - val_loss: 217.4707450867 - val_recon_loss: 208.8364944458 - val_kl_loss: 17.2685017586\n",
      "ADJUSTED LR\n",
      " |ââââââââââââ--------| 60.0%  - epoch_loss: 254.2114557902 - epoch_recon_loss: 244.0316691081 - epoch_kl_loss: 20.3595729192 - val_loss: 212.3425865173 - val_recon_loss: 203.8896903992 - val_kl_loss: 16.9057929516\n",
      "ADJUSTED LR\n",
      " |ââââââââââââ--------| 62.7%  - epoch_loss: 253.8197316488 - epoch_recon_loss: 243.7135401408 - epoch_kl_loss: 20.2123769760 - val_loss: 210.7218093872 - val_recon_loss: 202.2041015625 - val_kl_loss: 17.0354201794\n",
      "Stopping early: no improvement of more than 0 nats in 50 epochs\n",
      "If the early stopping criterion is too strong, please instantiate it with different parameters in the train method.\n",
      "Saving best state of network...\n",
      "Best State was in Epoch 250\n",
      "Duration of model training in run 7: 0 hours, 2 minutes and 1 seconds.\n",
      "\n",
      "INITIALIZING NEW NETWORK..............\n",
      "Encoder Architecture:\n",
      "\tInput Layer in, out and cond: 4000 256 1\n",
      "\tHidden Layer 1 in/out: 256 256\n",
      "\tHidden Layer 2 in/out: 256 256\n",
      "\tMean/Var Layer in/out: 256 1519\n",
      "Decoder Architecture:\n",
      "\tMasked linear layer in, ext_m, ext, cond, out:  1519 0 0 1 4000\n",
      "\twith hard mask.\n",
      "Last Decoder layer: softmax\n",
      "Preparing (4200, 4000)\n",
      "Instantiating dataset\n",
      "Init the group lasso proximal operator for the main terms.\n",
      " |âââââ---------------| 29.5%  - epoch_loss: 259.4545211792 - epoch_recon_loss: 247.0405909220 - epoch_kl_loss: 24.8278603236 - val_loss: 222.2486076355 - val_recon_loss: 212.5171623230 - val_kl_loss: 19.4628934860674\n",
      "ADJUSTED LR\n",
      " |âââââââ-------------| 36.0%  - epoch_loss: 256.8877777100 - epoch_recon_loss: 244.7335871379 - epoch_kl_loss: 24.3083829880 - val_loss: 221.5944633484 - val_recon_loss: 211.8167991638 - val_kl_loss: 19.5553236008\n",
      "ADJUSTED LR\n",
      " |ââââââââ------------| 42.8%  - epoch_loss: 260.6317138672 - epoch_recon_loss: 248.4924011230 - epoch_kl_loss: 24.2786276499 - val_loss: 224.1669616699 - val_recon_loss: 214.2821998596 - val_kl_loss: 19.7695236206\n",
      "ADJUSTED LR\n",
      " |âââââââââ-----------| 46.0%  - epoch_loss: 258.3312861125 - epoch_recon_loss: 246.2019724528 - epoch_kl_loss: 24.2586299896 - val_loss: 221.8627281189 - val_recon_loss: 211.9407844543 - val_kl_loss: 19.8438835144\n",
      "ADJUSTED LR\n",
      " |âââââââââ-----------| 49.2%  - epoch_loss: 260.0803670247 - epoch_recon_loss: 247.9541244507 - epoch_kl_loss: 24.2524873734 - val_loss: 222.4401092529 - val_recon_loss: 212.4184875488 - val_kl_loss: 20.0432443619\n",
      "ADJUSTED LR\n",
      " |ââââââââââ----------| 52.0%  - epoch_loss: 260.4155171712 - epoch_recon_loss: 248.4054590861 - epoch_kl_loss: 24.0201171875 - val_loss: 219.2447929382 - val_recon_loss: 209.3572807312 - val_kl_loss: 19.7750244141\n",
      "Stopping early: no improvement of more than 0 nats in 50 epochs\n",
      "If the early stopping criterion is too strong, please instantiate it with different parameters in the train method.\n",
      "Saving best state of network...\n",
      "Best State was in Epoch 156\n",
      "Duration of model training in run 8: 0 hours, 1 minutes and 39 seconds.\n"
     ]
    }
   ],
   "source": [
    "for subsample_pct in [10]:\n",
    "    train_expimap_models(dataset=f\"slideseqv2_mouse_hippocampus_subsample_{subsample_pct}pct\",\n",
    "                         cell_type_key=\"cell_type\",\n",
    "                         gp_dict=mouse_combined_new_gp_dict,\n",
    "                         adata_new=None,\n",
    "                         n_start_run=1,\n",
    "                         n_end_run=8,\n",
    "                         n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11c7293-0826-4a3e-a940-46690bdc32d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870bb13d-0aec-4b66-9b61-e10db42d36cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
