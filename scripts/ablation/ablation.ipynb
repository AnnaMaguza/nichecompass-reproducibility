{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "364a9ebc-3e3c-4645-9049-a34bd084c8a8",
   "metadata": {},
   "source": [
    "# Ablation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c55227-147e-417f-b0dd-bb0b7f322930",
   "metadata": {},
   "source": [
    "- **Creator**: Sebastian Birk (<sebastian.birk@helmholtz-munich.de>).\n",
    "- **Affiliation:** Helmholtz Munich, Institute of Computational Biology (ICB), Talavera-LÃ³pez Lab\n",
    "- **Date of Creation:** 06.01.2023\n",
    "- **Date of Last Modification:** 27.06.2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7529cde5-be12-403b-a94c-07561774b86c",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faad87bd-fef5-4429-a175-d714c491ae76",
   "metadata": {},
   "source": [
    "### 1.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9533f18-f082-4dcc-8e93-117b9759133e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e0bf12-90ee-403e-8970-0d1ac2f47540",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../utils\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f93960-c759-424f-8cb2-1d8698acae2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import plottable\n",
    "import scanpy as sc\n",
    "import scib\n",
    "import seaborn as sns\n",
    "from matplotlib import gridspec\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from plottable import ColumnDefinition, Table\n",
    "from plottable.cmap import normed_cmap\n",
    "from plottable.formatters import tickcross\n",
    "from plottable.plots import bar\n",
    "\n",
    "from nichecompass.benchmarking import compute_benchmarking_metrics\n",
    "from nichecompass.models import NicheCompass\n",
    "from nichecompass.utils import (add_gps_from_gp_dict_to_adata,\n",
    "                                create_new_color_dict,\n",
    "                                extract_gp_dict_from_mebocost_es_interactions,\n",
    "                                extract_gp_dict_from_nichenet_lrt_interactions,\n",
    "                                extract_gp_dict_from_omnipath_lr_interactions,\n",
    "                                filter_and_combine_gp_dict_gps)\n",
    "\n",
    "from ablation_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b5efa5-2052-4986-8ae5-89cfab018515",
   "metadata": {},
   "source": [
    "### 1.2 Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c8b48a-ed5e-48b5-8c5c-c1de11493aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_key = \"nichecompass_latent\"\n",
    "spatial_key = \"spatial\"\n",
    "latent_knng_key = \"nichecompass_latent_knng\"\n",
    "spatial_knng_key = \"spatial_knng\"\n",
    "gp_names_key = \"nichecompass_gp_names\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28adc110-0f41-4a71-9838-dc7f0687809a",
   "metadata": {},
   "source": [
    "### 1.4 Run Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334b87ca-3387-4ba9-8567-84bc4754ff0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.set_figure_params(figsize=(6, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3944b0c4-023b-4fcb-9b61-9293f08939b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore future warnings and user warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=UserWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab6b302-1c0b-4937-8624-40629ada2e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get time of notebook execution for timestamping saved artifacts\n",
    "now = datetime.now()\n",
    "current_timestamp = now.strftime(\"%d%m%Y_%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85538952-006b-4b0b-a50c-fe7445ce22e2",
   "metadata": {},
   "source": [
    "### 1.5 Configure Paths and Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddcc49c-ba22-4155-acd5-05b5b810e091",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder_path = \"../../datasets/srt_data/gold\"\n",
    "artifact_folder_path = f\"../../artifacts\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1f3798-2b4a-49ed-892c-a85d167d8ff1",
   "metadata": {},
   "source": [
    "## 2. Ablation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8884ac28-0cdf-4b37-9281-4a86dd194ef5",
   "metadata": {},
   "source": [
    "### 2.1 Loss Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c35e676-2a44-46a0-a72a-e7102d808ec1",
   "metadata": {},
   "source": [
    "#### 2.1.1 Edge Reconstruction & Gene Expression Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d670edc-be19-4dbc-b691-d52bac75361f",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_timestamp = \"27062023_170937_2\"\n",
    "model_folder_path = f\"{artifact_folder_path}/{dataset}/models/{task}/{load_timestamp}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a355d5-e73a-4042-bb6f-9b29ff60faa3",
   "metadata": {},
   "source": [
    "- lambda_gene_expr_recon & lambda_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b10d503-b972-4d74-b902-7781ae95160c",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"loss_weights_ablation\"\n",
    "dataset = \"seqfish_mouse_organogenesis\"\n",
    "timestamps = [\"28062023_142033_45\", \"28062023_134141_15\", \"28062023_140826_35\", \"28062023_132911_5\"]\n",
    "cell_type_key = \"celltype_mapped_refined\"\n",
    "condition_key = None\n",
    "sample_key = \"sample\"\n",
    "\n",
    "datasets = [\"seqfish_mouse_organogenesis\"]\n",
    "experiment_ids = [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b24e36-0478-42f6-980a-90365ad968fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve metrics and params of ablation runs from mlflow and store in summary df\n",
    "summary_df = pd.DataFrame()\n",
    "for dataset, experiment_id in zip(datasets, experiment_ids):\n",
    "    runs_info = mlflow.list_run_infos(experiment_id)\n",
    "    for run_info in runs_info:\n",
    "        run = mlflow.get_run(run_info.run_uuid)\n",
    "        run_dict = {\"dataset\": dataset}\n",
    "        run_dict[\"timestamp\"] = run.data.params[\"timestamp\"]\n",
    "        run_dict[\"val_auroc_score\"] = run.data.metrics.get(\"val_auroc_score\", np.nan)\n",
    "        run_dict[\"val_gene_expr_mse_score\"] = run.data.metrics.get(\"val_gene_expr_mse_score\", np.nan)\n",
    "        run_dict[\"lambda_edge_recon_\"] = run.data.params[\"lambda_edge_recon_\"]\n",
    "        run_dict[\"lambda_gene_expr_recon_\"] = run.data.params[\"lambda_gene_expr_recon_\"]\n",
    "        run_dict[\"n_neighbors\"] = run.data.params[\"n_neighbors\"]\n",
    "        run_df = pd.DataFrame(run_dict, index=[0])\n",
    "        summary_df = pd.concat([summary_df, run_df], ignore_index=True)\n",
    "summary_df[\"loss_weights\"] = summary_df.apply(lambda row: get_loss_weights(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6893db-9d34-432b-a6a0-e6cfc075e504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestamps = summary_df[\"timestamp\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9ed849-ad54-4a3c-98b8-4e51edcb6f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics and add to summary df\n",
    "metrics_df = pd.DataFrame()\n",
    "for dataset in datasets:\n",
    "    current_iteration_metrics_df = compute_metrics(\n",
    "        artifact_folder_path=artifact_folder_path,\n",
    "        dataset=dataset,\n",
    "        task=task,\n",
    "        timestamps=timestamps,\n",
    "        cell_type_key=cell_type_key,\n",
    "        condition_key=condition_key,\n",
    "        spatial_knng_key=spatial_knng_key,\n",
    "        latent_knng_key=latent_knng_key,\n",
    "        spatial_key=spatial_key,\n",
    "        latent_key=latent_key)\n",
    "    metrics_df = pd.concat([metrics_df, current_iteration_metrics_df], axis=0)\n",
    "summary_df = pd.merge(summary_df, metrics_df, on=[\"dataset\", \"timestamp\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4a6e77-742d-421e-bfb2-713fc9e05a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = summary_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5617a69-12d3-4336-827c-465b24fb046d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066b3afb-017f-495b-9bb4-26610351dde7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195f6b61-d39c-4333-8473-42ef97056c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_type_colors = create_new_color_dict(\n",
    "    adata=adata,\n",
    "    cat_key=cell_type_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99b12ce-c1c2-4b06-97e8-0c53f15d2e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = adata.obs[sample_key].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd1a4ca-f8d5-4f51-9d58-792b219f081c",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470bc957-1029-47d5-bdbc-cfa6e38c0d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_cols = [\"cas\", \"mlami\", \"gcs\", \"cca\"]\n",
    "metric_cols_weights = [1., 1., 1., 3.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151d204b-a3a9-4547-9c12-038aedbf6289",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_df = plot_metrics(\n",
    "    fig_title=\"Loss Weights Ablation\",\n",
    "    df=test_df,\n",
    "    group_col=\"loss_weights\",\n",
    "    metric_cols_weights=metric_cols_weights,\n",
    "    metric_cols=metric_cols,\n",
    "    sort_metric_col=\"total_score\",\n",
    "    plot_ratio_active_gps=False,\n",
    "    save_fig=False,\n",
    "    file_name=\"ablation_metrics.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31725214-1509-48c6-adef-bf93b74f23ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_latent_space_comparison(plot_label=\"test\",\n",
    "                                  summary_df=df,\n",
    "                                  model_timestamps=timestamps_of_interest,\n",
    "                                  dataset=dataset,\n",
    "                                  cat_key=cell_type_key,\n",
    "                                  cat_colors=cell_type_colors,\n",
    "                                  groups=None,\n",
    "                                  sample_key=sample_key,\n",
    "                                  samples=samples,\n",
    "                                  spot_size=0.03,\n",
    "                                  save_fig=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b2822c-a115-49c1-8d94-4a8003901c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_latent_space_comparison(plot_label,\n",
    "                                      summary_df,\n",
    "                                      model_timestamps,\n",
    "                                      dataset,\n",
    "                                      cat_key,\n",
    "                                      cat_colors,\n",
    "                                      sample_key,\n",
    "                                      samples,\n",
    "                                      groups=None,\n",
    "                                      spot_size=0.03,\n",
    "                                      save_fig=True):\n",
    "    ncols_samples = min(3, len(samples))\n",
    "    ncols_models = min(3, len(model_timestamps))\n",
    "    nrows = (2 + int(len(samples) / 3) +\n",
    "             int(len(model_timestamps) / 3))\n",
    "    # Create plot of cell type annotations in physical and latent spaces\n",
    "    fig = plt.figure(figsize=(20, len(samples) + 20))\n",
    "    title = fig.suptitle(t=f\"{plot_label} in NicheCompass \" \\\n",
    "                           \"Latent and Physical Space\",\n",
    "                         y=0.96,\n",
    "                         x=0.55,\n",
    "                         fontsize=20)\n",
    "    spec1 = gridspec.GridSpec(ncols=ncols_samples,\n",
    "                              nrows=nrows,\n",
    "                              width_ratios=[1] * ncols_samples,\n",
    "                              height_ratios=[2] * nrows)\n",
    "    spec2 = gridspec.GridSpec(ncols=ncols_models,\n",
    "                              nrows=nrows,\n",
    "                              width_ratios=[1] * ncols_models,\n",
    "                              height_ratios=[2] * nrows)\n",
    "    axs = []\n",
    "    \n",
    "    adata = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/models/{task}/{model_timestamps[0]}/{dataset}_{task}.h5ad\")\n",
    "    print(adata)\n",
    "    \n",
    "    for i, sample in enumerate(samples):\n",
    "        axs.append(fig.add_subplot(spec1[i]))\n",
    "        sc.pl.spatial(adata=adata[adata.obs[sample_key] == sample],\n",
    "                      color=[cat_key],\n",
    "                      groups=groups,                  \n",
    "                      palette=cat_colors,\n",
    "                      spot_size=spot_size,\n",
    "                      title=f\"{plot_label} in \\n Physical Space \\n\"\n",
    "                            f\"(Sample: {sample})\",\n",
    "                      legend_loc=None,\n",
    "                      ax=axs[i],\n",
    "                      show=False)\n",
    "        \n",
    "    for j, timestamp in enumerate(model_timestamps):\n",
    "        axs.append(fig.add_subplot(spec2[i + j]))\n",
    "        \n",
    "        adata = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/models/{task}/{timestamp}/{dataset}_{task}.h5ad\")\n",
    "        \n",
    "        sc.pl.umap(adata=adata,\n",
    "                   color=[cat_key],\n",
    "                   groups=groups,\n",
    "                   palette=cat_colors,\n",
    "                   title=f\"{plot_label} in NicheCompass Latent Space\",\n",
    "                   ax=axs[i+j],\n",
    "                   show=False)\n",
    "    \n",
    "    # Create and position shared legend\n",
    "    handles, labels = axs[0].get_legend_handles_labels()\n",
    "    lgd = fig.legend(handles,\n",
    "                     labels,\n",
    "                     loc=\"center left\",\n",
    "                     bbox_to_anchor=(0.98, 0.5))\n",
    "    axs[0].get_legend().remove()\n",
    "\n",
    "    # Adjust, save and display plot\n",
    "    plt.subplots_adjust(wspace=0.2, hspace=0.25)\n",
    "    if save_fig:\n",
    "        fig.savefig(file_path,\n",
    "                    bbox_extra_artists=(lgd, title),\n",
    "                    bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03f46fb-4f75-420d-acd8-6fbcb8f4a91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fff9214-08d9-42c4-b022-5550788b5f11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb854907-e0d3-4084-98aa-48eb2d5cdabe",
   "metadata": {},
   "source": [
    "#### 2.1.2 Visualize Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684fc7dc-c3d0-4415-91c9-1595c10f5e22",
   "metadata": {},
   "source": [
    "##### 2.1.2.1 seqFISH Mouse Organogenesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc7fcf2-86e5-4440-80a9-756456e55535",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_latent_space_comparison(\n",
    "    dataset=\"seqfish_mouse_organogenesis_embryo2\",\n",
    "    cell_type_colors=color_utils.seqfish_mouse_organogenesis_cell_type_colors,\n",
    "    cell_type_groups=None,\n",
    "    n_neighbors=12,\n",
    "    run_number=5,\n",
    "    spot_size=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01d3ebc-a3fa-420d-afde-d49689389a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_latent_space_comparison(dataset=\"seqfish_mouse_organogenesis_embryo2\",\n",
    "                                cell_type_colors=seqfish_mouse_organogenesis_embryo2_cell_type_colors,\n",
    "                                cell_type_groups=\"Mixed mesenchymal mesoderm\", # \"Gut tube\",\n",
    "                                n_neighbors=12,\n",
    "                                run_number=5,\n",
    "                                spot_size=0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41be394-92e7-4847-8e9d-2b7431a8be5d",
   "metadata": {},
   "source": [
    "##### 2.1.2.2 MERFISH Mouse Liver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9712b9e-2715-4eba-8469-e2c2778159c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepLinc did not work on this dataset\n",
    "compute_latent_space_comparison(dataset=\"vizgen_merfish_mouse_liver\",\n",
    "                                cell_type_colors=vizgen_merfish_mouse_liver_cell_type_colors,\n",
    "                                n_neighbors=12,\n",
    "                                run_number=5,\n",
    "                                included_models=[\"NicheCompass\",\n",
    "                                                 \"expiMap\",\n",
    "                                                 \"scVI\"],\n",
    "                                spot_size=20.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97660a2a-1c62-428d-80b4-ec75f70a10ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepLinc did not work on this dataset\n",
    "compute_latent_space_comparison(dataset=\"vizgen_merfish_mouse_liver_sample\",\n",
    "                                cell_type_colors=vizgen_merfish_mouse_liver_cell_type_colors,\n",
    "                                n_neighbors=12,\n",
    "                                run_number=5,\n",
    "                                included_models=[\"NicheCompass\",\n",
    "                                                 \"GraphST\",\n",
    "                                                 \"SageNet\",\n",
    "                                                 \"expiMap\",\n",
    "                                                 \"scVI\"],\n",
    "                                spot_size=20.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff24528-8d9e-4496-8271-131eae6fe78f",
   "metadata": {},
   "source": [
    "##### 2.1.2.3 STARmap PLUS Mouse CNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73e2fdd-00f4-498c-8d53-a8e2ca1baac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_latent_space_comparison(dataset=\"starmap_plus_mouse_cns\",\n",
    "                                cell_type_colors=starmap_pluse_mouse_cns_cell_type_colors,\n",
    "                                n_neighbors=12,\n",
    "                                run_number=5,\n",
    "                                included_models=[\"NicheCompass\",\n",
    "                                                 \"expiMap\",\n",
    "                                                 \"scVI\"],\n",
    "                                spot_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b344d3de-7c38-44a0-b26e-19e35ed442bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_latent_space_comparison(dataset=\"starmap_plus_mouse_cns_sample\",\n",
    "                                cell_type_colors=starmap_pluse_mouse_cns_cell_type_colors,\n",
    "                                n_neighbors=12,\n",
    "                                run_number=5,\n",
    "                                spot_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9def1fe7-a072-46e0-b7b3-36fd22a54a6a",
   "metadata": {},
   "source": [
    "##### 2.1.2.4 NanoString CosMx Human NSCLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc27321-91c8-44b5-aa44-c04055a2e1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_latent_space_comparison(dataset=\"nanostring_cosmx_human_nsclc\",\n",
    "                                cell_type_colors=nanostring_cosmx_human_nsclc_cell_type_colors,\n",
    "                                n_neighbors=12,\n",
    "                                run_number=5,\n",
    "                                included_models=[\"NicheCompass\",\n",
    "                                                 \"expiMap\",\n",
    "                                                 \"scVI\"],\n",
    "                                spot_size=100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb84dc7-267b-4725-9160-acd4b574c4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_latent_space_comparison(dataset=\"nanostring_cosmx_human_nsclc_sample\",\n",
    "                                cell_type_colors=nanostring_cosmx_human_nsclc_cell_type_colors,\n",
    "                                n_neighbors=12,\n",
    "                                run_number=5,\n",
    "                                spot_size=100.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781e4275-de08-4bf4-adbf-9519615d6ff4",
   "metadata": {},
   "source": [
    "### 2.2 Benchmarking Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85601b8d-cbbf-4374-8ecd-cdce99f72baa",
   "metadata": {},
   "source": [
    "#### 2.2.1 Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce3a1e5-6886-4f83-b17d-1e3b4f58e56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_combined_benchmarking_metrics(model_adata,\n",
    "                                          model_name,\n",
    "                                          cell_type_key=\"cell_type\",\n",
    "                                          run_number_list=list(np.arange(1, 11)),\n",
    "                                          n_neighbors_list=[4, 4, 8, 8, 12, 12, 16, 16, 20, 20],\n",
    "                                          ger_genes=None):\n",
    "    benchmarking_dict_list = []\n",
    "    for run_number, n_neighbors in zip(run_number_list, n_neighbors_list):\n",
    "        \n",
    "        # Compute NicheCompass metrics\n",
    "        benchmarking_dict = compute_benchmarking_metrics(adata=model_adata,\n",
    "                                                         latent_key=f\"{model_name}_latent_run{run_number}\",\n",
    "                                                         cell_type_key=cell_type_key,\n",
    "                                                         spatial_key=spatial_key,\n",
    "                                                         spatial_knng_key=f\"spatial_{n_neighbors}nng\",\n",
    "                                                         latent_knng_key=f\"{model_name}_latent_{n_neighbors}nng_run{run_number}\",\n",
    "                                                         ger_genes=ger_genes)\n",
    "        benchmarking_dict[\"model_name\"] = model_name\n",
    "        benchmarking_dict[\"run\"] = run_number\n",
    "        benchmarking_dict_list.append(benchmarking_dict)\n",
    "    return benchmarking_dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a735441-aac3-4a3a-b56c-7ee638a0ba69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_combined_benchmarking_metrics_for_all_models(\n",
    "        dataset,\n",
    "        cell_type_key=\"cell_type\",\n",
    "        run_number_list=list(np.arange(1, 11)),\n",
    "        n_neighbors_list=[4, 4, 8, 8, 12, 12, 16, 16, 20, 20],\n",
    "        use_only_gp_mask_target_genes_for_gene_expr_regr=True,\n",
    "        included_models=[\"nichecompass\",\n",
    "                         \"deeplinc\",\n",
    "                         \"graphst\",\n",
    "                         \"sagenet\",\n",
    "                         \"expimap\",\n",
    "                         \"scvi\",\n",
    "                         \"pca\"]):\n",
    "    # Configure dataset artifact folder path\n",
    "    dataset_artifact_folder_path = f\"../../artifacts/{dataset}/method_benchmarking/comparison/{current_timestamp}\"\n",
    "    os.makedirs(dataset_artifact_folder_path, exist_ok=True)\n",
    "    \n",
    "    if use_only_gp_mask_target_genes_for_gene_expr_regr:\n",
    "        # Identify genes that are available in gp mask as target genes\n",
    "        print(\"Retrieving gp mask target genes...\")\n",
    "        adata = sc.read_h5ad(data_folder_path + f\"{dataset}.h5ad\")\n",
    "        \n",
    "        nichenet_gp_dict = extract_gp_dict_from_nichenet_ligand_target_mx(\n",
    "            keep_target_genes_ratio=0.01,\n",
    "            max_n_target_genes_per_gp=20000,\n",
    "            load_from_disk=False,\n",
    "            save_to_disk=False,\n",
    "            file_path=nichenet_ligand_target_mx_file_path)\n",
    "\n",
    "        omnipath_gp_dict = extract_gp_dict_from_omnipath_lr_interactions(\n",
    "            min_curation_effort=0,\n",
    "            load_from_disk=False,\n",
    "            save_to_disk=False,\n",
    "            file_path=omnipath_lr_interactions_file_path)\n",
    "\n",
    "        mebocost_gp_dict = extract_gp_dict_from_mebocost_es_interactions(\n",
    "            dir_path=f\"{gp_data_folder_path}/metabolite_enzyme_sensor_gps/\",\n",
    "            species=\"mouse\",\n",
    "            genes_uppercase=True)\n",
    "\n",
    "        # Combine gene programs into one dictionary\n",
    "        combined_gp_dict = dict(nichenet_gp_dict)\n",
    "        combined_gp_dict.update(omnipath_gp_dict)\n",
    "        combined_gp_dict.update(mebocost_gp_dict)\n",
    "\n",
    "        # Filter and combine gene programs\n",
    "        combined_new_gp_dict = filter_and_combine_gp_dict_gps(\n",
    "            gp_dict=combined_gp_dict,\n",
    "            gp_filter_mode=\"subset\", #None,\n",
    "            combine_overlap_gps=True, #True,\n",
    "            overlap_thresh_source_genes=0.9,\n",
    "            overlap_thresh_target_genes=0.9,\n",
    "            overlap_thresh_genes=0.9,\n",
    "            verbose=True)\n",
    "\n",
    "        # Add the gene program dictionary as binary masks to the adata for model training\n",
    "        add_gps_from_gp_dict_to_adata(\n",
    "            gp_dict=combined_new_gp_dict,\n",
    "            adata=adata,\n",
    "            genes_uppercase=True,\n",
    "            gp_targets_mask_key=\"nichecompass_gp_targets\",\n",
    "            gp_sources_mask_key=\"nichecompass_gp_sources\",\n",
    "            gp_names_key=\"nichecompass_gp_names\",\n",
    "            min_genes_per_gp=1,\n",
    "            min_source_genes_per_gp=0,\n",
    "            min_target_genes_per_gp=0,\n",
    "            max_genes_per_gp=None,\n",
    "            max_source_genes_per_gp=None,\n",
    "            max_target_genes_per_gp=None)\n",
    "\n",
    "        ger_genes = adata.var_names[adata.uns[\"nichecompass_target_genes_idx\"]].tolist()\n",
    "        del(adata)\n",
    "    else:\n",
    "        ger_genes = None\n",
    "    \n",
    "    # PCA\n",
    "    if \"pca\" in included_models:\n",
    "        print(\"Computing metrics for PCA...\")\n",
    "        adata_pca = sc.read_h5ad(data_folder_path + f\"{dataset}_pca.h5ad\")\n",
    "        benchmarking_dict_list_pca = compute_combined_benchmarking_metrics(\n",
    "            model_adata=adata_pca,\n",
    "            model_name=\"pca\",\n",
    "            run_number_list=run_number_list,\n",
    "            n_neighbors_list=n_neighbors_list,\n",
    "            cell_type_key=cell_type_key,\n",
    "            ger_genes=ger_genes)   \n",
    "    \n",
    "        benchmarking_dict_list = benchmarking_dict_list_pca\n",
    "        with open(f\"{dataset_artifact_folder_path}/benchmarking_dict_list.pickle\", \"wb\") as f:\n",
    "            pickle.dump(benchmarking_dict_list, f)\n",
    "        del(adata_pca)\n",
    "        print(\"\")\n",
    "    \n",
    "    # scVI\n",
    "    if \"scvi\" in included_models:\n",
    "        print(\"Computing metrics for scVI...\")\n",
    "        adata_scvi = sc.read_h5ad(data_folder_path + f\"{dataset}_scvi.h5ad\")\n",
    "        benchmarking_dict_list_scvi = compute_combined_benchmarking_metrics(\n",
    "            model_adata=adata_scvi,\n",
    "            model_name=\"scvi\",\n",
    "            run_number_list=run_number_list,\n",
    "            n_neighbors_list=n_neighbors_list,\n",
    "            cell_type_key=cell_type_key,\n",
    "            ger_genes=ger_genes)  \n",
    "        benchmarking_dict_list += benchmarking_dict_list_scvi\n",
    "        with open(f\"{dataset_artifact_folder_path}/benchmarking_dict_list.pickle\", \"wb\") as f:\n",
    "            pickle.dump(benchmarking_dict_list, f)\n",
    "        del(adata_scvi)\n",
    "        print(\"\")\n",
    "\n",
    "    # expiMap\n",
    "    if \"expimap\" in included_models:\n",
    "        print(\"Computing metrics for expiMap...\")\n",
    "        adata_expimap = sc.read_h5ad(data_folder_path + f\"{dataset}_expimap.h5ad\")\n",
    "        benchmarking_dict_list_expimap = compute_combined_benchmarking_metrics(\n",
    "            model_adata=adata_expimap,\n",
    "            model_name=\"expimap\",\n",
    "            run_number_list=run_number_list,\n",
    "            n_neighbors_list=n_neighbors_list,\n",
    "            cell_type_key=cell_type_key,\n",
    "            ger_genes=ger_genes)  \n",
    "        benchmarking_dict_list += benchmarking_dict_list_expimap\n",
    "        with open(f\"{dataset_artifact_folder_path}/benchmarking_dict_list.pickle\", \"wb\") as f:\n",
    "            pickle.dump(benchmarking_dict_list, f)\n",
    "        del(adata_expimap)\n",
    "        print(\"\")\n",
    "    \n",
    "    # SageNet\n",
    "    if \"sagenet\" in included_models:\n",
    "        print(\"Computing metrics for SageNet...\")\n",
    "        adata_sagenet = sc.read_h5ad(data_folder_path + f\"{dataset}_sagenet.h5ad\")\n",
    "        benchmarking_dict_list_sagenet = compute_combined_benchmarking_metrics(\n",
    "            model_adata=adata_sagenet,\n",
    "            model_name=\"sagenet\",\n",
    "            run_number_list=run_number_list,\n",
    "            n_neighbors_list=n_neighbors_list,\n",
    "            cell_type_key=cell_type_key,\n",
    "            ger_genes=ger_genes) \n",
    "        benchmarking_dict_list += benchmarking_dict_list_sagenet\n",
    "        with open(f\"{dataset_artifact_folder_path}/benchmarking_dict_list.pickle\", \"wb\") as f:\n",
    "            pickle.dump(benchmarking_dict_list, f)\n",
    "        del(adata_sagenet)\n",
    "        print(\"\")\n",
    "    \n",
    "    # DeepLinc\n",
    "    if \"deeplinc\" in included_models:\n",
    "        print(\"Computing metrics for DeepLinc...\")\n",
    "        adata_deeplinc = sc.read_h5ad(data_folder_path + f\"{dataset}_deeplinc.h5ad\")\n",
    "        benchmarking_dict_list_deeplinc = compute_combined_benchmarking_metrics(\n",
    "            model_adata=adata_deeplinc,\n",
    "            model_name=\"deeplinc\",\n",
    "            run_number_list=run_number_list,\n",
    "            n_neighbors_list=n_neighbors_list,\n",
    "            cell_type_key=cell_type_key,\n",
    "            ger_genes=ger_genes)\n",
    "        benchmarking_dict_list += benchmarking_dict_list_deeplinc\n",
    "        with open(f\"{dataset_artifact_folder_path}/benchmarking_dict_list.pickle\", \"wb\") as f:\n",
    "            pickle.dump(benchmarking_dict_list, f)\n",
    "        del(adata_deeplinc)\n",
    "        print(\"\")\n",
    "    \n",
    "    # GraphST\n",
    "    if \"graphst\" in included_models:\n",
    "        print(\"Computing metrics for GraphST...\")\n",
    "        adata_graphst = sc.read_h5ad(data_folder_path + f\"{dataset}_graphst.h5ad\")\n",
    "        benchmarking_dict_list_graphst = compute_combined_benchmarking_metrics(\n",
    "            model_adata=adata_graphst,\n",
    "            model_name=\"graphst\",\n",
    "            run_number_list=run_number_list,\n",
    "            n_neighbors_list=n_neighbors_list,\n",
    "            cell_type_key=cell_type_key,\n",
    "            ger_genes=ger_genes)\n",
    "        benchmarking_dict_list += benchmarking_dict_list_graphst\n",
    "        with open(f\"{dataset_artifact_folder_path}/benchmarking_dict_list.pickle\", \"wb\") as f:\n",
    "            pickle.dump(benchmarking_dict_list, f)\n",
    "        del(adata_graphst)\n",
    "        print(\"\")\n",
    "\n",
    "    # NicheCompass\n",
    "    if \"nichecompass\" in included_models:\n",
    "        print(\"Computing metrics for NicheCompass...\")\n",
    "        adata_nichecompass = sc.read_h5ad(data_folder_path + f\"{dataset}_nichecompass.h5ad\")\n",
    "        benchmarking_dict_list_nichecompass = compute_combined_benchmarking_metrics(\n",
    "            model_adata=adata_nichecompass,\n",
    "            model_name=\"nichecompass\",\n",
    "            run_number_list=run_number_list,\n",
    "            n_neighbors_list=n_neighbors_list,\n",
    "            cell_type_key=cell_type_key,\n",
    "            ger_genes=ger_genes)\n",
    "        benchmarking_dict_list += benchmarking_dict_list_nichecompass\n",
    "        with open(f\"{dataset_artifact_folder_path}/benchmarking_dict_list.pickle\", \"wb\") as f:\n",
    "            pickle.dump(benchmarking_dict_list, f)\n",
    "        del(adata_nichecompass)\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675da1cd-08a5-4e1c-8ffc-7c38d5d1858d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_colormap(cmap, minval=0.0, maxval=1.0, n=100):\n",
    "    new_cmap = colors.LinearSegmentedColormap.from_list(\n",
    "        'trunc({n},{a:.2f},{b:.2f})'.format(n=cmap.name, a=minval, b=maxval),\n",
    "        cmap(np.linspace(minval, maxval, n)))\n",
    "    return new_cmap\n",
    "\n",
    "def plot_benchmarking_results(df,\n",
    "                              show=True,\n",
    "                              save_dir=None,\n",
    "                              save_name=\"benchmarking_results.svg\"):\n",
    "    datasets = df[\"dataset\"].unique().tolist()\n",
    "    df = df.pivot(index=[\"model_name\", \"spatially_aware\"], columns=[\"dataset\", \"score_type\"], values=\"score\")\n",
    "    df.reset_index(inplace=True)\n",
    "    df.columns = ['_'.join(col).strip(\"_\") for col in df.columns.values]\n",
    "    if len(datasets) > 1:\n",
    "        for i, dataset in enumerate(datasets):\n",
    "            df[f\"Total ({i})\"] = df[[col for col in list(df.columns) if dataset in col]].mean(axis=1)\n",
    "        df[\"Total (All)\"] = df[list(set(list(df.columns)) - set([\"model_name\", \"spatially_aware\"]))].mean(axis=1)\n",
    "        df.sort_values(by=[\"Total (All)\"], inplace=True, ascending=False)\n",
    "    else:\n",
    "        df[\"Total\"] = df[list(set(list(df.columns)) - set([\"model_name\"]))].mean(axis=1)\n",
    "        df.sort_values(by=[\"Total\"], inplace=True, ascending=False)\n",
    "    df.rename(columns={\"model_name\": \"Model\"}, inplace=True)\n",
    "    \n",
    "    cmap_fn = lambda col_data: normed_cmap(col_data, cmap=matplotlib.cm.PRGn, num_stds=2.5)\n",
    "\n",
    "    column_definitions = [\n",
    "        ColumnDefinition(name=\"Model\",\n",
    "                         title=\"Model\",\n",
    "                         width=1.5,\n",
    "                         textprops={\"ha\": \"left\", \"weight\": \"bold\"}),\n",
    "        ColumnDefinition(name=\"spatially_aware\",\n",
    "                         title=\"Spatially \\n Aware\",\n",
    "                         width=1.,\n",
    "                         formatter=tickcross)]\n",
    "\n",
    "    metric_cols = [\"cas\", \"clisis\", \"gcs\", \"mlami\"]\n",
    "    aggregate_cols = [col for col in list(df.columns) if \"Total\" in col]\n",
    "\n",
    "    for i, dataset in enumerate(datasets):\n",
    "        if len(datasets) > 1:\n",
    "            dataset_number_string = f\"({i})\"\n",
    "        else:\n",
    "            dataset_number_string = \"\"\n",
    "        # Circles for the metric columns\n",
    "        column_definitions += [\n",
    "            ColumnDefinition(\n",
    "                name=f\"{dataset}_{col}\",\n",
    "                title=col.upper(),\n",
    "                width=1,\n",
    "                textprops={\n",
    "                    \"ha\": \"center\",\n",
    "                    \"bbox\": {\"boxstyle\": \"circle\", \"pad\": 0.25}},\n",
    "                cmap=cmap_fn(df[f\"{dataset}_{col}\"]),\n",
    "                group=f\"Metrics \\n {dataset.replace('_', ' ').title()} {dataset_number_string}\",\n",
    "                border=\"left\" if j == 0 else None,\n",
    "                formatter=\"{:.2f}\")\n",
    "            for j, col in enumerate(metric_cols)]\n",
    "\n",
    "        # Bars for the aggregate columns\n",
    "        column_definitions += [\n",
    "            ColumnDefinition(\n",
    "                name=col,\n",
    "                title=col,\n",
    "                width=1,\n",
    "                plot_fn=bar,\n",
    "                plot_kw={\n",
    "                    \"cmap\": truncate_colormap(matplotlib.cm.YlOrRd, 0, 0.8),\n",
    "                    \"plot_bg_bar\": False,\n",
    "                    \"annotate\": True,\n",
    "                    \"height\": 0.9,\n",
    "                    \"formatter\": \"{:.2f}\",\n",
    "                },\n",
    "                group=\"Aggregate Scores\",\n",
    "                border=\"left\" if j == 0 else None)\n",
    "            for j, col in enumerate(aggregate_cols)]\n",
    "        \n",
    "    # Allow to manipulate text post-hoc (in illustrator)\n",
    "    with matplotlib.rc_context({\"svg.fonttype\": \"none\"}):\n",
    "        fig, ax = plt.subplots(figsize=(len(df.columns) * 1., 3 + 0.3 * len(df.columns)))\n",
    "        tab = Table(\n",
    "            df,\n",
    "            cell_kw={\n",
    "                \"linewidth\": 0,\n",
    "                \"edgecolor\": \"k\"},\n",
    "            column_definitions=column_definitions,\n",
    "            ax=ax,\n",
    "            row_dividers=True,\n",
    "            footer_divider=True,\n",
    "            textprops={\"fontsize\": 10, \"ha\": \"center\"},\n",
    "            row_divider_kw={\"linewidth\": 1, \"linestyle\": (0, (1, 5))},\n",
    "            col_label_divider_kw={\"linewidth\": 1, \"linestyle\": \"-\"},\n",
    "            column_border_kw={\"linewidth\": 1, \"linestyle\": \"-\"},\n",
    "            index_col=\"Model\",\n",
    "        ).autoset_fontcolors(colnames=df.columns)\n",
    "    if show:\n",
    "        plt.show()\n",
    "    if save_dir is not None:\n",
    "        os.makedirs(save_dir, exist_ok=True)        \n",
    "        fig.savefig(os.path.join(save_dir, save_name), facecolor=ax.get_facecolor(), dpi=300)\n",
    "    return tab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd5a246-b9b1-4d20-9f39-0875d441b8bb",
   "metadata": {},
   "source": [
    "#### 2.2.2 Compute Benchmarking Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbe798c-0b98-4b47-a91c-d9756a688dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_combined_benchmarking_metrics_for_all_models(\n",
    "    dataset=\"seqfish_mouse_organogenesis_embryo2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2910da85-38d5-4855-8151-70094c208c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_combined_benchmarking_metrics_for_all_models(\n",
    "    dataset=\"vizgen_merfish_mouse_liver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35744341-7dc3-4cbc-a0af-aaa392af8170",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_combined_benchmarking_metrics_for_all_models(\n",
    "    dataset=\"vizgen_merfish_mouse_liver_sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d1f940-2b9f-4bc8-810e-1bdab00b9329",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_combined_benchmarking_metrics_for_all_models(\n",
    "    dataset=\"starmap_plus_mouse_cns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8f449a-0ec5-4b39-be0e-2184ea709c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_combined_benchmarking_metrics_for_all_models(\n",
    "    dataset=\"starmap_plus_mouse_cns_sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dd6a14-5a1c-423b-8f2f-3cc7524ba51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_combined_benchmarking_metrics_for_all_models(\n",
    "    dataset=\"nanostring_cosmx_human_nsclc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b805ce71-9d1b-422f-96fc-1b7098fa1688",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_combined_benchmarking_metrics_for_all_models(\n",
    "    dataset=\"nanostring_cosmx_human_nsclc_sample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d224f8-b044-4133-8242-e55c7bec4e9f",
   "metadata": {},
   "source": [
    "#### 3.2.3 Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06c1040-6026-425b-9f93-086de58b56d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "datasets = [\"seqfish_mouse_organogenesis_embryo2\",\n",
    "            \"starmap_plus_mouse_cns_sample\",\n",
    "            \"nanostring_cosmx_human_nsclc_sample\"]\n",
    "timestamps = [\"07032023_193322\",\n",
    "              \"07032023_071219\",\n",
    "              \"07032023_080409\"]\n",
    "\n",
    "for dataset, timestamp in zip(datasets, timestamps):\n",
    "    dataset_artifact_folder_path = f\"../../artifacts/{dataset}/method_benchmarking/comparison/{timestamp}\"\n",
    "    \n",
    "    # Read complete benchmarking data from disk\n",
    "    with open(f\"{dataset_artifact_folder_path}/benchmarking_dict_list.pickle\", \"rb\") as f:\n",
    "        benchmarking_dict_list = pickle.load(f)\n",
    "        dataset_df = pd.DataFrame(benchmarking_dict_list)\n",
    "        dataset_df[\"dataset\"] = dataset\n",
    "        df = pd.concat([df, dataset_df])\n",
    "df.head()\n",
    "\n",
    "columns = [\"gcs\",\n",
    "           \"mlami\",\n",
    "           \"cas\",\n",
    "           \"clisis\",\n",
    "           #\"gerr2\",\n",
    "           #\"cca\"\n",
    "           ]\n",
    "\n",
    "rows = [\"nichecompass\",\n",
    "        \"deeplinc\",\n",
    "        \"graphst\",\n",
    "        \"sagenet\",\n",
    "        \"pca\",\n",
    "        \"scvi\",\n",
    "        \"expimap\"]\n",
    "\n",
    "unrolled_df = pd.melt(df, \n",
    "   id_vars = [\"model_name\", \"dataset\"],\n",
    "   value_vars = columns,\n",
    "   var_name = \"score_type\", \n",
    "   value_name = \"score\")\n",
    "\n",
    "# Compute metric means over all runs\n",
    "mean_df = unrolled_df.groupby([\"model_name\", \"dataset\", \"score_type\"]).mean()\n",
    "mean_df.reset_index(inplace=True)\n",
    "\n",
    "# Remove pca for plot\n",
    "mean_df = mean_df[mean_df[\"model_name\"] != \"pca\"]\n",
    "\n",
    "# Reformat for plot\n",
    "mean_df.replace({\"nichecompass\": \"NicheCompass\",\n",
    "                 \"deeplinc\": \"DeepLinc\",\n",
    "                 \"expimap\": \"expiMap\",\n",
    "                 \"graphst\": \"GraphST\",\n",
    "                 \"sagenet\": \"SageNet\",\n",
    "                 \"scvi\": \"scVI\",\n",
    "                 \"nanostring_cosmx_human_nsclc_sample\": \"nanostring_cosmx_sample\",\n",
    "                 \"starmap_plus_mouse_cns_sample\": \"starmap_plus_sample\",\n",
    "                 \"seqfish_mouse_organogenesis_embryo2\": \"seqfish\"}, inplace=True)\n",
    "\n",
    "# Create spatial indicator column\n",
    "def is_spatially_aware_model(row):\n",
    "    if row[\"model_name\"] in [\"NicheCompass\", \"DeepLinc\", \"GraphST\", \"SageNet\"]:\n",
    "        return True\n",
    "    return False\n",
    "mean_df[\"spatially_aware\"] = mean_df.apply(lambda row: is_spatially_aware_model(row), axis=1)\n",
    "\n",
    "mean_df_seqfish = mean_df[mean_df[\"dataset\"] == \"seqfish\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94762fcf-ffec-4a65-9373-675be6155b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_benchmarking_results(mean_df_seqfish,\n",
    "                          save_dir=figure_folder_path,\n",
    "                          save_name=\"benchmarking_results_seqfish.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908193c6-0de2-443c-b14e-29f99d5b8f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_benchmarking_results(mean_df,\n",
    "                          save_dir=figure_folder_path,\n",
    "                          save_name=\"benchmarking_results.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3c634a-8f83-4890-a2db-5123185471ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metric means over all runs\n",
    "mean_df = unrolled_df.groupby([\"model_name\", \"dataset\", \"score_type\"]).mean()\n",
    "\n",
    "print(mean_df)\n",
    "mean_df = mean_df.reindex(rows)\n",
    "\n",
    "metric_ranks = []\n",
    "for metric in mean_df.columns:\n",
    "    mean_df[f\"{metric}_rank\"] = mean_df[metric].rank(ascending=False).astype(int)\n",
    "\n",
    "mean_df[\"model_name\"] = mean_df.index\n",
    "\n",
    "unrolled_mean_df = pd.melt(mean_df, \n",
    "   id_vars = [\"model_name\", \"dataset\"],\n",
    "   value_vars = columns,\n",
    "   var_name = \"score_type\", \n",
    "   value_name = \"score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d302fa-377f-4b5b-8e2c-ec65db7487b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 15))\n",
    "ax = sns.barplot(data=unrolled_mean_df,\n",
    "                 x=\"score_type\",\n",
    "                 y=\"score\",\n",
    "                 hue=\"model_name\",\n",
    "                 palette=\"Accent\")\n",
    "\n",
    "plt.xticks(fontsize=30)\n",
    "plt.yticks(fontsize=30)\n",
    "\n",
    "# Iterate over the bars and annotate each one with the rank\n",
    "for i, p in enumerate(ax.patches):\n",
    "    model_idx, metric_idx = divmod(i, len(columns))\n",
    "    rank = mean_df.loc[rows[model_idx], columns[metric_idx] + \"_rank\"]\n",
    "    ax.annotate(\"%.0f\" % rank,\n",
    "                (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                fontsize=20,\n",
    "                color=\"gray\",\n",
    "                weight=\"bold\",\n",
    "                xytext=(0, 8),\n",
    "                textcoords=\"offset points\")\n",
    "\n",
    "plt.xlabel(\"Metric\",\n",
    "           fontsize=30)\n",
    "plt.ylabel(\"Metric Value (higher better)\",\n",
    "           fontsize=30)\n",
    "plt.legend(loc=2,\n",
    "           bbox_to_anchor=(1, 1),\n",
    "           prop={\"size\": 28})\n",
    "plt.title(\"Model Benchmarking Evaluation Metrics\",\n",
    "          fontsize=30,\n",
    "          pad=20)\n",
    "plt.savefig(f\"{figure_folder_path}/eval_metrics.svg\",\n",
    "            dpi=300,\n",
    "            bbox_inches=\"tight\",\n",
    "            format=\"svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c821ec-ab73-498e-a6b8-4fc86306059a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_df[\"dataset_score_type\"] = mean_df[\"score_type\"] + mean_df[\"dataset\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f25b370-bf79-44a5-87af-22b60e83f765",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_df[mean_df[\"model_name\"] == \"nichecompass\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8644d0-c337-4e38-889c-5c9142aeb337",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, figsize=(30, 15))\n",
    "\n",
    "plt.xlabel(\"Metric\",\n",
    "           fontsize=30)\n",
    "plt.ylabel(\"Metric Value (higher better)\",\n",
    "           fontsize=30)\n",
    "plt.legend(loc=2,\n",
    "           bbox_to_anchor=(1, 1),\n",
    "           prop={\"size\": 28})\n",
    "plt.title(\"Model Benchmarking Evaluation Metrics\",\n",
    "          fontsize=30,\n",
    "          pad=20)\n",
    "\n",
    "sns.scatterplot(data=mean_df[mean_df[\"dataset\"] == \"starmap_plus_mouse_cns_sample\"],\n",
    "                ax=axs[0],\n",
    "                 x=\"score_type\",\n",
    "                 y=\"score\",\n",
    "                 hue=\"model_name\",\n",
    "                 palette=\"Accent\",\n",
    "                 s=1000,\n",
    "                 style=\"dataset\")\n",
    "\n",
    "sns.scatterplot(data=mean_df[mean_df[\"dataset\"] == \"nanostring_cosmx_human_nsclc_sample\"],\n",
    "                ax=axs[1],\n",
    "                 x=\"score_type\",\n",
    "                 y=\"score\",\n",
    "                 hue=\"model_name\",\n",
    "                 palette=\"Accent\",\n",
    "                 s=1000,\n",
    "                 style=\"dataset\")\n",
    "\n",
    "plt.xticks(fontsize=30)\n",
    "plt.yticks(fontsize=30)\n",
    "\n",
    "\n",
    "plt.savefig(f\"{figure_folder_path}/eval_metrics.svg\",\n",
    "            dpi=300,\n",
    "            bbox_inches=\"tight\",\n",
    "            format=\"svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cb6f0d-8911-4df1-890e-7c80506a16d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "ax = sns.scatterplot(data=mean_df,\n",
    "                 x=\"dataset_score_type\",\n",
    "                 y=\"score\",\n",
    "                 hue=\"model_name\",\n",
    "                 palette=\"Accent\",\n",
    "                 s=500,\n",
    "                 style=\"dataset\")\n",
    "\n",
    "plt.xticks(fontsize=30)\n",
    "plt.yticks(fontsize=30)\n",
    "\n",
    "# Iterate over the bars and annotate each one with the rank\n",
    "for i, p in enumerate(ax.patches):\n",
    "    model_idx, metric_idx = divmod(i, len(columns))\n",
    "    rank = mean_df.loc[rows[model_idx], columns[metric_idx] + \"_rank\"]\n",
    "    ax.annotate(\"%.0f\" % rank,\n",
    "                (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                fontsize=20,\n",
    "                color=\"gray\",\n",
    "                weight=\"bold\",\n",
    "                xytext=(0, 8),\n",
    "                textcoords=\"offset points\")\n",
    "\n",
    "plt.xlabel(\"Metric\",\n",
    "           fontsize=30)\n",
    "plt.ylabel(\"Metric Value (higher better)\",\n",
    "           fontsize=30)\n",
    "plt.legend(loc=2,\n",
    "           bbox_to_anchor=(1, 1),\n",
    "           prop={\"size\": 28})\n",
    "plt.title(\"Model Benchmarking Evaluation Metrics\",\n",
    "          fontsize=30,\n",
    "          pad=20)\n",
    "plt.savefig(f\"{figure_folder_path}/eval_metrics.svg\",\n",
    "            dpi=300,\n",
    "            bbox_inches=\"tight\",\n",
    "            format=\"svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89418b7-7d74-4dfb-be72-1f1c0aef93f1",
   "metadata": {},
   "source": [
    "##### 3.2.8.1 Metrics Ranking Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895e0bff-e8b0-4bc2-afa1-50b38cd19f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_df_min_best = mean_df[[\"gcd\", \"cad\", \"arclisi\", \"germse\"]] # lower values are better\n",
    "mean_df_max_best = mean_df[[\"mlnmi\", \"cca\", \"ari\", \"clisi\", \"nmi\", \"asw\", \"ilasw\", ]] # higher values are better\n",
    "rank_df_min = mean_df_min_best.rank(method=\"max\", ascending=True)\n",
    "rank_df_max = mean_df_max_best.rank(method=\"max\", ascending=False)\n",
    "rank_df = pd.concat([rank_df_min, rank_df_max], axis=1)\n",
    "rank_df = rank_df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfb4629-bd72-4918-bcf0-5176937a28b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap = sns.heatmap(rank_df, annot=True, cmap=\"YlGnBu\")\n",
    "fig = heatmap.get_figure()\n",
    "plt.title(\"Method Benchmarking Metrics Ranking\", fontsize=20, pad=25)\n",
    "plt.xticks(rotation=45)\n",
    "fig.savefig(f\"{figure_folder_path}/metrics_ranking_{current_timestamp}.png\",\n",
    "            bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40bd054-dc77-45c5-9c12-7ea78f6829a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55de09bf-3e2d-41a2-913e-f8e8d6a4817e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2383b1f3-24d5-44bd-b49e-e8377b0aa716",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "9878ab49-8a09-4803-a523-37a797aa8993",
   "metadata": {},
   "source": [
    "dataset = \"vizgen_merfish_mouse_liver\"\n",
    "model = \"expimap\"\n",
    "adata_model = sc.read_h5ad(data_folder_path + f\"{dataset}_{model}.h5ad\")\n",
    "adata_original = sc.read_h5ad(data_folder_path + f\"{dataset}.h5ad\")\n",
    "adata_model.var_names = adata_original.var_names\n",
    "adata_model.obs_names = adata_original.obs_names\n",
    "adata_model.obsm[\"spatial\"] = adata_original.obsm[\"spatial\"]\n",
    "adata_model.obs[\"cell_type\"] = adata_original.obs[\"Cell_Type\"].values\n",
    "adata_model.write(f\"{data_folder_path}/{dataset}_{model}.h5ad\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0699529d-35fd-404f-b7c5-221cdc26aaf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
