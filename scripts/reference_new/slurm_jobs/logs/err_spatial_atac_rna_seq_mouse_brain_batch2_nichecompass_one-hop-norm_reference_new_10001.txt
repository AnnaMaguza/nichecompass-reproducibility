/home/aih/sebastian.birk/workspace/projects/nichecompass/nichecompass/utils/gene_programs.py:203: ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual.
  adata.uns[sources_categories_label_encoder_key] = sources_categories_label_encoder
window_graph:   0%|          | 0/3864 [00:00<?, ?it/s]window_graph:  17%|█▋        | 667/3864 [00:00<00:00, 6668.27it/s]window_graph:  35%|███▍      | 1334/3864 [00:00<00:00, 6211.95it/s]window_graph:  52%|█████▏    | 2017/3864 [00:00<00:00, 6480.68it/s]window_graph:  70%|██████▉   | 2699/3864 [00:00<00:00, 6608.21it/s]window_graph:  89%|████████▉ | 3431/3864 [00:00<00:00, 6856.57it/s]window_graph: 100%|██████████| 3864/3864 [00:00<00:00, 6823.15it/s]
/home/aih/sebastian.birk/workspace/projects/nichecompass/nichecompass/models/nichecompass.py:319: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)
  self.gene_peaks_mask_ = torch.sparse_coo_tensor(
Traceback (most recent call last):
  File "/home/aih/sebastian.birk/workspace/projects/nichecompass-reproducibility/scripts/reference_new/../train_nichecompass_reference_model.py", line 876, in <module>
    model.train(n_epochs=args.n_epochs,
  File "/home/aih/sebastian.birk/workspace/projects/nichecompass/nichecompass/models/nichecompass.py", line 738, in train
    self.trainer.train(
  File "/home/aih/sebastian.birk/workspace/projects/nichecompass/nichecompass/train/trainer.py", line 419, in train
    train_optim_loss.backward()
  File "/home/aih/sebastian.birk/miniconda3/envs/nichecompass-test/lib/python3.9/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/home/aih/sebastian.birk/miniconda3/envs/nichecompass-test/lib/python3.9/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.84 GiB (GPU 0; 39.42 GiB total capacity; 33.74 GiB already allocated; 2.18 GiB free; 36.36 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
