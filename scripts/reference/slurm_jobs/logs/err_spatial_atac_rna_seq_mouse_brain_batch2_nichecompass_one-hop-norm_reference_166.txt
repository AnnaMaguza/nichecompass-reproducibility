/home/aih/sebastian.birk/workspace/projects/nichecompass/nichecompass/utils/gene_programs.py:203: ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual.
  adata.uns[sources_categories_label_encoder_key] = sources_categories_label_encoder
window_graph:   0%|          | 0/4675 [00:00<?, ?it/s]window_graph:  15%|█▌        | 713/4675 [00:00<00:00, 7102.69it/s]window_graph:  30%|███       | 1424/4675 [00:00<00:00, 6855.57it/s]window_graph:  46%|████▌     | 2137/4675 [00:00<00:00, 6975.43it/s]window_graph:  62%|██████▏   | 2888/4675 [00:00<00:00, 7183.58it/s]window_graph:  77%|███████▋  | 3607/4675 [00:00<00:00, 7077.37it/s]window_graph:  95%|█████████▍| 4424/4675 [00:00<00:00, 7441.69it/s]window_graph: 100%|██████████| 4675/4675 [00:00<00:00, 7385.65it/s]
/home/aih/sebastian.birk/workspace/projects/nichecompass/nichecompass/models/nichecompass.py:319: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)
  self.gene_peaks_mask_ = torch.sparse_coo_tensor(
Traceback (most recent call last):
  File "/home/aih/sebastian.birk/workspace/projects/nichecompass-reproducibility/scripts/reference/../train_nichecompass_reference_model.py", line 826, in <module>
    model.train(n_epochs=args.n_epochs,
  File "/home/aih/sebastian.birk/workspace/projects/nichecompass/nichecompass/models/nichecompass.py", line 730, in train
    self.trainer.train(
  File "/home/aih/sebastian.birk/workspace/projects/nichecompass/nichecompass/train/trainer.py", line 419, in train
    train_optim_loss.backward()
  File "/home/aih/sebastian.birk/miniconda3/envs/nichecompass-test/lib/python3.9/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/home/aih/sebastian.birk/miniconda3/envs/nichecompass-test/lib/python3.9/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.39 GiB (GPU 0; 39.42 GiB total capacity; 27.78 GiB already allocated; 1.99 GiB free; 36.55 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
