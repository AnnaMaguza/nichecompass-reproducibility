/home/aih/sebastian.birk/workspace/projects/nichecompass/nichecompass/utils/gene_programs.py:203: ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual.
  adata.uns[sources_categories_label_encoder_key] = sources_categories_label_encoder
window_graph:   0%|          | 0/4675 [00:00<?, ?it/s]window_graph:  13%|█▎        | 629/4675 [00:00<00:00, 6286.17it/s]window_graph:  28%|██▊       | 1301/4675 [00:00<00:00, 6537.88it/s]window_graph:  43%|████▎     | 2004/4675 [00:00<00:00, 6760.08it/s]window_graph:  58%|█████▊    | 2727/4675 [00:00<00:00, 6942.75it/s]window_graph:  73%|███████▎  | 3422/4675 [00:00<00:00, 6925.55it/s]window_graph:  90%|█████████ | 4217/4675 [00:00<00:00, 7271.06it/s]window_graph: 100%|██████████| 4675/4675 [00:00<00:00, 7130.86it/s]
/home/aih/sebastian.birk/workspace/projects/nichecompass/nichecompass/models/nichecompass.py:319: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)
  self.gene_peaks_mask_ = torch.sparse_coo_tensor(
Traceback (most recent call last):
  File "/home/aih/sebastian.birk/workspace/projects/nichecompass-reproducibility/scripts/reference/../train_nichecompass_reference_model.py", line 826, in <module>
    model.train(n_epochs=args.n_epochs,
  File "/home/aih/sebastian.birk/workspace/projects/nichecompass/nichecompass/models/nichecompass.py", line 730, in train
    self.trainer.train(
  File "/home/aih/sebastian.birk/workspace/projects/nichecompass/nichecompass/train/trainer.py", line 419, in train
    train_optim_loss.backward()
  File "/home/aih/sebastian.birk/miniconda3/envs/nichecompass-test/lib/python3.9/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/home/aih/sebastian.birk/miniconda3/envs/nichecompass-test/lib/python3.9/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.35 GiB (GPU 0; 31.74 GiB total capacity; 27.13 GiB already allocated; 625.88 MiB free; 30.53 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
